{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VEaY6aMwtl4w",
        "erfHheistl4x",
        "5kZAFCPstl46",
        "xQpZUXBYtl46"
      ],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyri0n11/distributed-system/blob/main/4_1_intro_motivation_mapreduce_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUlkWZxttl4n"
      },
      "source": [
        "\n",
        "### Overview\n",
        "\n",
        "1. Recap of functional programming in Python\n",
        "2. Python's `map` and `reduce` functions\n",
        "3. Writing parallel code using `map`\n",
        "4. The Map-Reduce programming model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnEtaYMetl4o"
      },
      "source": [
        "## History\n",
        "\n",
        "- The Map-Reduce programming model was popularised by Google (Dean and Ghemawat 2008).\n",
        "\n",
        "- The first popular open-source implementation was Apache Hadoop, first released in 2011.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Er-nqtrStl4o"
      },
      "source": [
        "## Functional programming\n",
        "\n",
        "Consider the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KItrfbbMtl4p"
      },
      "source": [
        "def double_everything_in(data):\n",
        "    result = []\n",
        "    for i in data:\n",
        "        result.append(2 * i)\n",
        "    return result\n",
        "\n",
        "def quadruple_everything_in(data):\n",
        "    result = []\n",
        "    for i in data:\n",
        "        result.append(4 * i)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJxh_EdStl4p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cf7cb76-3612-401a-8f70-ad4bd05d124d"
      },
      "source": [
        "double_everything_in([1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6, 8, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSJ9EoXXtl4r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a238302-ce95-408e-87dd-25a92a37210e"
      },
      "source": [
        "quadruple_everything_in([1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 8, 12, 16, 20]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWAlQJ_9tl4s"
      },
      "source": [
        "### DRY - Fundamental Programming Concept\n",
        "\n",
        "- The above code violates the [\"do not repeat yourself\"](https://en.wikipedia.org/wiki/Don't_repeat_yourself_) principle of good software engineering practice.\n",
        "\n",
        "- How can rewrite the code so that it avoids duplication?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISBWzZdxtl4t"
      },
      "source": [
        "def multiply_by_x_everything_in(x, data):\n",
        "    result = []\n",
        "    for i in data:\n",
        "        result.append(x * i)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktIZ1OZmtl4t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a5ca9b0-4cf2-47f9-de5a-0a0c4fdbc6ea"
      },
      "source": [
        "multiply_by_x_everything_in(2, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6, 8, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUb8a_Uatl4t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b1edf1e-2148-4d3c-8718-eb725e2a951f"
      },
      "source": [
        "multiply_by_x_everything_in(4, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 8, 12, 16, 20]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CPY7p5Ebtl4u"
      },
      "source": [
        "- Now consider the following code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXoqZKbLtl4u"
      },
      "source": [
        "def squared(x):\n",
        "    return x*x\n",
        "\n",
        "def double(x):\n",
        "    return x*2\n",
        "\n",
        "def square_everything_in(data):\n",
        "    result = []\n",
        "    for i in data:\n",
        "        result.append(squared(i))\n",
        "    return result\n",
        "\n",
        "def double_everything_in(data):\n",
        "    result = []\n",
        "    for i in data:\n",
        "        result.append(double(i))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8or_BFdtl4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51fae59a-731a-4029-f4ad-90e3f519b50c"
      },
      "source": [
        "square_everything_in([1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9, 16, 25]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mpCMj4vPtl4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "685cd677-90b8-40ce-e572-4587a97debf5"
      },
      "source": [
        "double_everything_in([1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6, 8, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEaY6aMwtl4w"
      },
      "source": [
        "### Passing Functions as Values\n",
        "- Functions can be passed to other functions as values.\n",
        "-\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "607XT-K4tl4w"
      },
      "source": [
        "def apply_f_to_everything_in(f, data):\n",
        "    result = []\n",
        "    for x in data:\n",
        "        result.append(f(x))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyaNOZyBtl4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08e510c3-1d4f-412c-dc25-db429a3e24d5"
      },
      "source": [
        "apply_f_to_everything_in(squared, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9, 16, 25]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxvB3bnttl4w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870502e1-41df-4d60-f9a2-18912d24723d"
      },
      "source": [
        "apply_f_to_everything_in(double, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6, 8, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erfHheistl4x"
      },
      "source": [
        "### Lambda expressions\n",
        "\n",
        "- We can use anonymous functions to save having to define a function each time we want to use map."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e8mkM2Ctl4x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5890fe7e-ea07-44ca-8a4e-d2a8a49c0ea3"
      },
      "source": [
        "apply_f_to_everything_in(lambda x: x*x, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9, 16, 25]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJfvXKIUTTZR",
        "outputId": "24ebb8b2-1a30-48ad-bcd8-70a70ea7bff4"
      },
      "source": [
        "apply_f_to_everything_in(lambda x: 2*x, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, 4, 6, 8, 10]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov5HqJHetl4x"
      },
      "source": [
        "# Python's `map` function\n",
        "\n",
        "- Python has a built-in function `map` which is much faster than our version.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xthp90Nvtl4x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b4a327-8ecc-4244-c014-19356e292fd8"
      },
      "source": [
        "map(lambda x: x*x, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<map at 0x7bff191923e0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5FhLeVWtl4y"
      },
      "source": [
        "## Implementing reduce\n",
        "\n",
        "- The `reduce` function is an example of a [fold](https://en.wikipedia.org/wiki/Fold_%28higher-order_function%29).\n",
        "\n",
        "- There are different ways we can fold data.\n",
        "\n",
        "- The following implements a *left* fold.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Rr0gPj_tl4y"
      },
      "source": [
        "def foldl(f, data, z):\n",
        "    if (len(data) == 0):\n",
        "        print (z)\n",
        "        return z\n",
        "    else:\n",
        "        head = data[0]\n",
        "        tail = data[1:]\n",
        "        print (\"Folding\", head, \"with\", tail, \"using\", z)\n",
        "        partial_result = f(z, data[0])\n",
        "        print (\"Partial result is\", partial_result)\n",
        "        return foldl(f, tail, partial_result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BffOLSjctl4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d43f89c7-45d3-4eb9-ed36-0871e53e86ed"
      },
      "source": [
        "def add(x, y):\n",
        "    return x + y\n",
        "\n",
        "foldl(add, [3, 3, 3, 3, 3], 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folding 3 with [3, 3, 3, 3] using 0\n",
            "Partial result is 3\n",
            "Folding 3 with [3, 3, 3] using 3\n",
            "Partial result is 6\n",
            "Folding 3 with [3, 3] using 6\n",
            "Partial result is 9\n",
            "Folding 3 with [3] using 9\n",
            "Partial result is 12\n",
            "Folding 3 with [] using 12\n",
            "Partial result is 15\n",
            "15\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2c8pZeWtl4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd91be6a-305f-455d-df4d-9633873faceb"
      },
      "source": [
        "foldl(lambda x, y: x + y, [1, 2, 3, 4, 5], 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folding 1 with [2, 3, 4, 5] using 0\n",
            "Partial result is 1\n",
            "Folding 2 with [3, 4, 5] using 1\n",
            "Partial result is 3\n",
            "Folding 3 with [4, 5] using 3\n",
            "Partial result is 6\n",
            "Folding 4 with [5] using 6\n",
            "Partial result is 10\n",
            "Folding 5 with [] using 10\n",
            "Partial result is 15\n",
            "15\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdMy-s1gtl4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f398bd1a-66ee-4322-9f04-a4c19409ccef"
      },
      "source": [
        "foldl(lambda x, y: x - y, [1, 2, 3, 4, 5], 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folding 1 with [2, 3, 4, 5] using 0\n",
            "Partial result is -1\n",
            "Folding 2 with [3, 4, 5] using -1\n",
            "Partial result is -3\n",
            "Folding 3 with [4, 5] using -3\n",
            "Partial result is -6\n",
            "Folding 4 with [5] using -6\n",
            "Partial result is -10\n",
            "Folding 5 with [] using -10\n",
            "Partial result is -15\n",
            "-15\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-15"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pEE26o3tl4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b64b21-357a-449d-98b3-534f6e7533ad"
      },
      "source": [
        "(((((0 - 1) - 2) - 3) - 4) - 5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-15"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9RGnLIctl4z"
      },
      "source": [
        "- Subtraction is neither [commutative](https://en.wikipedia.org/wiki/Commutative_property) nor [associative](https://en.wikipedia.org/wiki/Associative_property), so the order in which apply the fold matters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIfG7Zxntl4z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa4a5ab3-abf5-4de5-ffbc-87c42b267641"
      },
      "source": [
        "(1 - (2 - (3 - (4 - (5 - 0)))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMtG-dSZtl4z"
      },
      "source": [
        "def foldr(f, data, z):\n",
        "    if (len(data) == 0):\n",
        "        return z\n",
        "    else:\n",
        "        return f(data[0], foldr(f, data[1:], z))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_XOcMintl40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35d086c5-d4d8-4351-c80d-26a730117c70"
      },
      "source": [
        "foldl(lambda x, y: x - y,  [1, 2, 3, 4, 5], 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folding 1 with [2, 3, 4, 5] using 0\n",
            "Partial result is -1\n",
            "Folding 2 with [3, 4, 5] using -1\n",
            "Partial result is -3\n",
            "Folding 3 with [4, 5] using -3\n",
            "Partial result is -6\n",
            "Folding 4 with [5] using -6\n",
            "Partial result is -10\n",
            "Folding 5 with [] using -10\n",
            "Partial result is -15\n",
            "-15\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-15"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Udv4ZFmXtl40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c17e2f5-7e5b-4974-96cb-965e2ab4d607"
      },
      "source": [
        "foldr(lambda x, y: x - y, [1, 2, 3, 4, 5], 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qkagLEatl40"
      },
      "source": [
        "## Python's `reduce` function.\n",
        "\n",
        "- Python's built-in `reduce` function is a *left* fold."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2wqZLH8tl40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "440d7a70-36a4-4c51-b7c0-73902e9f8a9c"
      },
      "source": [
        "from functools import reduce\n",
        "reduce(lambda x, y: x + y, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ydxb9yQYtl41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "def6893e-9b1c-45ac-855a-11a8e1fb26ed"
      },
      "source": [
        "%time\n",
        "reduce(lambda x, y: x - y, [1, 2, 3, 4, 5], 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.72 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-15"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EChnfJgQtl41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48a5bb7-9d7c-44fc-cf19-bedd81d93d41"
      },
      "source": [
        "%time\n",
        "foldl(lambda x, y: x - y, [1, 2, 3, 4, 5], 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
            "Wall time: 9.06 µs\n",
            "Folding 1 with [2, 3, 4, 5] using 0\n",
            "Partial result is -1\n",
            "Folding 2 with [3, 4, 5] using -1\n",
            "Partial result is -3\n",
            "Folding 3 with [4, 5] using -3\n",
            "Partial result is -6\n",
            "Folding 4 with [5] using -6\n",
            "Partial result is -10\n",
            "Folding 5 with [] using -10\n",
            "Partial result is -15\n",
            "-15\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-15"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfxFaiQgtl41"
      },
      "source": [
        "# Functional programming and parallelism\n",
        "\n",
        "- Functional programming lends itself to [parallel programming](https://computing.llnl.gov/tutorials/parallel_comp/#Models).\n",
        "\n",
        "- The `map` function can easily be parallelised through [data-level parallelism](https://en.wikipedia.org/wiki/Data_parallelism),\n",
        "    - provided that the function we supply as an argument is *free from* [side-effects](https://en.wikipedia.org/wiki/Side_effect_%28computer_science%29)\n",
        "        - (which is why we avoid working with mutable data).\n",
        "\n",
        "- We can see this by rewriting it so:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fmyo_mDtl41"
      },
      "source": [
        "def perform_computation(f, result, data, i):\n",
        "    print (\"Computing the \", i, \"th result...\")\n",
        "    # This could be scheduled on a different CPU\n",
        "    result[i] = f(data[i])\n",
        "\n",
        "def my_map(f, data):\n",
        "    result = [None] * len(data)\n",
        "    for i in range(len(data)):\n",
        "        perform_computation(f, result, data, i)\n",
        "    # Wait for other CPUs to finish, and then..\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONvlsTx7tl41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8f3d02a-8da5-4700-a772-aa74875e9496"
      },
      "source": [
        "%time\n",
        "my_map(lambda x: x * x, [1, 2, 3, 4, 5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 8.34 µs\n",
            "Computing the  0 th result...\n",
            "Computing the  1 th result...\n",
            "Computing the  2 th result...\n",
            "Computing the  3 th result...\n",
            "Computing the  4 th result...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9, 16, 25]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jit3MJu2tl42"
      },
      "source": [
        "## A multi-threaded `map` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsT8BJrrtl42"
      },
      "source": [
        "from threading import Thread\n",
        "\n",
        "def schedule_computation_threaded(f, result, data, threads, i):\n",
        "    # Each function evaluation is scheduled on a different core.\n",
        "    def my_job():\n",
        "        print (\"Processing data:\", data[i], \"... \")\n",
        "        result[i] = f(data[i])\n",
        "        print (\"Finished job #\", i)\n",
        "        print (\"Result was\", result[i])\n",
        "    threads[i] = Thread(target=my_job)\n",
        "\n",
        "def my_map_multithreaded(f, data):\n",
        "    n = len(data)\n",
        "    result = [None] * n\n",
        "    threads = [None] * n\n",
        "    print (\"Scheduling jobs.. \")\n",
        "    for i in range(n):\n",
        "        schedule_computation_threaded(f, result, data, threads, i)\n",
        "    print (\"Starting jobs.. \")\n",
        "    for i in range(n):\n",
        "        threads[i].start()\n",
        "    print (\"Waiting for jobs to finish.. \")\n",
        "    for i in range(n):\n",
        "        threads[i].join()\n",
        "    print (\"All done.\")\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjcWZUAftl42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6877bbf-6655-40fc-f7f3-9cd7bfa4065c"
      },
      "source": [
        "%time\n",
        "my_map_multithreaded(lambda x: x*x, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.72 µs\n",
            "Scheduling jobs.. \n",
            "Starting jobs.. \n",
            "Processing data: Processing data: 2 ... \n",
            "Finished job # 1\n",
            "Result was 4\n",
            "Processing data: 3 ... \n",
            "Finished job # 2\n",
            "Result was 91 ... \n",
            "Finished job #Processing data: 4 ... \n",
            "Finished job # 3\n",
            "Result was \n",
            "16\n",
            " 0\n",
            "Result was 1Processing data: \n",
            "5Processing data: 6 ...  ... \n",
            "Finished job # 4\n",
            "Result was 25\n",
            "\n",
            "Processing data: 7 ... \n",
            "Finished job # 6\n",
            "Result was 49\n",
            "Finished job # 5\n",
            "Result was 36\n",
            "Processing data: 8 Processing data: ... \n",
            "Finished job # 7\n",
            "Result was 64\n",
            "9 ... \n",
            "Finished job # 8\n",
            "Result was 81\n",
            "Processing data: 10 ... \n",
            "Finished job # 9\n",
            "Result was 100\n",
            "Processing data: 11 ... \n",
            "Finished job # 10\n",
            "Result was 121\n",
            "Processing data: 12 ... \n",
            "Finished job # 11\n",
            "Result was 144\n",
            "Waiting for jobs to finish.. \n",
            "All done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100, 121, 144]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEV4ea1Etl42",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7af31af-317e-481e-ad82-ee21a6f06d1e"
      },
      "source": [
        "from numpy.random import uniform\n",
        "from time import sleep\n",
        "\n",
        "def a_function_which_takes_a_long_time(x):\n",
        "    sleep(uniform(2, 10))  # Simulate some long computation\n",
        "    return x*x\n",
        "\n",
        "%time\n",
        "my_map_multithreaded(a_function_which_takes_a_long_time, [1, 2, 3, 4, 5, 6, 7, 8, 9, 10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
            "Wall time: 5.48 µs\n",
            "Scheduling jobs.. \n",
            "Starting jobs.. \n",
            "Processing data: 1 ... \n",
            "Processing data: 2 ... \n",
            "Processing data: 3 ... \n",
            "Processing data: 4 ... \n",
            "Processing data: 5 ... \n",
            "Processing data: 6 ... \n",
            "Processing data: 7 ... \n",
            "Processing data: 8 ... \n",
            "Processing data:Processing data: 10Waiting for jobs to finish..  9 ... \n",
            "\n",
            " ... \n",
            "Finished job # 7\n",
            "Result was 64\n",
            "Finished job # 6\n",
            "Result was 49\n",
            "Finished job # 4\n",
            "Result was 25\n",
            "Finished job # 5\n",
            "Result was 36\n",
            "Finished job # 2\n",
            "Result was 9\n",
            "Finished job # 8\n",
            "Result was 81\n",
            "Finished job # 1\n",
            "Result was 4\n",
            "Finished job # 3\n",
            "Result was 16\n",
            "Finished job # 9\n",
            "Result was 100\n",
            "Finished job # 0\n",
            "Result was 1\n",
            "All done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 4, 9, 16, 25, 36, 49, 64, 81, 100]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gx2Itg6Ptl42"
      },
      "source": [
        "## Map Reduce\n",
        "\n",
        "- Map Reduce is a _programming model_ for scalable parallel processing.\n",
        "- Scalable here means that it can work on big data with very large compute clusters.\n",
        "- There are many implementations: e.g. Apache Hadoop and Apache Spark.\n",
        "- We can use Map-Reduce with any programming language:\n",
        "    - Hadoop is written in Java\n",
        "    - Spark is written in Scala, but has a Python interface.\n",
        "- *Functional programming* languages such as Python or Scala fit very well with the Map Reduce model:\n",
        "    - However, we don't *have* to use functional programming."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFvetFDVD6e6"
      },
      "source": [
        "![MapReduce](https://github.com/pnavaro/big-data/blob/master/notebooks/images/mapreduce.jpg?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS28lTmatl42"
      },
      "source": [
        "- A MapReduce implementation will take care of the low-level functionality so that you don't have to worry about:\n",
        "    - load balancing\n",
        "    - network I/O\n",
        "    - network and disk transfer optimisation\n",
        "    - handling of machine failures\n",
        "    - serialization of data\n",
        "    - etc..\n",
        "- The model is designed to move the processing to where the data resides."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIrEYEnVtl43"
      },
      "source": [
        "## Typical steps in a Map Reduce Computation\n",
        "\n",
        "1. ETL a big data set.\n",
        "2. _Map_ operation: extract something you care about from each row\n",
        "3. \"Shuffle and Sort\": task/node allocation\n",
        "4. _Reduce_ operation: aggregate, summarise, filter or transform\n",
        "5. Write the results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etM5ZAYYtl43"
      },
      "source": [
        "## Callbacks for Map Reduce\n",
        "\n",
        "- The data set, and the state of each stage of the computation, is represented as a set of key-value pairs.\n",
        "\n",
        "- The programmer provides a map function:\n",
        "\n",
        "$\\operatorname{map}(k, v) \\rightarrow \\; \\left< k', v' \\right>*$  \n",
        "\n",
        "- and a reduce function:\n",
        "\n",
        "$\\operatorname{reduce}(k', \\left< k', v'\\right> *) \\rightarrow \\; \\left< k', v''\n",
        "\\right> *$\n",
        "\n",
        "- The $*$ refers to a *collection* of values.\n",
        "\n",
        "- These collections are *not* ordered."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec-rrLrHDe2l"
      },
      "source": [
        "This part is to code in Python language a wordcount application using map-reduce process. A java version is well explained on [this page](https://www.dezyre.com/hadoop-tutorial/hadoop-mapreduce-wordcount-tutorial)\n",
        "\n",
        "![domain decomposition](https://github.com/pnavaro/big-data/blob/master/notebooks/images/domain_decomp.png?raw=1)\n",
        "\n",
        "credits: https://computing.llnl.gov/tutorials/parallel_comp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0FAXBh-Wtl43"
      },
      "source": [
        "## Word Count Example\n",
        "\n",
        "- In this simple example, the input is a set of URLs, each record is a document.\n",
        "\n",
        "- Problem: compute how many times each word has occurred across data set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRL0h0Lhtl43"
      },
      "source": [
        "## Word Count: Map\n",
        "\n",
        "\n",
        "- The input to $\\operatorname{map}$ is a mapping:\n",
        "\n",
        "- Key: URL\n",
        "- Value: Contents of document"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbJefeRntl43"
      },
      "source": [
        "$\\left< document1, to \\; be \\; or \\; not \\; to \\; be \\right>$  \n",
        "    \n",
        "\n",
        "- In this example, our $\\operatorname{map}$ function will process a given URL, and produces a mapping:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMtA3pz8tl43"
      },
      "source": [
        "- Key: word\n",
        "- Value: 1\n",
        "\n",
        "- So our original data-set will be transformed to:\n",
        "  \n",
        "  $\\left< to, 1 \\right>$\n",
        "  $\\left< be, 1 \\right>$\n",
        "  $\\left< or, 1 \\right>$\n",
        "  $\\left< not, 1 \\right>$\n",
        "  $\\left< to, 1 \\right>$\n",
        "  $\\left< be, 1 \\right>$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O2qbbsrGtl43"
      },
      "source": [
        "## Word Count: Reduce\n",
        "\n",
        "\n",
        "- The reduce operation groups values according to their key, and then performs a reduce on each key.\n",
        "\n",
        "- The collections are partitioned across different storage units, therefore.\n",
        "\n",
        "- Map-Reduce will fold the data in such a way that it minimises data-copying across the cluster.\n",
        "\n",
        "- Data in different partitions are reduced separately in parallel.\n",
        "\n",
        "- The final result is a reduce of the reduced data in each partition.\n",
        "\n",
        "- Therefore it is very important that our operator *is both commutative and associative*.\n",
        "\n",
        "- In our case the function is the `+` operator\n",
        "\n",
        "  $\\left< be, 2 \\right>$  \n",
        "  $\\left< not, 1 \\right>$  \n",
        "  $\\left< or, 1 \\right>$  \n",
        "  $\\left< to, 2 \\right>$  \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWHFF8sEtl44"
      },
      "source": [
        "## Map and Reduce compared with Python\n",
        "\n",
        "- Notice that these functions are formulated differently from the standard Python functions of the same name.\n",
        "\n",
        "- The `reduce` function works with key-value *pairs*.\n",
        "\n",
        "- It would be more apt to call it something like `reduceByKey`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkZt8lI4tl44"
      },
      "source": [
        "## MiniMapReduce\n",
        "\n",
        "- To illustrate how the Map-Reduce programming model works, we can implement our own Map-Reduce framework in Python.\n",
        "\n",
        "- This *illustrates* how a problem can be written in terms of `map` and `reduce` operations.\n",
        "\n",
        "- Note that these are illustrative functions; this is *not* how Hadoop or Apache Spark actually implement them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCXHugVwtl44"
      },
      "source": [
        "##########################################################\n",
        "#\n",
        "#   MiniMapReduce\n",
        "#\n",
        "# A non-parallel, non-scalable Map-Reduce implementation\n",
        "##########################################################\n",
        "\n",
        "def groupByKey(data):\n",
        "    result = dict()\n",
        "    for key, value in data:\n",
        "        if key in result:\n",
        "            result[key].append(value)\n",
        "        else:\n",
        "            result[key] = [value]\n",
        "    return result\n",
        "\n",
        "def reduceByKey(f, data):\n",
        "    key_values = groupByKey(data)\n",
        "    return map(lambda key:\n",
        "                   (key, reduce(f, key_values[key])),\n",
        "                       key_values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EC0QrL7dtl44"
      },
      "source": [
        "## Word-count using MiniMapReduce\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3LFtr7etl44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8bacb11-3397-49ac-c055-c644f49d0be2"
      },
      "source": [
        "data = map(lambda x: (x, 1), \"to be or not to be, or to be and not to be are the same whatever to be or not to be and who cares\".split())\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<map at 0x7bfedc3b13c0>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPGfpO66tl45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44afb561-b83f-4885-a78c-dfd9dd822b40"
      },
      "source": [
        "groupByKey(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'to': [1, 1, 1, 1, 1, 1],\n",
              " 'be': [1, 1, 1, 1, 1],\n",
              " 'or': [1, 1, 1],\n",
              " 'not': [1, 1, 1],\n",
              " 'be,': [1],\n",
              " 'and': [1, 1],\n",
              " 'are': [1],\n",
              " 'the': [1],\n",
              " 'same': [1],\n",
              " 'whatever': [1],\n",
              " 'who': [1],\n",
              " 'cares': [1]}"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2w3iWuUtl45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a134c037-6688-485a-eaf2-e17dcf134665"
      },
      "source": [
        "reduceByKey(lambda x, y: x + y, data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<map at 0x7bfedc3b14e0>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPginmvJtl45"
      },
      "source": [
        "## Parallelising MiniMapReduce\n",
        "\n",
        "- We can easily turn our Map-Reduce implementation into a parallel, multi-threaded framework\n",
        "by using the `my_map_multithreaded` function we defined earlier.\n",
        "\n",
        "- This will allow us to perform map-reduce computations that exploit parallel processing using *multiple* cores on a *single* computer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iBbyFVlOtl45"
      },
      "source": [
        "def reduceByKey_multithreaded(f, data):\n",
        "    key_values = groupByKey(data)\n",
        "    return my_map_multithreaded(\n",
        "        lambda key: (key, reduce(f, key_values[key])), key_values.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia87FJXAtl45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12ac3c7d-bc1e-4346-da2f-c2d440cd8921"
      },
      "source": [
        "%time\n",
        "data1 = map(lambda x: (x, 1), \"to be or not to be, or to be and not to be are the same whatever to be or not to be and who cares\".split())\n",
        "data1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
            "Wall time: 5.72 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<map at 0x7bfedc10e5c0>"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reduceByKey_multithreaded(lambda x, y: x + y, data1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6iIcvvZeGv_",
        "outputId": "28a5310c-0677-4e5c-baf0-208ede6e864f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scheduling jobs.. \n",
            "Starting jobs.. \n",
            "Waiting for jobs to finish.. \n",
            "All done.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIKtbfKvtl46"
      },
      "source": [
        "## Parallelising the reduce step\n",
        "\n",
        "- Provided that our operator is both associative and commutative we can\n",
        "also parallelise the reduce operation.\n",
        "\n",
        "- We partition the data into approximately equal subsets.\n",
        "\n",
        "- We then reduce each subset independently on a separate core.\n",
        "\n",
        "- The results can be combined in a final reduce step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kZAFCPstl46"
      },
      "source": [
        "### Partitioning the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9bWNqmxtl46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5f97453-898e-422c-ac5e-71f4ee937faf"
      },
      "source": [
        "def split_data(data, split_points):\n",
        "    partitions = []\n",
        "    n = 0\n",
        "    for i in split_points:\n",
        "        partitions.append(data[n:i])\n",
        "        n = i\n",
        "    partitions.append(data[n:])\n",
        "    return partitions\n",
        "\n",
        "data = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k']\n",
        "partitioned_data = split_data(data, [3])\n",
        "partitioned_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['a', 'b', 'c'], ['d', 'e', 'f', 'g', 'h', 'i', 'j', 'k']]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQpZUXBYtl46"
      },
      "source": [
        "### Reducing across partitions in parallel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IU5D3SC_tl46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "05f1b850-dc07-4347-c855-cfec5473e9ad"
      },
      "source": [
        "from threading import Thread\n",
        "\n",
        "def parallel_reduce(f, partitions):\n",
        "\n",
        "    n = len(partitions)\n",
        "    results = [None] * n\n",
        "    threads = [None] * n\n",
        "\n",
        "    def job(i):\n",
        "        results[i] = reduce(f, partitions[i])\n",
        "\n",
        "    for i in range(n):\n",
        "        threads[i] = Thread(target = lambda: job(i))\n",
        "        threads[i].start()\n",
        "\n",
        "    for i in range(n):\n",
        "        threads[i].join()\n",
        "\n",
        "    return reduce(f, results)\n",
        "\n",
        "parallel_reduce(lambda x, y: x + y, partitioned_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abcdefghijk'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2wM_1F2tl46"
      },
      "source": [
        "## Map-Reduce on a cluster of computers\n",
        "\n",
        "- The code we have written so far will *not* allow us to exploit parallelism from multiple computers in a [cluster](https://en.wikipedia.org/wiki/Computer_cluster).\n",
        "\n",
        "- Developing such a framework would be a very large software engineering project.\n",
        "\n",
        "- There are existing frameworks we can use:\n",
        "    - [Apache Hadoop](https://hadoop.apache.org/)\n",
        "    - [Apache Spark](https://spark.apache.org/)\n",
        "    \n",
        "- In our program, we will mostly focus on Apache Spark."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise\n",
        "\n",
        "Given that we have a list of numbers and we want to calculate the sum of squares of these numbers. We'll first use `map` to square each number, then use `reduce` to sum up the squares. Finally, please parallelize the process using multithreading for potentially faster execution."
      ],
      "metadata": {
        "id": "nv7ZLjGXLD4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Sequential version (map + reduce)\n",
        "from functools import reduce\n",
        "\n",
        "numbers = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Step 1: square each number using map\n",
        "squared = map(lambda x: x ** 2, numbers)\n",
        "\n",
        "# Step 2: sum the squares using reduce\n",
        "sum_of_squares = reduce(lambda a, b: a + b, squared)\n",
        "\n",
        "print(sum_of_squares)\n"
      ],
      "metadata": {
        "id": "UG42YVWDLDRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f969d0c1-9f1e-40b6-8a38-ced046688ea5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF-FeXiiC_eM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac748f2-def7-4634-fb28-af5e9c5ef17d"
      },
      "source": [
        "# 2. Parallelized version using multithreading\n",
        "from functools import reduce\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def square(x):\n",
        "    return x ** 2\n",
        "\n",
        "numbers = [1, 2, 3, 4, 5]\n",
        "\n",
        "# Step 1: parallel map using threads\n",
        "with ThreadPoolExecutor(max_workers=4) as executor:\n",
        "    squared = executor.map(square, numbers)\n",
        "\n",
        "# Step 2: reduce to sum the results\n",
        "sum_of_squares = reduce(lambda a, b: a + b, squared)\n",
        "\n",
        "print(sum_of_squares)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "55\n"
          ]
        }
      ]
    }
  ]
}