{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyri0n11/distributed-system/blob/main/lab6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise I\n",
        "\n",
        "The input is a textual csv file containing the daily value of PM10 for a set of sensors, and in each line of the files has the following format:\n",
        "```sensorId,date,PM10 value (Î¼g/m3)\\n```\n",
        "\n",
        "Here is the example of data:\n",
        "```\n",
        "s1,2016-01-01,20.5\n",
        "s2,2016-01-01,30.1\n",
        "s1,2016-01-02,60.2\n",
        "s2,2016-01-02,20.4\n",
        "s1,2016-01-03,55.5\n",
        "s2,2016-01-03,52.5\n",
        "```\n",
        "\n",
        "You're required to use pyspark to load the file, filter the values and use map/reduce code idea to give the output. The output is a line for each sensor on the standard output.\n",
        "Each line contains a `sensorId` and the list of `dates` with a PM10 values greater than 50 for that sensor. The example output:\n",
        "```\n",
        "(s1, [2016-01-02, 2016-01-03])\n",
        "(s2, [2016-01-03])\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "8H58RnChZq0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise II\n",
        "\n",
        "Using the same data of the Exercise I, you're required to get the output: sensors ordered by the number of critical days. Each line of the output contains the number of days with a PM10 values greater than 50 for a sensor `s` and the `sensorId` of sensor `s`.\n",
        "\n",
        "The example of the output:\n",
        "```\n",
        "2, s1\n",
        "1, s2\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Jgu0vQKVbqDf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise III\n",
        "\n",
        "In this exercise, you're given an input: A CSV file containing a list of profiles\n",
        "\n",
        "- Header: `name,age,gender`\n",
        "- Each line of the file contains the information about one user\n",
        "\n",
        "The example of input data\n",
        "```\n",
        "name,surname,age\n",
        "Paolo,Garza,42\n",
        "Luca,Boccia,41\n",
        "Maura,Bianchi,16\n",
        "```\n",
        "\n",
        "You're required to use pyspark to load and analyze the data to achieve the output: A CSV file containing one line for each profile. The original age attribute is substituted with a new attributed called rangeage of type String.\n",
        "```\n",
        "rangeage = \"[\" + (age/10)*10 + \"-\" + (age/10)*10+9 + \"]\"\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ADGjGNWKePfN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "igKez2B6aPe0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}