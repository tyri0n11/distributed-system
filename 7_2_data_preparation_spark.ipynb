{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyri0n11/distributed-system/blob/main/7_2_data_preparation_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef3J63Uke14M"
      },
      "source": [
        "# `StringIndexer` and `OneHotEncoder`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UJgVwv-atT8"
      },
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "sc = SparkContext(conf=SparkConf())\n",
        "spark = SparkSession(sparkContext=sc)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m37etkvQa1bj"
      },
      "source": [
        "# Example data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyJ5XVFGatqv",
        "outputId": "91234f47-699f-4614-d4c8-f1d6854c6cc7"
      },
      "source": [
        "import pandas as pd\n",
        "pdf = pd.DataFrame({\n",
        "        'x1': ['a','a','b','b', 'b', 'c'],\n",
        "        'x2': ['apple', 'orange', 'orange','orange', 'peach', 'peach'],\n",
        "        'x3': [1, 1, 2, 2, 2, 4],\n",
        "        'x4': [2.4, 2.5, 3.5, 1.4, 2.1,1.5],\n",
        "        'y1': [1, 0, 1, 0, 0, 1],\n",
        "        'y2': ['yes', 'no', 'no', 'yes', 'yes', 'yes']\n",
        "    })\n",
        "# `pdf` is pandas dataframe while `df` is Spark dataframe\n",
        "df = spark.createDataFrame(pdf)\n",
        "df.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+\n",
            "| x1|    x2| x3| x4| y1| y2|\n",
            "+---+------+---+---+---+---+\n",
            "|  a| apple|  1|2.4|  1|yes|\n",
            "|  a|orange|  1|2.5|  0| no|\n",
            "|  b|orange|  2|3.5|  1| no|\n",
            "|  b|orange|  2|1.4|  0|yes|\n",
            "|  b| peach|  2|2.1|  0|yes|\n",
            "|  c| peach|  4|1.5|  1|yes|\n",
            "+---+------+---+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Type of pdf', type(pdf))\n",
        "print('Type of df', type(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgtkzuwks7DI",
        "outputId": "498b4847-0386-4c35-96a6-7ed3c03d77a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of pdf <class 'pandas.core.frame.DataFrame'>\n",
            "Type of df <class 'pyspark.sql.classic.dataframe.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rom_jfRSa9dl"
      },
      "source": [
        "# StringIndexer\n",
        "\n",
        "`StringIndexer` maps a string column to a index column that will be treated as a categorical column by spark. **The indices start with 0 and are ordered by label frequencies**. If it is a numerical column, the column will first be casted to a string column and then indexed by  StringIndexer.\n",
        "\n",
        "There are three steps to implement the StringIndexer\n",
        "\n",
        "1. Build the StringIndexer model: specify the input column and output column names.\n",
        "2. Learn the StringIndexer model: fit the model with your data.\n",
        "3. Execute the indexing: call the transform function to execute the indexing process.\n",
        "\n",
        "### Example: `StringIndex` column \"x1\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr74TF0Oattg",
        "outputId": "8bea7cec-a73a-48b5-d404-78556ac0a490"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# build indexer\n",
        "string_indexer = StringIndexer(inputCol='x1', outputCol='indexed_x1')\n",
        "\n",
        "# learn the model\n",
        "string_indexer_model = string_indexer.fit(df)\n",
        "\n",
        "# transform the data\n",
        "df_stringindexer = string_indexer_model.transform(df)\n",
        "\n",
        "# resulting df\n",
        "df_stringindexer.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+----------+\n",
            "| x1|    x2| x3| x4| y1| y2|indexed_x1|\n",
            "+---+------+---+---+---+---+----------+\n",
            "|  a| apple|  1|2.4|  1|yes|       1.0|\n",
            "|  a|orange|  1|2.5|  0| no|       1.0|\n",
            "|  b|orange|  2|3.5|  1| no|       0.0|\n",
            "|  b|orange|  2|1.4|  0|yes|       0.0|\n",
            "|  b| peach|  2|2.1|  0|yes|       0.0|\n",
            "|  c| peach|  4|1.5|  1|yes|       2.0|\n",
            "+---+------+---+---+---+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Your task `StringIndex` column \"x2\""
      ],
      "metadata": {
        "id": "-lgrM5cevD2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "# build indexer\n",
        "string_indexer_2 = StringIndexer(inputCol='x2', outputCol='indexed_x2')\n",
        "# learn the model\n",
        "string_indexer_model_2 = string_indexer_2.fit(df)\n",
        "# transform the data\n",
        "df_stringindexer = string_indexer_model_2.transform(df)\n",
        "# resulting df\n",
        "df_stringindexer.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQIB28uBvKdm",
        "outputId": "85aacf11-c997-4151-aa53-3dfebb1a2b96"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+----------+\n",
            "| x1|    x2| x3| x4| y1| y2|indexed_x2|\n",
            "+---+------+---+---+---+---+----------+\n",
            "|  a| apple|  1|2.4|  1|yes|       2.0|\n",
            "|  a|orange|  1|2.5|  0| no|       0.0|\n",
            "|  b|orange|  2|3.5|  1| no|       0.0|\n",
            "|  b|orange|  2|1.4|  0|yes|       0.0|\n",
            "|  b| peach|  2|2.1|  0|yes|       1.0|\n",
            "|  c| peach|  4|1.5|  1|yes|       1.0|\n",
            "+---+------+---+---+---+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QAwN0gu1vlh7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q09eR6hNbJ4X"
      },
      "source": [
        "From the result above, we can see that (a, b, c) in column x1 are converted to (1.0, 0.0, 2.0). They are ordered by their frequencies in column x1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-aFv1K_bJ7H"
      },
      "source": [
        "## OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VhH9d-ybJ-N"
      },
      "source": [
        "**`OneHotEncoder`** converts each categories of a **StringIndexed** column to a `sparse vector`. Each sparse vector has **at most one single active elements** that indicate the category index."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7zMQ4Oyv7UK",
        "outputId": "7ffa377c-c52e-49a5-d660-8ad3b4ec3d6f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+\n",
            "| x1|    x2| x3| x4| y1| y2|\n",
            "+---+------+---+---+---+---+\n",
            "|  a| apple|  1|2.4|  1|yes|\n",
            "|  a|orange|  1|2.5|  0| no|\n",
            "|  b|orange|  2|3.5|  1| no|\n",
            "|  b|orange|  2|1.4|  0|yes|\n",
            "|  b| peach|  2|2.1|  0|yes|\n",
            "+---+------+---+---+---+---+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or9TkUeXatvv",
        "outputId": "cf598276-e224-40a3-f9c3-ddacc8b47333"
      },
      "source": [
        "df_ohe = df.select('x1')\n",
        "df_ohe.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| x1|\n",
            "+---+\n",
            "|  a|\n",
            "|  a|\n",
            "|  b|\n",
            "|  b|\n",
            "|  b|\n",
            "|  c|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFm04i8AbTfY"
      },
      "source": [
        "### `StringIndex` column 'x1'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D21fB0GatzE",
        "outputId": "5ca8ba05-6b3b-4cc1-aff9-18fc672dd4db"
      },
      "source": [
        "df_x1_indexed = StringIndexer(inputCol='x1', outputCol='indexed_x1').fit(df_ohe).transform(df_ohe)\n",
        "df_x1_indexed.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+\n",
            "| x1|indexed_x1|\n",
            "+---+----------+\n",
            "|  a|       1.0|\n",
            "|  a|       1.0|\n",
            "|  b|       0.0|\n",
            "|  b|       0.0|\n",
            "|  b|       0.0|\n",
            "|  c|       2.0|\n",
            "+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsHb_WbJbYUn"
      },
      "source": [
        "'x1' has three categories: 'a', 'b' and 'c',  which corresponding string indices 1.0, 0.0 and 2.0, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A26L03v2bYXQ"
      },
      "source": [
        "### Mapping string indices to sparse vectors\n",
        "\n",
        "* Encoding format: 'string index': ['string indices vector size', 'index of string index in string indices vector', **1.0** ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuFjx-kObYai"
      },
      "source": [
        "Here the string indices vector is `[0.0, 1.0, 2.0]`. Therefore, the mapping between string indices and sparse vectors are:\n",
        "* `0.0: [3, [0], [1.0]]`\n",
        "* `1.0: [3, [1], [1.0]]`\n",
        "* `2.0: [3, [2], [1.0]]`\n",
        "\n",
        "After we convert all sparse vectors to dense vectors, we get:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC9zDWhMat1R",
        "outputId": "8dfd038b-cae9-48ea-a095-84984b2b4fe9"
      },
      "source": [
        "from pyspark.ml.linalg import DenseVector, SparseVector, DenseMatrix, SparseMatrix\n",
        "x = [SparseVector(3, {0: 1.0}).toArray()] + \\\n",
        "    [SparseVector(3, {1: 1.0}).toArray()] + \\\n",
        "    [SparseVector(3, {2: 1.0}).toArray()]\n",
        "\n",
        "import numpy as np\n",
        "np.array(x)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVbgtDBzbpTs"
      },
      "source": [
        "**The obtained matrix is exactly the matrix that we would use to represent our categorical variable in a statistical class**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDYvaXZEbpWq"
      },
      "source": [
        "### One more step to go\n",
        "\n",
        "`OneHotEncoder` by default will drop the last category. So the **string indices vector** becomes `[0.0, 1.0]`, and the mappings between string indices and sparse vectors are:\n",
        "\n",
        "* `0.0: [2, [0], [1.0]]`\n",
        "* `1.0: [2, [1], [1.0]]`\n",
        "* `2.0: [2, [], []]`\n",
        "\n",
        "We use a sparse vector that has **no active element**(basically all elements are 0's) to represent the last category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws0oqTKkbpZK"
      },
      "source": [
        "# Verify\n",
        "\n",
        "### OneHotEncode column 'indexed_x1'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZuADf7iat8D"
      },
      "source": [
        "from pyspark.ml.feature import OneHotEncoder"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# review `df_x1_indexed`, what is it?\n",
        "df_x1_indexed.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFOkG6uQ652t",
        "outputId": "99cbd124-5d0a-4dd2-c7c5-d2a0edd6178c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+\n",
            "| x1|indexed_x1|\n",
            "+---+----------+\n",
            "|  a|       1.0|\n",
            "|  a|       1.0|\n",
            "|  b|       0.0|\n",
            "|  b|       0.0|\n",
            "|  b|       0.0|\n",
            "+---+----------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UozxlA0cb3Nm",
        "outputId": "a601cc64-dc71-4c1c-c372-2be1a053f6bf"
      },
      "source": [
        "OneHotEncoder(inputCol='indexed_x1', outputCol='encoded_x1').fit(df_x1_indexed).transform(df_x1_indexed).show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-------------+\n",
            "| x1|indexed_x1|   encoded_x1|\n",
            "+---+----------+-------------+\n",
            "|  a|       1.0|(2,[1],[1.0])|\n",
            "|  a|       1.0|(2,[1],[1.0])|\n",
            "|  b|       0.0|(2,[0],[1.0])|\n",
            "|  b|       0.0|(2,[0],[1.0])|\n",
            "|  b|       0.0|(2,[0],[1.0])|\n",
            "|  c|       2.0|    (2,[],[])|\n",
            "+---+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YITbqgAgecCF"
      },
      "source": [
        "### Specify to not drop the last category\n",
        "\n",
        "If we choose to not drop the last category, we get the expected results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6y1gArnb3Qw",
        "outputId": "65b1b3eb-6fbe-4df2-ce81-f83c56b20cab"
      },
      "source": [
        "OneHotEncoder(dropLast=False, inputCol='indexed_x1', outputCol='encoded_x1').fit(df_x1_indexed).transform(df_x1_indexed).show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-------------+\n",
            "| x1|indexed_x1|   encoded_x1|\n",
            "+---+----------+-------------+\n",
            "|  a|       1.0|(3,[1],[1.0])|\n",
            "|  a|       1.0|(3,[1],[1.0])|\n",
            "|  b|       0.0|(3,[0],[1.0])|\n",
            "|  b|       0.0|(3,[0],[1.0])|\n",
            "|  b|       0.0|(3,[0],[1.0])|\n",
            "|  c|       2.0|(3,[2],[1.0])|\n",
            "+---+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "**Do the same OneHotEncoder for the columns `x2` and `y2`**"
      ],
      "metadata": {
        "id": "OpfroL2gf3bY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw65oYrcb3Ss",
        "outputId": "d323dbf9-72a1-4c7b-f3b0-f42d9db8d151",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "OneHotEncoder(dropLast=False, inputCol='indexed_x2', outputCol='encoded_x2').fit(df_stringindexer).transform(df_stringindexer).show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+----------+-------------+\n",
            "| x1|    x2| x3| x4| y1| y2|indexed_x2|   encoded_x2|\n",
            "+---+------+---+---+---+---+----------+-------------+\n",
            "|  a| apple|  1|2.4|  1|yes|       2.0|(3,[2],[1.0])|\n",
            "|  a|orange|  1|2.5|  0| no|       0.0|(3,[0],[1.0])|\n",
            "|  b|orange|  2|3.5|  1| no|       0.0|(3,[0],[1.0])|\n",
            "|  b|orange|  2|1.4|  0|yes|       0.0|(3,[0],[1.0])|\n",
            "|  b| peach|  2|2.1|  0|yes|       1.0|(3,[1],[1.0])|\n",
            "|  c| peach|  4|1.5|  1|yes|       1.0|(3,[1],[1.0])|\n",
            "+---+------+---+---+---+---+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_y2_indexed = StringIndexer(\n",
        "    inputCol=\"y2\",\n",
        "    outputCol=\"indexed_y2\"\n",
        ").fit(df).transform(df)\n",
        "\n",
        "OneHotEncoder(dropLast=False, inputCol='indexed_y2', outputCol='encoded_y2').fit(df_y2_indexed).transform(df_y2_indexed).show()\n"
      ],
      "metadata": {
        "id": "bnSCmYWHuQVl",
        "outputId": "34da6f5a-ffdb-42bf-e1cd-02267fac5af3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+----------+-------------+\n",
            "| x1|    x2| x3| x4| y1| y2|indexed_y2|   encoded_y2|\n",
            "+---+------+---+---+---+---+----------+-------------+\n",
            "|  a| apple|  1|2.4|  1|yes|       0.0|(2,[0],[1.0])|\n",
            "|  a|orange|  1|2.5|  0| no|       1.0|(2,[1],[1.0])|\n",
            "|  b|orange|  2|3.5|  1| no|       1.0|(2,[1],[1.0])|\n",
            "|  b|orange|  2|1.4|  0|yes|       0.0|(2,[0],[1.0])|\n",
            "|  b| peach|  2|2.1|  0|yes|       0.0|(2,[0],[1.0])|\n",
            "|  c| peach|  4|1.5|  1|yes|       0.0|(2,[0],[1.0])|\n",
            "+---+------+---+---+---+---+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddY5V8VXfuxc"
      },
      "source": [
        "# Vector assembler\n",
        "\n",
        "## Example data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph7SsboWb3Vz",
        "outputId": "8a418273-957c-401c-91a2-1c9d764c48c3"
      },
      "source": [
        "import pandas as pd\n",
        "pdf = pd.DataFrame({\n",
        "        'x1': ['a','a','b','b', 'b', 'c'],\n",
        "        'x2': ['apple', 'orange', 'orange','orange', 'peach', 'peach'],\n",
        "        'x3': [1, 1, 2, 2, 2, 4],\n",
        "        'x4': [2.4, 2.5, 3.5, 1.4, 2.1,1.5],\n",
        "        'y1': [1, 0, 1, 0, 0, 1],\n",
        "        'y2': ['yes', 'no', 'no', 'yes', 'yes', 'yes']\n",
        "    })\n",
        "df = spark.createDataFrame(pdf)\n",
        "df.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+\n",
            "| x1|    x2| x3| x4| y1| y2|\n",
            "+---+------+---+---+---+---+\n",
            "|  a| apple|  1|2.4|  1|yes|\n",
            "|  a|orange|  1|2.5|  0| no|\n",
            "|  b|orange|  2|3.5|  1| no|\n",
            "|  b|orange|  2|1.4|  0|yes|\n",
            "|  b| peach|  2|2.1|  0|yes|\n",
            "|  c| peach|  4|1.5|  1|yes|\n",
            "+---+------+---+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6gUwqSJf8h4"
      },
      "source": [
        "# VectorAssembler\n",
        "\n",
        "To fit a ML model in pyspark, we need to combine all feature columns into one single column of vectors: the **featuresCol**. The `VectorAssembler` can be used to combine multiple **`OneHotEncoder` columns** and **other continuous variable columns** into one single column.\n",
        "\n",
        "The example below shows how to combine three OneHotEncoder columns and one numeric column into a **featureCol** column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp7oT4vvf-WG"
      },
      "source": [
        "## StringIndex and OneHotEncode categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcAhLCUkb3YB"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGqs4THGb3ak",
        "outputId": "dcb5e265-e302-42e6-d479-665888a7b195"
      },
      "source": [
        "all_stages = [StringIndexer(inputCol=c, outputCol='idx_' + c) for c in ['x1', 'x2', 'x3']] + \\\n",
        "             [OneHotEncoder(inputCol='idx_' + c, outputCol='ohe_' + c) for c in ['x1', 'x2', 'x3']]\n",
        "all_stages"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StringIndexer_7c0afdfc310f,\n",
              " StringIndexer_e6994ccda426,\n",
              " StringIndexer_022f2757c433,\n",
              " OneHotEncoder_8e6fbb462af6,\n",
              " OneHotEncoder_2aeb2bdb8528,\n",
              " OneHotEncoder_10fc6185d9ed]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A92-NF0Pat-m",
        "outputId": "a5343030-30e6-4176-b938-b2c6e05c8d8b"
      },
      "source": [
        "df_new = Pipeline(stages=all_stages).fit(df).transform(df)\n",
        "df_new.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+------+------+------+-------------+-------------+-------------+\n",
            "| x1|    x2| x3| x4| y1| y2|idx_x1|idx_x2|idx_x3|       ohe_x1|       ohe_x2|       ohe_x3|\n",
            "+---+------+---+---+---+---+------+------+------+-------------+-------------+-------------+\n",
            "|  a| apple|  1|2.4|  1|yes|   1.0|   2.0|   1.0|(2,[1],[1.0])|    (2,[],[])|(2,[1],[1.0])|\n",
            "|  a|orange|  1|2.5|  0| no|   1.0|   0.0|   1.0|(2,[1],[1.0])|(2,[0],[1.0])|(2,[1],[1.0])|\n",
            "|  b|orange|  2|3.5|  1| no|   0.0|   0.0|   0.0|(2,[0],[1.0])|(2,[0],[1.0])|(2,[0],[1.0])|\n",
            "|  b|orange|  2|1.4|  0|yes|   0.0|   0.0|   0.0|(2,[0],[1.0])|(2,[0],[1.0])|(2,[0],[1.0])|\n",
            "|  b| peach|  2|2.1|  0|yes|   0.0|   1.0|   0.0|(2,[0],[1.0])|(2,[1],[1.0])|(2,[0],[1.0])|\n",
            "|  c| peach|  4|1.5|  1|yes|   2.0|   1.0|   2.0|    (2,[],[])|(2,[1],[1.0])|    (2,[],[])|\n",
            "+---+------+---+---+---+---+------+------+------+-------------+-------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K2_vP5qgOhf"
      },
      "source": [
        "## Assemble feature columns into one single **feacturesCol** with **`VectorAssembler`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "023kdI6bgK8L",
        "outputId": "72723c92-e33d-43bd-bf0b-5a1428ae5b52"
      },
      "source": [
        "df_assembled = VectorAssembler(inputCols=['ohe_x1', 'ohe_x2', 'ohe_x3', 'x4'], outputCol='featuresCol')\\\n",
        "    .transform(df_new)\\\n",
        "    .drop('idx_x1', 'idx_x2', 'idx_x3')\n",
        "df_assembled.show(truncate=False)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+-------------+-------------+-------------+-----------------------------+\n",
            "|x1 |x2    |x3 |x4 |y1 |y2 |ohe_x1       |ohe_x2       |ohe_x3       |featuresCol                  |\n",
            "+---+------+---+---+---+---+-------------+-------------+-------------+-----------------------------+\n",
            "|a  |apple |1  |2.4|1  |yes|(2,[1],[1.0])|(2,[],[])    |(2,[1],[1.0])|(7,[1,5,6],[1.0,1.0,2.4])    |\n",
            "|a  |orange|1  |2.5|0  |no |(2,[1],[1.0])|(2,[0],[1.0])|(2,[1],[1.0])|[0.0,1.0,1.0,0.0,0.0,1.0,2.5]|\n",
            "|b  |orange|2  |3.5|1  |no |(2,[0],[1.0])|(2,[0],[1.0])|(2,[0],[1.0])|[1.0,0.0,1.0,0.0,1.0,0.0,3.5]|\n",
            "|b  |orange|2  |1.4|0  |yes|(2,[0],[1.0])|(2,[0],[1.0])|(2,[0],[1.0])|[1.0,0.0,1.0,0.0,1.0,0.0,1.4]|\n",
            "|b  |peach |2  |2.1|0  |yes|(2,[0],[1.0])|(2,[1],[1.0])|(2,[0],[1.0])|[1.0,0.0,0.0,1.0,1.0,0.0,2.1]|\n",
            "|c  |peach |4  |1.5|1  |yes|(2,[],[])    |(2,[1],[1.0])|(2,[],[])    |(7,[3,6],[1.0,1.5])          |\n",
            "+---+------+---+---+---+---+-------------+-------------+-------------+-----------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5loOVu0gTb_"
      },
      "source": [
        "## Convert sparse vectors in featuresCol to dense vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBXnLcxQgLZ7"
      },
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.ml.linalg import SparseVector, DenseVector"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kFoNLNEgLco"
      },
      "source": [
        "def dense_features_col(x):\n",
        "    return(x.toArray().dtype)\n",
        "dense_features_col_udf = udf(dense_features_col, returnType=StringType())"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m8EOR7_PtRVA"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoHGEeBLgLgw",
        "outputId": "a07fc5f0-4308-40a1-c68a-be1efa001c32"
      },
      "source": [
        "df_assembled.rdd.map(lambda x: x['featuresCol']).take(6)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SparseVector(7, {1: 1.0, 5: 1.0, 6: 2.4}),\n",
              " DenseVector([0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.5]),\n",
              " DenseVector([1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.5]),\n",
              " DenseVector([1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.4]),\n",
              " DenseVector([1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.1]),\n",
              " SparseVector(7, {3: 1.0, 6: 1.5})]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtYLdUhogZmB",
        "outputId": "123f892f-2bd2-414a-9b95-5a8108322d67"
      },
      "source": [
        "df_assembled.rdd.map(lambda x: list(x['featuresCol'].toArray())).take(6)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(2.4)],\n",
              " [np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(2.5)],\n",
              " [np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(3.5)],\n",
              " [np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.4)],\n",
              " [np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(2.1)],\n",
              " [np.float64(0.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.5)]]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef9g5bCrgbnn"
      },
      "source": [],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practice"
      ],
      "metadata": {
        "id": "pbrgMGKa1kWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pdf2 = pd.DataFrame({\n",
        "        'x1': ['a','a','b','b', 'b', 'c'],\n",
        "        'x2': ['apple', 'orange', 'orange','orange', 'peach', 'peach'],\n",
        "        'x3': [1, 1, 2, 2, 2, 4],\n",
        "        'x4': [2.4, 2.5, 3.5, 1.4, 2.1,1.5],\n",
        "        'x5': ['man', 'woman', 'man', 'man', 'man', 'woman'],\n",
        "        'x6': [10.3, 11.4, 45.3, 32.5, 13.8, 17.2],\n",
        "        'x7': ['911', '113', '115', '113', '911', '115'],\n",
        "        'y1': [1, 0, 1, 0, 0, 1],\n",
        "        'y2': ['yes', 'no', 'no', 'yes', 'yes', 'yes']\n",
        "    })\n",
        "df2 = spark.createDataFrame(pdf2)\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQS0WNid1mUX",
        "outputId": "034678d6-a55c-4488-833f-f23feda3dd69"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+-----+----+---+---+---+\n",
            "| x1|    x2| x3| x4|   x5|  x6| x7| y1| y2|\n",
            "+---+------+---+---+-----+----+---+---+---+\n",
            "|  a| apple|  1|2.4|  man|10.3|911|  1|yes|\n",
            "|  a|orange|  1|2.5|woman|11.4|113|  0| no|\n",
            "|  b|orange|  2|3.5|  man|45.3|115|  1| no|\n",
            "|  b|orange|  2|1.4|  man|32.5|113|  0|yes|\n",
            "|  b| peach|  2|2.1|  man|13.8|911|  0|yes|\n",
            "|  c| peach|  4|1.5|woman|17.2|115|  1|yes|\n",
            "+---+------+---+---+-----+----+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Your task: Please do the Assemble feature columns (of all categorical and numerical features) into one single **feacturesCol** with **`VectorAssembler`**\n",
        "**Hint: Categorical features (`x1`, `x2`, `x3`, `x5`, `x7`) and numerical features (`x4`, `x6`)**"
      ],
      "metadata": {
        "id": "iDtjTiFNleNx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j_XGN0nP2OaG"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise: Do the Assemble feature columns (of all categorical and numerical features) into one single **feacturesCol** with **`VectorAssembler`** for **`mtcars`** dataset"
      ],
      "metadata": {
        "id": "4kuUBb5FqXlg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise: Do the Assemble feature columns (of all categorical and numerical features) into one single **feacturesCol** with **`VectorAssembler`** for **`titanic`** dataset"
      ],
      "metadata": {
        "id": "BMAxLQaRoTHE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aeT87zREqhSO"
      },
      "execution_count": 23,
      "outputs": []
    }
  ]
}