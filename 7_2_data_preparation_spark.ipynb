{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyri0n11/distributed-system/blob/main/7_2_data_preparation_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef3J63Uke14M"
      },
      "source": [
        "# `StringIndexer` and `OneHotEncoder`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UJgVwv-atT8"
      },
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "sc = SparkContext(conf=SparkConf())\n",
        "spark = SparkSession(sparkContext=sc)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m37etkvQa1bj"
      },
      "source": [
        "# Example data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyJ5XVFGatqv",
        "outputId": "ecded650-d500-4c6d-95de-31e316e6e941"
      },
      "source": [
        "import pandas as pd\n",
        "pdf = pd.DataFrame({\n",
        "        'x1': ['a','a','b','b', 'b', 'c'],\n",
        "        'x2': ['apple', 'orange', 'orange','orange', 'peach', 'peach'],\n",
        "        'x3': [1, 1, 2, 2, 2, 4],\n",
        "        'x4': [2.4, 2.5, 3.5, 1.4, 2.1,1.5],\n",
        "        'y1': [1, 0, 1, 0, 0, 1],\n",
        "        'y2': ['yes', 'no', 'no', 'yes', 'yes', 'yes']\n",
        "    })\n",
        "# `pdf` is pandas dataframe while `df` is Spark dataframe\n",
        "df = spark.createDataFrame(pdf)\n",
        "df.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+\n",
            "| x1|    x2| x3| x4| y1| y2|\n",
            "+---+------+---+---+---+---+\n",
            "|  a| apple|  1|2.4|  1|yes|\n",
            "|  a|orange|  1|2.5|  0| no|\n",
            "|  b|orange|  2|3.5|  1| no|\n",
            "|  b|orange|  2|1.4|  0|yes|\n",
            "|  b| peach|  2|2.1|  0|yes|\n",
            "|  c| peach|  4|1.5|  1|yes|\n",
            "+---+------+---+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Type of pdf', type(pdf))\n",
        "print('Type of df', type(df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kgtkzuwks7DI",
        "outputId": "48fc4545-385e-4459-be03-f41f935cf0c8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of pdf <class 'pandas.core.frame.DataFrame'>\n",
            "Type of df <class 'pyspark.sql.classic.dataframe.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rom_jfRSa9dl"
      },
      "source": [
        "# StringIndexer\n",
        "\n",
        "`StringIndexer` maps a string column to a index column that will be treated as a categorical column by spark. **The indices start with 0 and are ordered by label frequencies**. If it is a numerical column, the column will first be casted to a string column and then indexed by  StringIndexer.\n",
        "\n",
        "There are three steps to implement the StringIndexer\n",
        "\n",
        "1. Build the StringIndexer model: specify the input column and output column names.\n",
        "2. Learn the StringIndexer model: fit the model with your data.\n",
        "3. Execute the indexing: call the transform function to execute the indexing process.\n",
        "\n",
        "### Example: `StringIndex` column \"x1\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr74TF0Oattg",
        "outputId": "4d878519-c945-4c96-b996-eea4f636fe8e"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "# build indexer\n",
        "string_indexer = StringIndexer(inputCol='x1', outputCol='indexed_x1')\n",
        "\n",
        "# learn the model\n",
        "string_indexer_model = string_indexer.fit(df)\n",
        "\n",
        "# transform the data\n",
        "df_stringindexer = string_indexer_model.transform(df)\n",
        "\n",
        "# resulting df\n",
        "df_stringindexer.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+----------+\n",
            "| x1|    x2| x3| x4| y1| y2|indexed_x1|\n",
            "+---+------+---+---+---+---+----------+\n",
            "|  a| apple|  1|2.4|  1|yes|       1.0|\n",
            "|  a|orange|  1|2.5|  0| no|       1.0|\n",
            "|  b|orange|  2|3.5|  1| no|       0.0|\n",
            "|  b|orange|  2|1.4|  0|yes|       0.0|\n",
            "|  b| peach|  2|2.1|  0|yes|       0.0|\n",
            "|  c| peach|  4|1.5|  1|yes|       2.0|\n",
            "+---+------+---+---+---+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Your task `StringIndex` column \"x2\""
      ],
      "metadata": {
        "id": "-lgrM5cevD2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "# build indexer\n",
        "string_indexer_2 = StringIndexer(inputCol='x2', outputCol='indexed_x2')\n",
        "# learn the model\n",
        "string_indexer_model_2 = string_indexer_2.fit(df)\n",
        "# transform the data\n",
        "df_stringindexer = string_indexer_model_2.transform(df)\n",
        "# resulting df\n",
        "df_stringindexer.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQIB28uBvKdm",
        "outputId": "f31a695c-f756-4eaa-d7c7-4e5eabad986e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+----------+\n",
            "| x1|    x2| x3| x4| y1| y2|indexed_x2|\n",
            "+---+------+---+---+---+---+----------+\n",
            "|  a| apple|  1|2.4|  1|yes|       2.0|\n",
            "|  a|orange|  1|2.5|  0| no|       0.0|\n",
            "|  b|orange|  2|3.5|  1| no|       0.0|\n",
            "|  b|orange|  2|1.4|  0|yes|       0.0|\n",
            "|  b| peach|  2|2.1|  0|yes|       1.0|\n",
            "|  c| peach|  4|1.5|  1|yes|       1.0|\n",
            "+---+------+---+---+---+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QAwN0gu1vlh7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q09eR6hNbJ4X"
      },
      "source": [
        "From the result above, we can see that (a, b, c) in column x1 are converted to (1.0, 0.0, 2.0). They are ordered by their frequencies in column x1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-aFv1K_bJ7H"
      },
      "source": [
        "## OneHotEncoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VhH9d-ybJ-N"
      },
      "source": [
        "**`OneHotEncoder`** converts each categories of a **StringIndexed** column to a `sparse vector`. Each sparse vector has **at most one single active elements** that indicate the category index."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7zMQ4Oyv7UK",
        "outputId": "79080a8b-c04f-42a9-fe10-f21876e4154a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+\n",
            "| x1|    x2| x3| x4| y1| y2|\n",
            "+---+------+---+---+---+---+\n",
            "|  a| apple|  1|2.4|  1|yes|\n",
            "|  a|orange|  1|2.5|  0| no|\n",
            "|  b|orange|  2|3.5|  1| no|\n",
            "|  b|orange|  2|1.4|  0|yes|\n",
            "|  b| peach|  2|2.1|  0|yes|\n",
            "+---+------+---+---+---+---+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or9TkUeXatvv",
        "outputId": "0d5f620e-dc0a-4bc5-df60-f8447b9f0529"
      },
      "source": [
        "df_ohe = df.select('x1')\n",
        "df_ohe.show()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+\n",
            "| x1|\n",
            "+---+\n",
            "|  a|\n",
            "|  a|\n",
            "|  b|\n",
            "|  b|\n",
            "|  b|\n",
            "|  c|\n",
            "+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFm04i8AbTfY"
      },
      "source": [
        "### `StringIndex` column 'x1'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6D21fB0GatzE",
        "outputId": "d00169cc-5e46-48f6-95f2-44a41e314e4e"
      },
      "source": [
        "df_x1_indexed = StringIndexer(inputCol='x1', outputCol='indexed_x1').fit(df_ohe).transform(df_ohe)\n",
        "df_x1_indexed.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+\n",
            "| x1|indexed_x1|\n",
            "+---+----------+\n",
            "|  a|       1.0|\n",
            "|  a|       1.0|\n",
            "|  b|       0.0|\n",
            "|  b|       0.0|\n",
            "|  b|       0.0|\n",
            "|  c|       2.0|\n",
            "+---+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsHb_WbJbYUn"
      },
      "source": [
        "'x1' has three categories: 'a', 'b' and 'c',  which corresponding string indices 1.0, 0.0 and 2.0, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A26L03v2bYXQ"
      },
      "source": [
        "### Mapping string indices to sparse vectors\n",
        "\n",
        "* Encoding format: 'string index': ['string indices vector size', 'index of string index in string indices vector', **1.0** ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OuFjx-kObYai"
      },
      "source": [
        "Here the string indices vector is `[0.0, 1.0, 2.0]`. Therefore, the mapping between string indices and sparse vectors are:\n",
        "* `0.0: [3, [0], [1.0]]`\n",
        "* `1.0: [3, [1], [1.0]]`\n",
        "* `2.0: [3, [2], [1.0]]`\n",
        "\n",
        "After we convert all sparse vectors to dense vectors, we get:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC9zDWhMat1R",
        "outputId": "784744c7-1aba-41f1-f58f-67a845cc51f5"
      },
      "source": [
        "from pyspark.ml.linalg import DenseVector, SparseVector, DenseMatrix, SparseMatrix\n",
        "x = [SparseVector(3, {0: 1.0}).toArray()] + \\\n",
        "    [SparseVector(3, {1: 1.0}).toArray()] + \\\n",
        "    [SparseVector(3, {2: 1.0}).toArray()]\n",
        "\n",
        "import numpy as np\n",
        "np.array(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVbgtDBzbpTs"
      },
      "source": [
        "**The obtained matrix is exactly the matrix that we would use to represent our categorical variable in a statistical class**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDYvaXZEbpWq"
      },
      "source": [
        "### One more step to go\n",
        "\n",
        "`OneHotEncoder` by default will drop the last category. So the **string indices vector** becomes `[0.0, 1.0]`, and the mappings between string indices and sparse vectors are:\n",
        "\n",
        "* `0.0: [2, [0], [1.0]]`\n",
        "* `1.0: [2, [1], [1.0]]`\n",
        "* `2.0: [2, [], []]`\n",
        "\n",
        "We use a sparse vector that has **no active element**(basically all elements are 0's) to represent the last category."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ws0oqTKkbpZK"
      },
      "source": [
        "# Verify\n",
        "\n",
        "### OneHotEncode column 'indexed_x1'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZuADf7iat8D"
      },
      "source": [
        "from pyspark.ml.feature import OneHotEncoder"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# review `df_x1_indexed`, what is it?\n",
        "df_x1_indexed.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yFOkG6uQ652t",
        "outputId": "37cf01a9-5002-4a1f-83c5-f5f1252bfb42"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+\n",
            "| x1|indexed_x1|\n",
            "+---+----------+\n",
            "|  a|       1.0|\n",
            "|  a|       1.0|\n",
            "|  b|       0.0|\n",
            "|  b|       0.0|\n",
            "|  b|       0.0|\n",
            "+---+----------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UozxlA0cb3Nm",
        "outputId": "9c7670c1-e685-4fc6-c4a8-adf66d01ae4c"
      },
      "source": [
        "OneHotEncoder(inputCol='indexed_x1', outputCol='encoded_x1').fit(df_x1_indexed).transform(df_x1_indexed).show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-------------+\n",
            "| x1|indexed_x1|   encoded_x1|\n",
            "+---+----------+-------------+\n",
            "|  a|       1.0|(2,[1],[1.0])|\n",
            "|  a|       1.0|(2,[1],[1.0])|\n",
            "|  b|       0.0|(2,[0],[1.0])|\n",
            "|  b|       0.0|(2,[0],[1.0])|\n",
            "|  b|       0.0|(2,[0],[1.0])|\n",
            "|  c|       2.0|    (2,[],[])|\n",
            "+---+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YITbqgAgecCF"
      },
      "source": [
        "### Specify to not drop the last category\n",
        "\n",
        "If we choose to not drop the last category, we get the expected results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6y1gArnb3Qw",
        "outputId": "f93e5333-1cc2-4588-e434-1a8aa7f94f32"
      },
      "source": [
        "OneHotEncoder(dropLast=False, inputCol='indexed_x1', outputCol='encoded_x1').fit(df_x1_indexed).transform(df_x1_indexed).show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+----------+-------------+\n",
            "| x1|indexed_x1|   encoded_x1|\n",
            "+---+----------+-------------+\n",
            "|  a|       1.0|(3,[1],[1.0])|\n",
            "|  a|       1.0|(3,[1],[1.0])|\n",
            "|  b|       0.0|(3,[0],[1.0])|\n",
            "|  b|       0.0|(3,[0],[1.0])|\n",
            "|  b|       0.0|(3,[0],[1.0])|\n",
            "|  c|       2.0|(3,[2],[1.0])|\n",
            "+---+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exercise:\n",
        "**Do the same OneHotEncoder for the columns `x2` and `y2`**"
      ],
      "metadata": {
        "id": "OpfroL2gf3bY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw65oYrcb3Ss",
        "outputId": "0c3f9bff-0592-4f35-aed1-24ae4cf27fc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "OneHotEncoder(dropLast=False, inputCol='indexed_x2', outputCol='encoded_x2').fit(df_stringindexer).transform(df_stringindexer).show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+----------+-------------+\n",
            "| x1|    x2| x3| x4| y1| y2|indexed_x2|   encoded_x2|\n",
            "+---+------+---+---+---+---+----------+-------------+\n",
            "|  a| apple|  1|2.4|  1|yes|       2.0|(3,[2],[1.0])|\n",
            "|  a|orange|  1|2.5|  0| no|       0.0|(3,[0],[1.0])|\n",
            "|  b|orange|  2|3.5|  1| no|       0.0|(3,[0],[1.0])|\n",
            "|  b|orange|  2|1.4|  0|yes|       0.0|(3,[0],[1.0])|\n",
            "|  b| peach|  2|2.1|  0|yes|       1.0|(3,[1],[1.0])|\n",
            "|  c| peach|  4|1.5|  1|yes|       1.0|(3,[1],[1.0])|\n",
            "+---+------+---+---+---+---+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_y2_indexed = StringIndexer(\n",
        "    inputCol=\"y2\",\n",
        "    outputCol=\"indexed_y2\"\n",
        ").fit(df).transform(df)\n",
        "\n",
        "OneHotEncoder(dropLast=False, inputCol='indexed_y2', outputCol='encoded_y2').fit(df_y2_indexed).transform(df_y2_indexed).show()\n"
      ],
      "metadata": {
        "id": "bnSCmYWHuQVl",
        "outputId": "24e15632-62f8-4135-8b4e-54904ecb0396",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+----------+-------------+\n",
            "| x1|    x2| x3| x4| y1| y2|indexed_y2|   encoded_y2|\n",
            "+---+------+---+---+---+---+----------+-------------+\n",
            "|  a| apple|  1|2.4|  1|yes|       0.0|(2,[0],[1.0])|\n",
            "|  a|orange|  1|2.5|  0| no|       1.0|(2,[1],[1.0])|\n",
            "|  b|orange|  2|3.5|  1| no|       1.0|(2,[1],[1.0])|\n",
            "|  b|orange|  2|1.4|  0|yes|       0.0|(2,[0],[1.0])|\n",
            "|  b| peach|  2|2.1|  0|yes|       0.0|(2,[0],[1.0])|\n",
            "|  c| peach|  4|1.5|  1|yes|       0.0|(2,[0],[1.0])|\n",
            "+---+------+---+---+---+---+----------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddY5V8VXfuxc"
      },
      "source": [
        "# Vector assembler\n",
        "\n",
        "## Example data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph7SsboWb3Vz",
        "outputId": "f0e9f8b6-63f8-4c78-a155-e95b11c2d007"
      },
      "source": [
        "import pandas as pd\n",
        "pdf = pd.DataFrame({\n",
        "        'x1': ['a','a','b','b', 'b', 'c'],\n",
        "        'x2': ['apple', 'orange', 'orange','orange', 'peach', 'peach'],\n",
        "        'x3': [1, 1, 2, 2, 2, 4],\n",
        "        'x4': [2.4, 2.5, 3.5, 1.4, 2.1,1.5],\n",
        "        'y1': [1, 0, 1, 0, 0, 1],\n",
        "        'y2': ['yes', 'no', 'no', 'yes', 'yes', 'yes']\n",
        "    })\n",
        "df = spark.createDataFrame(pdf)\n",
        "df.show()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+\n",
            "| x1|    x2| x3| x4| y1| y2|\n",
            "+---+------+---+---+---+---+\n",
            "|  a| apple|  1|2.4|  1|yes|\n",
            "|  a|orange|  1|2.5|  0| no|\n",
            "|  b|orange|  2|3.5|  1| no|\n",
            "|  b|orange|  2|1.4|  0|yes|\n",
            "|  b| peach|  2|2.1|  0|yes|\n",
            "|  c| peach|  4|1.5|  1|yes|\n",
            "+---+------+---+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6gUwqSJf8h4"
      },
      "source": [
        "# VectorAssembler\n",
        "\n",
        "To fit a ML model in pyspark, we need to combine all feature columns into one single column of vectors: the **featuresCol**. The `VectorAssembler` can be used to combine multiple **`OneHotEncoder` columns** and **other continuous variable columns** into one single column.\n",
        "\n",
        "The example below shows how to combine three OneHotEncoder columns and one numeric column into a **featureCol** column.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vp7oT4vvf-WG"
      },
      "source": [
        "## StringIndex and OneHotEncode categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcAhLCUkb3YB"
      },
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml import Pipeline"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGqs4THGb3ak",
        "outputId": "03ea3dc2-67c0-479a-e03c-4ce1895636d6"
      },
      "source": [
        "all_stages = [StringIndexer(inputCol=c, outputCol='idx_' + c) for c in ['x1', 'x2', 'x3']] + \\\n",
        "             [OneHotEncoder(inputCol='idx_' + c, outputCol='ohe_' + c) for c in ['x1', 'x2', 'x3']]\n",
        "all_stages"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[StringIndexer_fd5099100084,\n",
              " StringIndexer_e78869b60e6d,\n",
              " StringIndexer_de44d43ad2ec,\n",
              " OneHotEncoder_188440c8fa87,\n",
              " OneHotEncoder_fbbbbe8a4229,\n",
              " OneHotEncoder_d7b52d89d51e]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A92-NF0Pat-m",
        "outputId": "cccd3d86-7b19-4d45-a861-ecfb43e9d588"
      },
      "source": [
        "df_new = Pipeline(stages=all_stages).fit(df).transform(df)\n",
        "df_new.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+------+------+------+-------------+-------------+-------------+\n",
            "| x1|    x2| x3| x4| y1| y2|idx_x1|idx_x2|idx_x3|       ohe_x1|       ohe_x2|       ohe_x3|\n",
            "+---+------+---+---+---+---+------+------+------+-------------+-------------+-------------+\n",
            "|  a| apple|  1|2.4|  1|yes|   1.0|   2.0|   1.0|(2,[1],[1.0])|    (2,[],[])|(2,[1],[1.0])|\n",
            "|  a|orange|  1|2.5|  0| no|   1.0|   0.0|   1.0|(2,[1],[1.0])|(2,[0],[1.0])|(2,[1],[1.0])|\n",
            "|  b|orange|  2|3.5|  1| no|   0.0|   0.0|   0.0|(2,[0],[1.0])|(2,[0],[1.0])|(2,[0],[1.0])|\n",
            "|  b|orange|  2|1.4|  0|yes|   0.0|   0.0|   0.0|(2,[0],[1.0])|(2,[0],[1.0])|(2,[0],[1.0])|\n",
            "|  b| peach|  2|2.1|  0|yes|   0.0|   1.0|   0.0|(2,[0],[1.0])|(2,[1],[1.0])|(2,[0],[1.0])|\n",
            "|  c| peach|  4|1.5|  1|yes|   2.0|   1.0|   2.0|    (2,[],[])|(2,[1],[1.0])|    (2,[],[])|\n",
            "+---+------+---+---+---+---+------+------+------+-------------+-------------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0K2_vP5qgOhf"
      },
      "source": [
        "## Assemble feature columns into one single **feacturesCol** with **`VectorAssembler`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "023kdI6bgK8L",
        "outputId": "1cce44e3-27f8-4585-ba92-a1c1220d7cac"
      },
      "source": [
        "df_assembled = VectorAssembler(inputCols=['ohe_x1', 'ohe_x2', 'ohe_x3', 'x4'], outputCol='featuresCol')\\\n",
        "    .transform(df_new)\\\n",
        "    .drop('idx_x1', 'idx_x2', 'idx_x3')\n",
        "df_assembled.show(truncate=False)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+---+---+-------------+-------------+-------------+-----------------------------+\n",
            "|x1 |x2    |x3 |x4 |y1 |y2 |ohe_x1       |ohe_x2       |ohe_x3       |featuresCol                  |\n",
            "+---+------+---+---+---+---+-------------+-------------+-------------+-----------------------------+\n",
            "|a  |apple |1  |2.4|1  |yes|(2,[1],[1.0])|(2,[],[])    |(2,[1],[1.0])|(7,[1,5,6],[1.0,1.0,2.4])    |\n",
            "|a  |orange|1  |2.5|0  |no |(2,[1],[1.0])|(2,[0],[1.0])|(2,[1],[1.0])|[0.0,1.0,1.0,0.0,0.0,1.0,2.5]|\n",
            "|b  |orange|2  |3.5|1  |no |(2,[0],[1.0])|(2,[0],[1.0])|(2,[0],[1.0])|[1.0,0.0,1.0,0.0,1.0,0.0,3.5]|\n",
            "|b  |orange|2  |1.4|0  |yes|(2,[0],[1.0])|(2,[0],[1.0])|(2,[0],[1.0])|[1.0,0.0,1.0,0.0,1.0,0.0,1.4]|\n",
            "|b  |peach |2  |2.1|0  |yes|(2,[0],[1.0])|(2,[1],[1.0])|(2,[0],[1.0])|[1.0,0.0,0.0,1.0,1.0,0.0,2.1]|\n",
            "|c  |peach |4  |1.5|1  |yes|(2,[],[])    |(2,[1],[1.0])|(2,[],[])    |(7,[3,6],[1.0,1.5])          |\n",
            "+---+------+---+---+---+---+-------------+-------------+-------------+-----------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5loOVu0gTb_"
      },
      "source": [
        "## Convert sparse vectors in featuresCol to dense vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBXnLcxQgLZ7"
      },
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.ml.linalg import SparseVector, DenseVector"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kFoNLNEgLco"
      },
      "source": [
        "def dense_features_col(x):\n",
        "    return(x.toArray().dtype)\n",
        "dense_features_col_udf = udf(dense_features_col, returnType=StringType())"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m8EOR7_PtRVA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoHGEeBLgLgw",
        "outputId": "c6125bde-7d5f-4f1d-eb7e-7d281072cc13"
      },
      "source": [
        "df_assembled.rdd.map(lambda x: x['featuresCol']).take(6)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[SparseVector(7, {1: 1.0, 5: 1.0, 6: 2.4}),\n",
              " DenseVector([0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.5]),\n",
              " DenseVector([1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 3.5]),\n",
              " DenseVector([1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.4]),\n",
              " DenseVector([1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.1]),\n",
              " SparseVector(7, {3: 1.0, 6: 1.5})]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtYLdUhogZmB",
        "outputId": "88c736b0-7844-40a8-8b4e-eb488ad30f57"
      },
      "source": [
        "df_assembled.rdd.map(lambda x: list(x['featuresCol'].toArray())).take(6)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(2.4)],\n",
              " [np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(2.5)],\n",
              " [np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(3.5)],\n",
              " [np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.4)],\n",
              " [np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(2.1)],\n",
              " [np.float64(0.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(0.0),\n",
              "  np.float64(1.5)]]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ef9g5bCrgbnn"
      },
      "source": [],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Practice"
      ],
      "metadata": {
        "id": "pbrgMGKa1kWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "pdf2 = pd.DataFrame({\n",
        "        'x1': ['a','a','b','b', 'b', 'c'],\n",
        "        'x2': ['apple', 'orange', 'orange','orange', 'peach', 'peach'],\n",
        "        'x3': [1, 1, 2, 2, 2, 4],\n",
        "        'x4': [2.4, 2.5, 3.5, 1.4, 2.1,1.5],\n",
        "        'x5': ['man', 'woman', 'man', 'man', 'man', 'woman'],\n",
        "        'x6': [10.3, 11.4, 45.3, 32.5, 13.8, 17.2],\n",
        "        'x7': ['911', '113', '115', '113', '911', '115'],\n",
        "        'y1': [1, 0, 1, 0, 0, 1],\n",
        "        'y2': ['yes', 'no', 'no', 'yes', 'yes', 'yes']\n",
        "    })\n",
        "df2 = spark.createDataFrame(pdf2)\n",
        "df2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQS0WNid1mUX",
        "outputId": "797589c3-583c-4690-8a5d-41b6a0e4831a"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+---+---+-----+----+---+---+---+\n",
            "| x1|    x2| x3| x4|   x5|  x6| x7| y1| y2|\n",
            "+---+------+---+---+-----+----+---+---+---+\n",
            "|  a| apple|  1|2.4|  man|10.3|911|  1|yes|\n",
            "|  a|orange|  1|2.5|woman|11.4|113|  0| no|\n",
            "|  b|orange|  2|3.5|  man|45.3|115|  1| no|\n",
            "|  b|orange|  2|1.4|  man|32.5|113|  0|yes|\n",
            "|  b| peach|  2|2.1|  man|13.8|911|  0|yes|\n",
            "|  c| peach|  4|1.5|woman|17.2|115|  1|yes|\n",
            "+---+------+---+---+-----+----+---+---+---+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Your task: Please do the Assemble feature columns (of all categorical and numerical features) into one single **feacturesCol** with **`VectorAssembler`**\n",
        "**Hint: Categorical features (`x1`, `x2`, `x3`, `x5`, `x7`) and numerical features (`x4`, `x6`)**"
      ],
      "metadata": {
        "id": "iDtjTiFNleNx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "categorical_cols = ['x1', 'x2', 'x3', 'x5', 'x7']\n",
        "numerical_cols = ['x4', 'x6']"
      ],
      "metadata": {
        "id": "FqV21x-HMhYd"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexers = [\n",
        "    StringIndexer(\n",
        "        inputCol=col,\n",
        "        outputCol=f\"{col}_idx\",\n",
        "        handleInvalid=\"keep\"\n",
        "    )\n",
        "    for col in categorical_cols\n",
        "]\n"
      ],
      "metadata": {
        "id": "DvfjryvHMsdJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoders = [\n",
        "    OneHotEncoder(\n",
        "        inputCol=f\"{col}_idx\",\n",
        "        outputCol=f\"{col}_ohe\"\n",
        "    )\n",
        "    for col in categorical_cols\n",
        "]\n"
      ],
      "metadata": {
        "id": "z1e7734qMt8I"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=[f\"{col}_ohe\" for col in categorical_cols] + numerical_cols,\n",
        "    outputCol=\"featuresCol\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "7F51h-ppM3Zq"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n"
      ],
      "metadata": {
        "id": "0eRvzQxVM5C3"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_assembled = pipeline.fit(df2).transform(df2)\n",
        "df_assembled.select(\"featuresCol\").show(truncate=False)\n"
      ],
      "metadata": {
        "id": "VnCZ5DCYM6yX",
        "outputId": "79f0b386-570a-483b-b1df-414bf13ae528",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------+\n",
            "|featuresCol                                            |\n",
            "+-------------------------------------------------------+\n",
            "|(16,[1,5,7,9,13,14,15],[1.0,1.0,1.0,1.0,1.0,2.4,10.3]) |\n",
            "|(16,[1,3,7,10,11,14,15],[1.0,1.0,1.0,1.0,1.0,2.5,11.4])|\n",
            "|(16,[0,3,6,9,12,14,15],[1.0,1.0,1.0,1.0,1.0,3.5,45.3]) |\n",
            "|(16,[0,3,6,9,11,14,15],[1.0,1.0,1.0,1.0,1.0,1.4,32.5]) |\n",
            "|(16,[0,4,6,9,13,14,15],[1.0,1.0,1.0,1.0,1.0,2.1,13.8]) |\n",
            "|(16,[2,4,8,10,12,14,15],[1.0,1.0,1.0,1.0,1.0,1.5,17.2])|\n",
            "+-------------------------------------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise: Do the Assemble feature columns (of all categorical and numerical features) into one single **feacturesCol** with **`VectorAssembler`** for **`mtcars`** dataset"
      ],
      "metadata": {
        "id": "4kuUBb5FqXlg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('mtcars.csv', header=True, inferSchema=True)\n",
        "df.show(5)"
      ],
      "metadata": {
        "id": "Lki7ko1WOTwq",
        "outputId": "726be8be-1bc2-4ce6-9198-9cc98e525240",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "|              _c0| mpg|cyl| disp| hp|drat|   wt| qsec| vs| am|gear|carb|\n",
            "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "|        Mazda RX4|21.0|  6|160.0|110| 3.9| 2.62|16.46|  0|  1|   4|   4|\n",
            "|    Mazda RX4 Wag|21.0|  6|160.0|110| 3.9|2.875|17.02|  0|  1|   4|   4|\n",
            "|       Datsun 710|22.8|  4|108.0| 93|3.85| 2.32|18.61|  1|  1|   4|   1|\n",
            "|   Hornet 4 Drive|21.4|  6|258.0|110|3.08|3.215|19.44|  1|  0|   3|   1|\n",
            "|Hornet Sportabout|18.7|  8|360.0|175|3.15| 3.44|17.02|  0|  0|   3|   2|\n",
            "+-----------------+----+---+-----+---+----+-----+-----+---+---+----+----+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorical_cols = []\n",
        "numerical_cols = ['mpg', 'cyl', 'disp', 'hp', 'drat', 'wt', 'qsec', 'vs', 'am', 'gear', 'carb']"
      ],
      "metadata": {
        "id": "lkM7n66eOK-i"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoders = [\n",
        "    OneHotEncoder(\n",
        "        inputCol=f\"{col}_idx\",\n",
        "        outputCol=f\"{col}_ohe\"\n",
        "    )\n",
        "    for col in categorical_cols\n",
        "]"
      ],
      "metadata": {
        "id": "Oj9d8G54OJpA"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexers = [\n",
        "    StringIndexer(\n",
        "        inputCol=col,\n",
        "        outputCol=f\"{col}_idx\",\n",
        "        handleInvalid=\"keep\"\n",
        "    )\n",
        "    for col in categorical_cols\n",
        "]"
      ],
      "metadata": {
        "id": "gIK-aRzfOHSv"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=[f\"{col}_ohe\" for col in categorical_cols] + numerical_cols,\n",
        "    outputCol=\"featuresCol\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "R179H2uKOPtX"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n"
      ],
      "metadata": {
        "id": "gLnDoRK7ORF8"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_assembled = pipeline.fit(df).transform(df)\n",
        "df_assembled.select(\"featuresCol\").show(truncate=False)"
      ],
      "metadata": {
        "id": "DhU6owLPOSjO",
        "outputId": "be25f122-78b7-4971-a98a-c6ae986969b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------------------------------------------------+\n",
            "|featuresCol                                            |\n",
            "+-------------------------------------------------------+\n",
            "|[21.0,6.0,160.0,110.0,3.9,2.62,16.46,0.0,1.0,4.0,4.0]  |\n",
            "|[21.0,6.0,160.0,110.0,3.9,2.875,17.02,0.0,1.0,4.0,4.0] |\n",
            "|[22.8,4.0,108.0,93.0,3.85,2.32,18.61,1.0,1.0,4.0,1.0]  |\n",
            "|[21.4,6.0,258.0,110.0,3.08,3.215,19.44,1.0,0.0,3.0,1.0]|\n",
            "|[18.7,8.0,360.0,175.0,3.15,3.44,17.02,0.0,0.0,3.0,2.0] |\n",
            "|[18.1,6.0,225.0,105.0,2.76,3.46,20.22,1.0,0.0,3.0,1.0] |\n",
            "|[14.3,8.0,360.0,245.0,3.21,3.57,15.84,0.0,0.0,3.0,4.0] |\n",
            "|[24.4,4.0,146.7,62.0,3.69,3.19,20.0,1.0,0.0,4.0,2.0]   |\n",
            "|[22.8,4.0,140.8,95.0,3.92,3.15,22.9,1.0,0.0,4.0,2.0]   |\n",
            "|[19.2,6.0,167.6,123.0,3.92,3.44,18.3,1.0,0.0,4.0,4.0]  |\n",
            "|[17.8,6.0,167.6,123.0,3.92,3.44,18.9,1.0,0.0,4.0,4.0]  |\n",
            "|[16.4,8.0,275.8,180.0,3.07,4.07,17.4,0.0,0.0,3.0,3.0]  |\n",
            "|[17.3,8.0,275.8,180.0,3.07,3.73,17.6,0.0,0.0,3.0,3.0]  |\n",
            "|[15.2,8.0,275.8,180.0,3.07,3.78,18.0,0.0,0.0,3.0,3.0]  |\n",
            "|[10.4,8.0,472.0,205.0,2.93,5.25,17.98,0.0,0.0,3.0,4.0] |\n",
            "|[10.4,8.0,460.0,215.0,3.0,5.424,17.82,0.0,0.0,3.0,4.0] |\n",
            "|[14.7,8.0,440.0,230.0,3.23,5.345,17.42,0.0,0.0,3.0,4.0]|\n",
            "|[32.4,4.0,78.7,66.0,4.08,2.2,19.47,1.0,1.0,4.0,1.0]    |\n",
            "|[30.4,4.0,75.7,52.0,4.93,1.615,18.52,1.0,1.0,4.0,2.0]  |\n",
            "|[33.9,4.0,71.1,65.0,4.22,1.835,19.9,1.0,1.0,4.0,1.0]   |\n",
            "+-------------------------------------------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Exercise: Do the Assemble feature columns (of all categorical and numerical features) into one single **feacturesCol** with **`VectorAssembler`** for **`titanic`** dataset"
      ],
      "metadata": {
        "id": "BMAxLQaRoTHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv('kaggle-titanic-test.csv', header = True, inferSchema=True)\n",
        "df.show(20)"
      ],
      "metadata": {
        "id": "aeT87zREqhSO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9479f30b-fee8-4a7c-b581-aaf38c623dac"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|PassengerId|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
            "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "|        892|     3|    Kelly, Mr. James|  male|34.5|    0|    0|          330911| 7.8292| NULL|       Q|\n",
            "|        893|     3|Wilkes, Mrs. Jame...|female|47.0|    1|    0|          363272|    7.0| NULL|       S|\n",
            "|        894|     2|Myles, Mr. Thomas...|  male|62.0|    0|    0|          240276| 9.6875| NULL|       Q|\n",
            "|        895|     3|    Wirz, Mr. Albert|  male|27.0|    0|    0|          315154| 8.6625| NULL|       S|\n",
            "|        896|     3|Hirvonen, Mrs. Al...|female|22.0|    1|    1|         3101298|12.2875| NULL|       S|\n",
            "|        897|     3|Svensson, Mr. Joh...|  male|14.0|    0|    0|            7538|  9.225| NULL|       S|\n",
            "|        898|     3|Connolly, Miss. Kate|female|30.0|    0|    0|          330972| 7.6292| NULL|       Q|\n",
            "|        899|     2|Caldwell, Mr. Alb...|  male|26.0|    1|    1|          248738|   29.0| NULL|       S|\n",
            "|        900|     3|Abrahim, Mrs. Jos...|female|18.0|    0|    0|            2657| 7.2292| NULL|       C|\n",
            "|        901|     3|Davies, Mr. John ...|  male|21.0|    2|    0|       A/4 48871|  24.15| NULL|       S|\n",
            "|        902|     3|    Ilieff, Mr. Ylio|  male|NULL|    0|    0|          349220| 7.8958| NULL|       S|\n",
            "|        903|     1|Jones, Mr. Charle...|  male|46.0|    0|    0|             694|   26.0| NULL|       S|\n",
            "|        904|     1|Snyder, Mrs. John...|female|23.0|    1|    0|           21228|82.2667|  B45|       S|\n",
            "|        905|     2|Howard, Mr. Benjamin|  male|63.0|    1|    0|           24065|   26.0| NULL|       S|\n",
            "|        906|     1|Chaffee, Mrs. Her...|female|47.0|    1|    0|     W.E.P. 5734| 61.175|  E31|       S|\n",
            "|        907|     2|del Carlo, Mrs. S...|female|24.0|    1|    0|   SC/PARIS 2167|27.7208| NULL|       C|\n",
            "|        908|     2|   Keane, Mr. Daniel|  male|35.0|    0|    0|          233734|  12.35| NULL|       Q|\n",
            "|        909|     3|   Assaf, Mr. Gerios|  male|21.0|    0|    0|            2692|  7.225| NULL|       C|\n",
            "|        910|     3|Ilmakangas, Miss....|female|27.0|    1|    0|STON/O2. 3101270|  7.925| NULL|       S|\n",
            "|        911|     3|\"Assaf Khalil, Mr...|female|45.0|    0|    0|            2696|  7.225| NULL|       C|\n",
            "+-----------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('PassengerId', 'Name', 'Cabin').dropna()\n",
        "df.show(5)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "id": "d3i5MjqRSqkY",
        "outputId": "199ff7b9-948a-4aac-853d-01654b0dd872",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+----+-----+-----+-------+-------+--------+\n",
            "|Pclass|   Sex| Age|SibSp|Parch| Ticket|   Fare|Embarked|\n",
            "+------+------+----+-----+-----+-------+-------+--------+\n",
            "|     3|  male|34.5|    0|    0| 330911| 7.8292|       Q|\n",
            "|     3|female|47.0|    1|    0| 363272|    7.0|       S|\n",
            "|     2|  male|62.0|    0|    0| 240276| 9.6875|       Q|\n",
            "|     3|  male|27.0|    0|    0| 315154| 8.6625|       S|\n",
            "|     3|female|22.0|    1|    1|3101298|12.2875|       S|\n",
            "+------+------+----+-----+-----+-------+-------+--------+\n",
            "only showing top 5 rows\n",
            "root\n",
            " |-- Pclass: integer (nullable = true)\n",
            " |-- Sex: string (nullable = true)\n",
            " |-- Age: double (nullable = true)\n",
            " |-- SibSp: integer (nullable = true)\n",
            " |-- Parch: integer (nullable = true)\n",
            " |-- Ticket: string (nullable = true)\n",
            " |-- Fare: double (nullable = true)\n",
            " |-- Embarked: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "categorial_cols = ['Sex', 'Embarked', 'Ticket']\n",
        "numerical_cols = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']"
      ],
      "metadata": {
        "id": "7aOK5CikSd0p"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoders = [\n",
        "    OneHotEncoder(\n",
        "        inputCol=f\"{col}_idx\",\n",
        "        outputCol=f\"{col}_ohe\"\n",
        "    )\n",
        "    for col in categorical_cols\n",
        "]"
      ],
      "metadata": {
        "id": "aYo0KSR2TDYT"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexers = [\n",
        "    StringIndexer(\n",
        "        inputCol=col,\n",
        "        outputCol=f\"{col}_idx\",\n",
        "        handleInvalid=\"keep\"\n",
        "    )\n",
        "    for col in categorical_cols\n",
        "]"
      ],
      "metadata": {
        "id": "HWYEpieKTEcf"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assembler = VectorAssembler(\n",
        "    inputCols=[f\"{col}_ohe\" for col in categorical_cols] + numerical_cols,\n",
        "    outputCol=\"featuresCol\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "o5HH3sQrTF2l"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline(stages=indexers + encoders + [assembler])\n"
      ],
      "metadata": {
        "id": "BXyUACTOTHR3"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_assembled = pipeline.fit(df).transform(df)\n",
        "df_assembled.select(\"featuresCol\").show(truncate=False)"
      ],
      "metadata": {
        "id": "xBbOGnYCTJcI",
        "outputId": "c9f29c72-5244-427a-f1d4-cc5c07679ae0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------------+\n",
            "|featuresCol               |\n",
            "+--------------------------+\n",
            "|[3.0,34.5,0.0,0.0,7.8292] |\n",
            "|[3.0,47.0,1.0,0.0,7.0]    |\n",
            "|[2.0,62.0,0.0,0.0,9.6875] |\n",
            "|[3.0,27.0,0.0,0.0,8.6625] |\n",
            "|[3.0,22.0,1.0,1.0,12.2875]|\n",
            "|[3.0,14.0,0.0,0.0,9.225]  |\n",
            "|[3.0,30.0,0.0,0.0,7.6292] |\n",
            "|[2.0,26.0,1.0,1.0,29.0]   |\n",
            "|[3.0,18.0,0.0,0.0,7.2292] |\n",
            "|[3.0,21.0,2.0,0.0,24.15]  |\n",
            "|[1.0,46.0,0.0,0.0,26.0]   |\n",
            "|[1.0,23.0,1.0,0.0,82.2667]|\n",
            "|[2.0,63.0,1.0,0.0,26.0]   |\n",
            "|[1.0,47.0,1.0,0.0,61.175] |\n",
            "|[2.0,24.0,1.0,0.0,27.7208]|\n",
            "|[2.0,35.0,0.0,0.0,12.35]  |\n",
            "|[3.0,21.0,0.0,0.0,7.225]  |\n",
            "|[3.0,27.0,1.0,0.0,7.925]  |\n",
            "|[3.0,45.0,0.0,0.0,7.225]  |\n",
            "|[1.0,55.0,1.0,0.0,59.4]   |\n",
            "+--------------------------+\n",
            "only showing top 20 rows\n"
          ]
        }
      ]
    }
  ]
}