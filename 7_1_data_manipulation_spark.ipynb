{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyri0n11/distributed-system/blob/main/7_1_data_manipulation_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G3_5j4Ra-Cgs"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "sc = SparkContext()\n",
        "spark = SparkSession(sparkContext=sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "8lf6GG2TDM2s",
        "outputId": "eb901fa1-42e5-456b-d461-20f892cbadb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x797580ce4b60>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://b986b22c9341:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ijjMPfI-Iuy"
      },
      "source": [
        "## Map functions\n",
        "\n",
        "These functions are probably the most commonly used functions when dealing with an RDD object.\n",
        "\n",
        "* `map()`\n",
        "* `mapValues()`\n",
        "* `flatMap()`\n",
        "* `flatMapValues()`\n",
        "\n",
        "### `map`\n",
        "\n",
        "The `map()` method applies a function to each elements of the RDD. Each element has to be a valid input to the function. The returned RDD has the function outputs as its new elements.\n",
        "\n",
        "Elements in the RDD object `map_exp_rdd` below are rows of the `mtcars` in string format. We are going to apply the `map()` function multiple times to convert each string elements as a list elements. Each list element has two values: the first value will be the auto model in string format; the second value will be a list of numeric values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "FQf2TexL-CjU",
        "outputId": "d9c6fedd-4408-4f3c-e955-5562185e05f6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e54d0bb3-5772-4b70-a3b9-16f4d4ef7667\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e54d0bb3-5772-4b70-a3b9-16f4d4ef7667\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AsBPdKp6QU52",
        "outputId": "21139d6f-4ab3-490c-b5fb-2b4b7617bfab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Unnamed: 0   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
              "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
              "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
              "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
              "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
              "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
              "\n",
              "   carb  \n",
              "0     4  \n",
              "1     4  \n",
              "2     1  \n",
              "3     1  \n",
              "4     2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bf0a201c-2d56-423c-9b37-5b0613106b14\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>mpg</th>\n",
              "      <th>cyl</th>\n",
              "      <th>disp</th>\n",
              "      <th>hp</th>\n",
              "      <th>drat</th>\n",
              "      <th>wt</th>\n",
              "      <th>qsec</th>\n",
              "      <th>vs</th>\n",
              "      <th>am</th>\n",
              "      <th>gear</th>\n",
              "      <th>carb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mazda RX4</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6</td>\n",
              "      <td>160.0</td>\n",
              "      <td>110</td>\n",
              "      <td>3.90</td>\n",
              "      <td>2.620</td>\n",
              "      <td>16.46</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mazda RX4 Wag</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6</td>\n",
              "      <td>160.0</td>\n",
              "      <td>110</td>\n",
              "      <td>3.90</td>\n",
              "      <td>2.875</td>\n",
              "      <td>17.02</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Datsun 710</td>\n",
              "      <td>22.8</td>\n",
              "      <td>4</td>\n",
              "      <td>108.0</td>\n",
              "      <td>93</td>\n",
              "      <td>3.85</td>\n",
              "      <td>2.320</td>\n",
              "      <td>18.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hornet 4 Drive</td>\n",
              "      <td>21.4</td>\n",
              "      <td>6</td>\n",
              "      <td>258.0</td>\n",
              "      <td>110</td>\n",
              "      <td>3.08</td>\n",
              "      <td>3.215</td>\n",
              "      <td>19.44</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hornet Sportabout</td>\n",
              "      <td>18.7</td>\n",
              "      <td>8</td>\n",
              "      <td>360.0</td>\n",
              "      <td>175</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.440</td>\n",
              "      <td>17.02</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf0a201c-2d56-423c-9b37-5b0613106b14')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bf0a201c-2d56-423c-9b37-5b0613106b14 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bf0a201c-2d56-423c-9b37-5b0613106b14');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-354e75b2-06c0-4f86-95d8-8ed4730438d0\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-354e75b2-06c0-4f86-95d8-8ed4730438d0')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-354e75b2-06c0-4f86-95d8-8ed4730438d0 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "mtcar_data",
              "summary": "{\n  \"name\": \"mtcar_data\",\n  \"rows\": 32,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"Ferrari Dino\",\n          \"Lincoln Continental\",\n          \"Pontiac Firebird\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mpg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.026948052089105,\n        \"min\": 10.4,\n        \"max\": 33.9,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          17.8,\n          33.9,\n          21.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cyl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 4,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6,\n          4,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"disp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 123.93869383138194,\n        \"min\": 71.1,\n        \"max\": 472.0,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          275.8,\n          75.7,\n          472.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 68,\n        \"min\": 52,\n        \"max\": 335,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          110,\n          52,\n          180\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"drat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5346787360709716,\n        \"min\": 2.76,\n        \"max\": 4.93,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          3.9,\n          4.93,\n          3.07\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9784574429896967,\n        \"min\": 1.513,\n        \"max\": 5.424,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          2.77,\n          1.615,\n          5.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"qsec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7869432360968431,\n        \"min\": 14.5,\n        \"max\": 22.9,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          15.5,\n          17.42,\n          17.05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"am\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gear\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"carb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "mtcar_data = pd.read_csv('./mtcars.csv')\n",
        "mtcar_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "oMcc5mCPDaUZ",
        "outputId": "5b6149dd-9c7e-47a5-9501-031316a271ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
              "\n",
              "Data structure also contains labeled axes (rows and columns).\n",
              "Arithmetic operations align on both row and column labels. Can be\n",
              "thought of as a dict-like container for Series objects. The primary\n",
              "pandas data structure.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
              "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
              "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
              "    which have an index defined, it is aligned by its index. This alignment also\n",
              "    occurs if data is a Series or a DataFrame itself. Alignment is done on\n",
              "    Series/DataFrame inputs.\n",
              "\n",
              "    If data is a list of dicts, column order follows insertion-order.\n",
              "\n",
              "index : Index or array-like\n",
              "    Index to use for resulting frame. Will default to RangeIndex if\n",
              "    no indexing information part of input data and no index provided.\n",
              "columns : Index or array-like\n",
              "    Column labels to use for resulting frame when data does not have them,\n",
              "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
              "    will perform column selection instead.\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
              "copy : bool or None, default None\n",
              "    Copy data from inputs.\n",
              "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
              "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
              "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
              "    ``copy=False`` will ensure that these inputs are not copied.\n",
              "\n",
              "    .. versionchanged:: 1.3.0\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
              "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
              "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
              "read_table : Read general delimited file into DataFrame.\n",
              "read_clipboard : Read text from clipboard into DataFrame.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing DataFrame from a dictionary.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d)\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Notice that the inferred dtype is int64.\n",
              "\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int64\n",
              "col2    int64\n",
              "dtype: object\n",
              "\n",
              "To enforce a single dtype:\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int8\n",
              "col2    int8\n",
              "dtype: object\n",
              "\n",
              "Constructing DataFrame from a dictionary including Series:\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n",
              "&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
              "   col1  col2\n",
              "0     0   NaN\n",
              "1     1   NaN\n",
              "2     2   2.0\n",
              "3     3   3.0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray:\n",
              "\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
              "...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; df2\n",
              "   a  b  c\n",
              "0  1  2  3\n",
              "1  4  5  6\n",
              "2  7  8  9\n",
              "\n",
              "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
              "\n",
              "&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
              "...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n",
              "&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n",
              "...\n",
              "&gt;&gt;&gt; df3\n",
              "   c  a\n",
              "0  3  1\n",
              "1  6  4\n",
              "2  9  7\n",
              "\n",
              "Constructing DataFrame from dataclass:\n",
              "\n",
              "&gt;&gt;&gt; from dataclasses import make_dataclass\n",
              "&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n",
              "&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
              "   x  y\n",
              "0  0  0\n",
              "1  0  3\n",
              "2  2  3\n",
              "\n",
              "Constructing DataFrame from Series/DataFrame:\n",
              "\n",
              "&gt;&gt;&gt; ser = pd.Series([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=ser, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df\n",
              "   0\n",
              "a  1\n",
              "c  3\n",
              "\n",
              "&gt;&gt;&gt; df1 = pd.DataFrame([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], columns=[&quot;x&quot;])\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(data=df1, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df2\n",
              "   x\n",
              "a  1\n",
              "c  3</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 509);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "type(mtcar_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oQWrMZg-CoA",
        "outputId": "16ab4cb2-d656-4214-d3ae-0423aa539cfd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[',mpg,cyl,disp,hp,drat,wt,qsec,vs,am,gear,carb',\n",
              " 'Mazda RX4,21,6,160,110,3.9,2.62,16.46,0,1,4,4',\n",
              " 'Mazda RX4 Wag,21,6,160,110,3.9,2.875,17.02,0,1,4,4',\n",
              " 'Datsun 710,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# create an example RDD\n",
        "map_exp_rdd = sc.textFile('./mtcars.csv')\n",
        "map_exp_rdd.take(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "KBPQTzWHDgK4",
        "outputId": "d29c4e3f-0aae-4326-f152-458a9f5c0071"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.RDD</b><br/>def __init__(jrdd: &#x27;JavaObject&#x27;, ctx: &#x27;SparkContext&#x27;, jrdd_deserializer: Serializer=AutoBatchedSerializer(CPickleSerializer()))</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/rdd.py</a>A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
              "Represents an immutable, partitioned collection of elements that can be\n",
              "operated on in parallel.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 336);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "type(map_exp_rdd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mvhoaSu-Cqx",
        "outputId": "ce826159-964c-49c8-fcff-ff1500b96b47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('',\n",
              "  ['mpg',\n",
              "   'cyl',\n",
              "   'disp',\n",
              "   'hp',\n",
              "   'drat',\n",
              "   'wt',\n",
              "   'qsec',\n",
              "   'vs',\n",
              "   'am',\n",
              "   'gear',\n",
              "   'carb']),\n",
              " ('Mazda RX4',\n",
              "  ['21', '6', '160', '110', '3.9', '2.62', '16.46', '0', '1', '4', '4']),\n",
              " ('Mazda RX4 Wag',\n",
              "  ['21', '6', '160', '110', '3.9', '2.875', '17.02', '0', '1', '4', '4']),\n",
              " ('Datsun 710',\n",
              "  ['22.8', '4', '108', '93', '3.85', '2.32', '18.61', '1', '1', '4', '1'])]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# split auto model from other feature values\n",
        "map_exp_rdd_1 = map_exp_rdd.map(lambda x: x.split(',')).map(lambda x: (x[0], x[1:]))\n",
        "map_exp_rdd_1.take(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24fAuUw8-Cr_",
        "outputId": "16f6fcd3-9a08-4fc3-c425-d10d83dd3598"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4',\n",
              "  ['21', '6', '160', '110', '3.9', '2.62', '16.46', '0', '1', '4', '4']),\n",
              " ('Mazda RX4 Wag',\n",
              "  ['21', '6', '160', '110', '3.9', '2.875', '17.02', '0', '1', '4', '4']),\n",
              " ('Datsun 710',\n",
              "  ['22.8', '4', '108', '93', '3.85', '2.32', '18.61', '1', '1', '4', '1']),\n",
              " ('Hornet 4 Drive',\n",
              "  ['21.4', '6', '258', '110', '3.08', '3.215', '19.44', '1', '0', '3', '1'])]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# remove the header row\n",
        "header = map_exp_rdd_1.first()\n",
        "# the filter method apply a function to each elemnts. The function output is a boolean value (TRUE or FALSE)\n",
        "# elements that have output TRUE will be kept.\n",
        "map_exp_rdd_2 = map_exp_rdd_1.filter(lambda x: x != header)\n",
        "map_exp_rdd_2.take(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSZDalUC-Cuu",
        "outputId": "b98c07fb-03ab-4828-a530-4f579d4e9703"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4',\n",
              "  [21.0, 6.0, 160.0, 110.0, 3.9, 2.62, 16.46, 0.0, 1.0, 4.0, 4.0]),\n",
              " ('Mazda RX4 Wag',\n",
              "  [21.0, 6.0, 160.0, 110.0, 3.9, 2.875, 17.02, 0.0, 1.0, 4.0, 4.0]),\n",
              " ('Datsun 710',\n",
              "  [22.8, 4.0, 108.0, 93.0, 3.85, 2.32, 18.61, 1.0, 1.0, 4.0, 1.0]),\n",
              " ('Hornet 4 Drive',\n",
              "  [21.4, 6.0, 258.0, 110.0, 3.08, 3.215, 19.44, 1.0, 0.0, 3.0, 1.0])]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# convert string values to numeric values\n",
        "map_exp_rdd_3 = map_exp_rdd_2.map(lambda x: (x[0], list(map(float, x[1]))))\n",
        "map_exp_rdd_3.take(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w9I4ss5-v82"
      },
      "source": [
        "### `mapValues`\n",
        "\n",
        "The `mapValues` function requires that each element in the RDD has a **key/value** pair structure, for example, a tuple of 2 items, or a list of 2 items. The `mapValues` function applies a function to each of the element values. The element key will remain unchanged.\n",
        "\n",
        "We can apply the `mapValues` function to the RDD object `mapValues_exp_rdd` below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mKh4etX-Cw4",
        "outputId": "6866211d-2a5a-495b-ddda-90c900b197f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4',\n",
              "  [21.0, 6.0, 160.0, 110.0, 3.9, 2.62, 16.46, 0.0, 1.0, 4.0, 4.0]),\n",
              " ('Mazda RX4 Wag',\n",
              "  [21.0, 6.0, 160.0, 110.0, 3.9, 2.875, 17.02, 0.0, 1.0, 4.0, 4.0]),\n",
              " ('Datsun 710',\n",
              "  [22.8, 4.0, 108.0, 93.0, 3.85, 2.32, 18.61, 1.0, 1.0, 4.0, 1.0]),\n",
              " ('Hornet 4 Drive',\n",
              "  [21.4, 6.0, 258.0, 110.0, 3.08, 3.215, 19.44, 1.0, 0.0, 3.0, 1.0])]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "mapValues_exp_rdd = map_exp_rdd_3\n",
        "mapValues_exp_rdd.take(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p9NHPBl-rUr",
        "outputId": "8afd9b10-3782-4208-e608-93e71bd58c9d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4', np.float64(29.90727272727273)),\n",
              " ('Mazda RX4 Wag', np.float64(29.98136363636364)),\n",
              " ('Datsun 710', np.float64(23.59818181818182)),\n",
              " ('Hornet 4 Drive', np.float64(38.73954545454546))]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import numpy as np\n",
        "mapValues_exp_rdd_1 = mapValues_exp_rdd.mapValues(lambda x: np.mean(x))\n",
        "mapValues_exp_rdd_1.take(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz1LndcqESO2",
        "outputId": "717b0e52-03c9-494d-89c4-6d00320253ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4', np.float64(0.0)),\n",
              " ('Mazda RX4 Wag', np.float64(0.0)),\n",
              " ('Datsun 710', np.float64(1.0)),\n",
              " ('Hornet 4 Drive', np.float64(0.0))]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import numpy as np\n",
        "mapValues_exp_rdd_2 = mapValues_exp_rdd.mapValues(lambda x: np.min(x))\n",
        "mapValues_exp_rdd_2.take(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL6sak0QE0tm",
        "outputId": "dc459c21-8a9c-4585-962f-adb415f8ef3b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4', np.float64(80.0)),\n",
              " ('Mazda RX4 Wag', np.float64(80.0)),\n",
              " ('Datsun 710', np.float64(54.5)),\n",
              " ('Hornet 4 Drive', np.float64(129.0))]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import numpy as np\n",
        "mapValues_exp_rdd_3 = mapValues_exp_rdd.mapValues(lambda x: (np.min(x)+np.max(x))/2)\n",
        "mapValues_exp_rdd_3.take(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjbtOMSz-4Sm"
      },
      "source": [
        "When using `mapValues()`, the x in the above lambda function refers to the element value, not including the element key."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Provide more examples of `mapValues()` in Spark\n",
        "\n",
        "# Calculate the sum of all values for each key\n",
        "mapValues_exp_rdd_4 = mapValues_exp_rdd.mapValues(lambda x: sum(x))\n",
        "mapValues_exp_rdd_4.take(4)\n",
        "\n",
        "# Find the maximum value for each key\n",
        "mapValues_exp_rdd_5 = mapValues_exp_rdd.mapValues(lambda x: max(x))\n",
        "mapValues_exp_rdd_5.take(4)\n",
        "\n",
        "# Convert each value (a list of floats) to a numpy array\n",
        "mapValues_exp_rdd_6 = mapValues_exp_rdd.mapValues(lambda x: np.array(x))\n",
        "mapValues_exp_rdd_6.take(4)\n",
        "\n",
        "# Apply a custom function to each value\n",
        "def custom_function(values):\n",
        "  \"\"\"Example custom function that calculates the range of a list of numbers\"\"\"\n",
        "  return max(values) - min(values)\n",
        "\n",
        "mapValues_exp_rdd_7 = mapValues_exp_rdd.mapValues(custom_function)\n",
        "mapValues_exp_rdd_7.take(4)\n",
        "\n",
        "# Example with a conditional operation: square values if the minimum is > 5\n",
        "mapValues_exp_rdd_8 = mapValues_exp_rdd.mapValues(lambda x: [val**2 for val in x] if min(x) > 5 else x)\n",
        "mapValues_exp_rdd_8.take(4)\n"
      ],
      "metadata": {
        "id": "eubdA5ADpHQ9",
        "outputId": "cc018f02-20c1-45ce-bafc-b2b5a88e2d58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4',\n",
              "  [21.0, 6.0, 160.0, 110.0, 3.9, 2.62, 16.46, 0.0, 1.0, 4.0, 4.0]),\n",
              " ('Mazda RX4 Wag',\n",
              "  [21.0, 6.0, 160.0, 110.0, 3.9, 2.875, 17.02, 0.0, 1.0, 4.0, 4.0]),\n",
              " ('Datsun 710',\n",
              "  [22.8, 4.0, 108.0, 93.0, 3.85, 2.32, 18.61, 1.0, 1.0, 4.0, 1.0]),\n",
              " ('Hornet 4 Drive',\n",
              "  [21.4, 6.0, 258.0, 110.0, 3.08, 3.215, 19.44, 1.0, 0.0, 3.0, 1.0])]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffBYhyPy-86E"
      },
      "source": [
        "### `flatMap`\n",
        "\n",
        "This function first applies a function to each elements of an RDD and then flatten the results. We can simply use this function to flatten elements of an RDD without extra operation on each elements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk30p-v4-rXn",
        "outputId": "e99dc28c-61c8-4b03-a7ac-ff1215601014"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 'b', 'c'), ('a', 'a'), ('c', 'c', 'c', 'd')]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "x = [('a', 'b', 'c'), ('a', 'a'), ('c', 'c', 'c', 'd')]\n",
        "flatMap_exp_rdd = sc.parallelize(x)\n",
        "flatMap_exp_rdd.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcbjRXZ4-ral",
        "outputId": "0926d395-2922-487b-9225-841cbab46e83"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'b', 'c', 'a', 'a', 'c', 'c', 'c', 'd']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "flatMap_exp_rdd_1 = flatMap_exp_rdd.flatMap(lambda x: x)\n",
        "flatMap_exp_rdd_1.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "8y8Q7ioXFTfF",
        "outputId": "05346dd6-b3af-415d-a676-0c392eb474cc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.PipelinedRDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.PipelinedRDD</b><br/>def __init__(prev: RDD[T], func: Callable[[int, Iterable[T]], Iterable[U]], preservesPartitioning: bool=False, isFromBarrier: bool=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/rdd.py</a>Examples\n",
              "--------\n",
              "Pipelined maps:\n",
              "\n",
              "&gt;&gt;&gt; rdd = sc.parallelize([1, 2, 3, 4])\n",
              "&gt;&gt;&gt; rdd.map(lambda x: 2 * x).cache().map(lambda x: 2 * x).collect()\n",
              "[4, 8, 12, 16]\n",
              "&gt;&gt;&gt; rdd.map(lambda x: 2 * x).map(lambda x: 2 * x).collect()\n",
              "[4, 8, 12, 16]\n",
              "\n",
              "Pipelined reduces:\n",
              "\n",
              "&gt;&gt;&gt; from operator import add\n",
              "&gt;&gt;&gt; rdd.map(lambda x: 2 * x).reduce(add)\n",
              "20\n",
              "&gt;&gt;&gt; rdd.flatMap(lambda x: [x, x]).reduce(add)\n",
              "20</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 5395);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "type(flatMap_exp_rdd_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9L609dD_Fwf"
      },
      "source": [
        "### `flatMapValues`\n",
        "\n",
        "The `flatMapValues` function requires that each element in the RDD has a **key/value** pair structure. It applies a function to each **element value** of the RDD object and then flatten the results.\n",
        "\n",
        "For example, my raw data looks like below. But I would like to transform the data so that it has three columns: the first column is the **sample id**; the second the column is the three **types (A,B or C)**; the third column is the **values**.\n",
        "\n",
        "| sample id |  A |  B |  C |\n",
        "|:---------:|:--:|:--:|:--:|\n",
        "|     1     | 23 | 18 | 32 |\n",
        "|     2     | 18 | 29 | 31 |\n",
        "|     3     | 34 | 21 | 18 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctnKvigZ-rcp",
        "outputId": "c2012a49-b507-499e-d677-86328e7813d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, (23, 28, 32)], [2, (18, 29, 31)], [3, (34, 21, 18)]]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# example data\n",
        "my_data = [\n",
        "    [1, (23, 28, 32)],\n",
        "    [2, (18, 29, 31)],\n",
        "    [3, (34, 21, 18)]\n",
        "]\n",
        "flatMapValues_exp_rdd = sc.parallelize(my_data)\n",
        "flatMapValues_exp_rdd.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOMbRpv__I7F",
        "outputId": "f4f00fb3-5388-4a0a-f919-d8f27ea6d17c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, ('A', 23)),\n",
              " (1, ('B', 28)),\n",
              " (1, ('C', 32)),\n",
              " (2, ('A', 18)),\n",
              " (2, ('B', 29)),\n",
              " (2, ('C', 31)),\n",
              " (3, ('A', 34)),\n",
              " (3, ('B', 21)),\n",
              " (3, ('C', 18))]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# merge A,B,and C columns into one column and add the type column\n",
        "flatMapValues_exp_rdd_1 = flatMapValues_exp_rdd.flatMapValues(lambda x: list(zip(list('ABC'), x)))\n",
        "flatMapValues_exp_rdd_1.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XLkEqaB_LXa",
        "outputId": "4b2c5ad8-ca9b-4f5d-e0f2-c2f5098eb4ed"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 'A', 23],\n",
              " [1, 'B', 28],\n",
              " [1, 'C', 32],\n",
              " [2, 'A', 18],\n",
              " [2, 'B', 29],\n",
              " [2, 'C', 31],\n",
              " [3, 'A', 34],\n",
              " [3, 'B', 21],\n",
              " [3, 'C', 18]]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# unpack the element values\n",
        "flatMapValues_exp_rdd_2 = flatMapValues_exp_rdd_1.map(lambda x: [x[0]] + list(x[1]) )\n",
        "flatMapValues_exp_rdd_2.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IkCtkPeG_OGk",
        "outputId": "9770926a-69fd-48ff-edf3-27c2ed4f8723",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('key1', ('even', 10)), ('key2', ('odd', 25))]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# prompt: Provide more examples of `flatMapValues()` in Pyspark\n",
        "\n",
        "# Example 1: Expanding a list of words associated with each key\n",
        "data = [('doc1', ['apple', 'banana']), ('doc2', ['orange', 'grape', 'kiwi'])]\n",
        "rdd = sc.parallelize(data)\n",
        "\n",
        "# Apply flatMapValues to expand the list of words into individual elements.\n",
        "expanded_rdd = rdd.flatMapValues(lambda words: words)\n",
        "expanded_rdd.collect()  # Output: [('doc1', 'apple'), ('doc1', 'banana'), ('doc2', 'orange'), ('doc2', 'grape'), ('doc2', 'kiwi')]\n",
        "\n",
        "\n",
        "# Example 2: Processing a list of tuples associated with each key.\n",
        "data2 = [('user1', [('productA', 5), ('productB', 2)]), ('user2', [('productC', 1), ('productA', 3)])]\n",
        "rdd2 = sc.parallelize(data2)\n",
        "\n",
        "# Separate product and quantity for each user.\n",
        "product_quantities = rdd2.flatMapValues(lambda purchases: purchases)\n",
        "product_quantities.collect() # Output: [('user1', ('productA', 5)), ('user1', ('productB', 2)), ('user2', ('productC', 1)), ('user2', ('productA', 3))]\n",
        "\n",
        "# Example 3: Splitting strings based on a delimiter\n",
        "data3 = [('sentence1', 'this is a test sentence'), ('sentence2', 'another example')]\n",
        "rdd3 = sc.parallelize(data3)\n",
        "\n",
        "# Split each sentence into words.\n",
        "words_rdd = rdd3.flatMapValues(lambda sentence: sentence.split())\n",
        "words_rdd.collect() # Output: [('sentence1', 'this'), ('sentence1', 'is'), ('sentence1', 'a'), ('sentence1', 'test'), ('sentence1', 'sentence'), ('sentence2', 'another'), ('sentence2', 'example')]\n",
        "\n",
        "\n",
        "# Example 4: Generating multiple key-value pairs from each original value\n",
        "data4 = [('key1', 10), ('key2', 25)]\n",
        "rdd4 = sc.parallelize(data4)\n",
        "\n",
        "\n",
        "# Generate key-value pairs based on whether values are even or odd\n",
        "def process_number(num):\n",
        "    if num % 2 == 0:\n",
        "      return [('even', num)]\n",
        "    else:\n",
        "      return [('odd', num)]\n",
        "\n",
        "processed_rdd = rdd4.flatMapValues(process_number)\n",
        "processed_rdd.collect() # Output: [('key1', ('even', 10)), ('key2', ('odd', 25))]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryl-6ZCB_gbu"
      },
      "source": [
        "## Aggregate functions\n",
        "Two aggregate functions:\n",
        "\n",
        "* `aggregate()`\n",
        "* `aggregateByKey()`\n",
        "\n",
        "### `aggregate(zeroValue, seqOp, combOp)`\n",
        "\n",
        "* **zeroValue** is like a data container. Its structure should match with the data structure of the returned values from the seqOp function.\n",
        "* **seqOp** is a function that takes two arguments: the first argument is the zeroValue and the second argument is an element from the RDD. The zeroValue gets updated with the returned value after every run.\n",
        "* **combOp** is a function that takes two arguments: the first argument is the final zeroValue from one partition and the other is another final zeroValue from another partition.\n",
        "\n",
        "The code below calculates the total sum of squares for **mpg** and **disp** in data set **mtcars**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLrIvL6Y_l0N"
      },
      "source": [
        "Step 1: get some data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP9Remgv_hII",
        "outputId": "bd6de489-8866-4053-cbf9-35cdc7ea740f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(mpg=21.0, disp=160.0),\n",
              " Row(mpg=21.0, disp=160.0),\n",
              " Row(mpg=22.8, disp=108.0),\n",
              " Row(mpg=21.4, disp=258.0),\n",
              " Row(mpg=18.7, disp=360.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "mtcars_df = spark.read.csv('./mtcars.csv', inferSchema=True, header=True).select(['mpg', 'disp'])\n",
        "mtcars_df.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LEuZHX7_wk9"
      },
      "source": [
        "Step 2: calculate averages of mgp and disp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiAOs1zH_hL1",
        "outputId": "0a487af9-11ef-4600-ae43-7888c0a8c285"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mpg mean =  20.090625000000003 ; disp mean =  230.721875\n"
          ]
        }
      ],
      "source": [
        "mpg_mean = mtcars_df.select('mpg').rdd.map(lambda x: x[0]).mean()\n",
        "disp_mean = mtcars_df.select('disp').rdd.map(lambda x: x[0]).mean()\n",
        "print('mpg mean = ', mpg_mean, '; '\n",
        "      'disp mean = ', disp_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F99X4I2o_5qJ"
      },
      "source": [
        "Step 3: build **zeroValue, seqOp** and **combOp**\n",
        "\n",
        "We are calculating two TSS. We create a tuple to store two values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "LSmHVKxz_hN1"
      },
      "outputs": [],
      "source": [
        "zeroValue = (0, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVH0LflKAAPZ"
      },
      "source": [
        "The **z** below refers to `zeroValue`. Its values get updated after every run. The **x** refers to an element in an RDD partition. In this case, both **z** and **x** have two values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "VScTN0ff_hP8"
      },
      "outputs": [],
      "source": [
        "seqOp = lambda z, x: (z[0] + (x[0] - mpg_mean)**2, z[1] + (x[1] - disp_mean)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9Kn97AMGRRu",
        "outputId": "f0c86f53-8362-40a8-ad8d-e7f92520b986"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.<lambda>(z, x)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "seqOp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgC3QsdqAGpv"
      },
      "source": [
        "The `combOp` function simply aggrate all `zeroValues` into one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "glyhdIJD_hSt"
      },
      "outputs": [],
      "source": [
        "combOp = lambda px, py: ( px[0] + py[0], px[1] + py[1] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZlLtjOdAKKb"
      },
      "source": [
        "Implement `aggregate()` function.\n",
        "\n",
        "## `aggregateByKey(zeroValue, seqOp, combOp)`\n",
        "\n",
        "This function does similar things as `aggregate()`. The `aggregate()` aggregate all results to the very end, but aggregateByKey() merge results by key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "tBCyaw-fbqzH",
        "outputId": "4c36df01-95df-4681-bc73-5c5686e0d142"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5d005566-98ce-4752-9b6a-ae48f0623716\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5d005566-98ce-4752-9b6a-ae48f0623716\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VXY7bSm_hWg",
        "outputId": "b5bd809f-a0f9-416c-c130-20774385ef7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal_length,sepal_width,petal_length,petal_width,species',\n",
              " '5.1,3.5,1.4,0.2,setosa']"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "iris_rdd = sc.textFile('./iris.csv', use_unicode=True)\n",
        "iris_rdd.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zieFneZM_hhO",
        "outputId": "45a477fe-bcc7-4398-b5c9-d6d41573496b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('setosa', [5.1, 3.5, 1.4, 0.2]),\n",
              " ('setosa', [4.9, 3.0, 1.4, 0.2]),\n",
              " ('setosa', [4.7, 3.2, 1.3, 0.2]),\n",
              " ('setosa', [4.6, 3.1, 1.5, 0.2]),\n",
              " ('setosa', [5.0, 3.6, 1.4, 0.2])]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "iris_rdd_2 = iris_rdd.map(lambda x: x.split(',')).\\\n",
        "    filter(lambda x: x[0] != 'sepal_length').\\\n",
        "    map(lambda x: (x[-1], [*map(float, x[:-1])]))\n",
        "iris_rdd_2.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAA6f6XBA-8U"
      },
      "source": [
        "### Define initial values, seqOp and combOp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Ku4yf29f_hj_"
      },
      "outputs": [],
      "source": [
        "zero_value = (0, 0)\n",
        "seqOp = (lambda x, y: (x[0] + (y[0])**2, x[1] + (y[1])**2))\n",
        "combOp = (lambda x, y: (x[0] + y[0], x[1] + y[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plq1nnx18Dyp",
        "outputId": "d06864fb-8794-46ff-86c2-bf79b82d0d71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.<lambda>(x, y)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "seqOp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmxsXfkI8Fxt",
        "outputId": "efd13852-e386-4dfb-dbf2-35a2792341f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.<lambda>(x, y)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "combOp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXtUz-kHBCRu"
      },
      "source": [
        "### Implement `aggregateByKey()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdFloy6U_hnG",
        "outputId": "8df883af-b51c-493b-f155-b19caae5b8b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('setosa', (1259.0899999999997, 591.2500000000002)),\n",
              " ('versicolor', (1774.8600000000001, 388.47)),\n",
              " ('virginica', (2189.9000000000005, 447.33))]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "list_aggregated_iris = iris_rdd_2.aggregateByKey(zero_value, seqOp, combOp).collect()\n",
        "list_aggregated_iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "NrdO7Z7DBH4a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqFeBwtWOdYT"
      },
      "source": [
        "# Convert continuous variables to categorical variables\n",
        "\n",
        "There are two functions we can use to split a continuous variable into categories:\n",
        "\n",
        "* `pyspark.ml.feature.Binarizer`: split a column of continuous features given a threshold\n",
        "* `pyspark.ml.feature.Bucktizer`: split a column of continuous features into categories given several breaking points.\n",
        "    + with n+1 split points, there are n categories (buckets).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwM3XWqZObw8",
        "outputId": "f93b0ce7-d14b-4aeb-df08-586ae43cc11d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|                  x1|                x2|\n",
            "+--------------------+------------------+\n",
            "| 0.47143516373249306| 6.834629351721363|\n",
            "| -1.1909756947064645| 7.127020269829002|\n",
            "|  1.4327069684260973|3.7025075479039495|\n",
            "| -0.3126518960917129| 5.611961860656249|\n",
            "| -0.7205887333650116| 5.030831653078097|\n",
            "|  0.8871629403077386|0.1376844959068224|\n",
            "|  0.8595884137174165| 7.728266216123741|\n",
            "| -0.6365235044173491| 8.826411906361166|\n",
            "|0.015696372114428918| 3.648859839013723|\n",
            "| -2.2426849541854055| 6.153961784334937|\n",
            "+--------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(seed=1234)\n",
        "pdf = pd.DataFrame({\n",
        "        'x1': np.random.randn(10),\n",
        "        'x2': np.random.rand(10)*10\n",
        "    })\n",
        "np.random.seed(seed=None)\n",
        "df = spark.createDataFrame(pdf)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP4yy95mOpLr"
      },
      "source": [
        "## Binarize the column x1 and Bucketize the column x2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nI0bvdNObzn",
        "outputId": "ccdcb579-fb73-4de5-ffb9-3b7c83e4d94b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+------+------+\n",
            "|                  x1|                x2|x1_new|x2_new|\n",
            "+--------------------+------------------+------+------+\n",
            "| 0.47143516373249306| 6.834629351721363|   1.0|   2.0|\n",
            "| -1.1909756947064645| 7.127020269829002|   0.0|   2.0|\n",
            "|  1.4327069684260973|3.7025075479039495|   1.0|   1.0|\n",
            "| -0.3126518960917129| 5.611961860656249|   0.0|   2.0|\n",
            "| -0.7205887333650116| 5.030831653078097|   0.0|   2.0|\n",
            "|  0.8871629403077386|0.1376844959068224|   1.0|   0.0|\n",
            "|  0.8595884137174165| 7.728266216123741|   1.0|   3.0|\n",
            "| -0.6365235044173491| 8.826411906361166|   0.0|   3.0|\n",
            "|0.015696372114428918| 3.648859839013723|   1.0|   1.0|\n",
            "| -2.2426849541854055| 6.153961784334937|   0.0|   2.0|\n",
            "+--------------------+------------------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import Binarizer, Bucketizer\n",
        "# threshold = 0 for binarizer\n",
        "binarizer = Binarizer(threshold=0, inputCol='x1', outputCol='x1_new')\n",
        "# provide 5 split points to generate 4 buckets\n",
        "bucketizer = Bucketizer(splits=[0, 2.5, 5, 7.5, 10], inputCol='x2', outputCol='x2_new')\n",
        "\n",
        "# pipeline stages\n",
        "from pyspark.ml import Pipeline\n",
        "stages = [binarizer, bucketizer]\n",
        "pipeline = Pipeline(stages=stages)\n",
        "\n",
        "# fit the pipeline model and transform the data\n",
        "pipeline.fit(df).transform(df).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise:\n",
        "Do binarizer for `x2` the threshold `3`, and buckertizer `x1` with the split point is `[0.1, 0.3, 0.5, 0.7, 0.9]`."
      ],
      "metadata": {
        "id": "c9WPYhk3uyxI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "FyrGjOPOOb2Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DEwjsi3Oxh3"
      },
      "source": [
        "# Data Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWJlnBHsOb6e",
        "outputId": "c427a8ff-b8d1-426e-a120-25b982202b25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iris.csv  mtcars.csv  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "o5hawrqeOb8T",
        "outputId": "0b931205-48ff-45d4-e669-792cc531336c"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-37bdaea4-3bae-4c37-b28a-d73752db1544\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-37bdaea4-3bae-4c37-b28a-d73752db1544\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7ZmC3ENOb-Z"
      },
      "outputs": [],
      "source": [
        "titanic = spark.read.csv('./kaggle-titanic-train.csv', header=True, inferSchema=True)\n",
        "titanic.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A12HJEVKQ9UQ"
      },
      "source": [
        "## Data type\n",
        "\n",
        "First, we want to check if string and numeric variables are imported as we expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58_zZmOzOcAH"
      },
      "outputs": [],
      "source": [
        "titanic.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83C2f_XARDul"
      },
      "source": [
        "## Data summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICcWm8A5OcCN"
      },
      "outputs": [],
      "source": [
        "len(titanic.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pCx94eZOcDx"
      },
      "outputs": [],
      "source": [
        "titanic.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaqqogxaRKsJ"
      },
      "source": [
        "### Summarize *columns*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msYO6i1XOcFz"
      },
      "outputs": [],
      "source": [
        "def describe_columns(df):\n",
        "    for i in df.columns:\n",
        "        print('Column: ' + i)\n",
        "        titanic.select(i).describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUByBgo2OcHQ"
      },
      "outputs": [],
      "source": [
        "describe_columns(titanic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu1Ygo2uRZ6c"
      },
      "source": [
        "### Find columns with missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHHI7d3oRQSq"
      },
      "outputs": [],
      "source": [
        "def find_missing_values_columns(df):\n",
        "    nrow = df.count()\n",
        "    for v in df.columns:\n",
        "        summary_df = df.select(v).describe()\n",
        "        v_count = int(summary_df.collect()[0][v])\n",
        "        if v_count < nrow:\n",
        "            missing_percentage = (1 - v_count/nrow) * 100\n",
        "            print(\"Total observations: \" + str(nrow) + \"\\n\"\n",
        "                 \"Total observations of \" + v + \": \" + str(v_count) + \"\\n\"\n",
        "                 \"Percentage of missing values: \" + str(missing_percentage) + \"%\" + \"\\n\"\n",
        "                 \"----------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN109EJmRQWX"
      },
      "outputs": [],
      "source": [
        "find_missing_values_columns(titanic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqjbk8MhRQYm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrA8RH6MR1QN"
      },
      "source": [
        "# Subset selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPD233IUR30V"
      },
      "source": [
        "## Select Rows by index\n",
        "\n",
        "First, we need to add index to each rows. The **zipWithIndex** function zips the RDD elements with their corresponding index and returns the result as a new element."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahvmeUFoSKzr"
      },
      "outputs": [],
      "source": [
        "mtcars = spark.read.csv('./mtcars.csv', inferSchema=True, header=True)\n",
        "# correct first column name\n",
        "mtcars = mtcars.withColumnRenamed('_c0', 'model')\n",
        "mtcars.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dFrR1CnRQaT"
      },
      "outputs": [],
      "source": [
        "mtcars.rdd.zipWithIndex().take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1eNzmsFSP-b"
      },
      "source": [
        "Now we can apply the **map** function to modify the structure of each element. Assume **x** is an element from the above RDD object, **x** has two elements: x[0] and x[1]. x[0] is an **Row** object, and x[1] is the index, which is an integer. We want to merge these two values to create a list. And we also want the first element in the list is the index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5C7IHC91RQd9"
      },
      "outputs": [],
      "source": [
        "mtcars.rdd.zipWithIndex().map(lambda x: [x[1]] + list(x[0])).take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM5baUq4SU4t"
      },
      "source": [
        "Let's add column names and save the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF0JEZrYRQfs"
      },
      "outputs": [],
      "source": [
        "header = ['index'] + mtcars.columns\n",
        "mtcars_df = mtcars.rdd.zipWithIndex().map(lambda x: [x[1]] + list(x[0])).toDF(header)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Weqr9ng4SVwE"
      },
      "outputs": [],
      "source": [
        "mtcars_df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN_J6Rv6Scg4"
      },
      "source": [
        "After we obtain the **index column**, we can apply the **pyspark.sql.DataFrame.filter** function to select rows of the DataFrame. The **filter** function takes a **column** of **types.BooleanType** as input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvdYCvMmSfzj"
      },
      "source": [
        "### Select specific rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRtbGax9SVzx"
      },
      "outputs": [],
      "source": [
        "mtcars_df.filter(mtcars_df.index.isin([1,2,4,6,9])).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdfEyXOwSmpc"
      },
      "source": [
        "### Select rows between a range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "096G5_4vSV2E"
      },
      "outputs": [],
      "source": [
        "mtcars_df.filter(mtcars_df.index.between(5, 10)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EAObeWPSsyD"
      },
      "source": [
        "### Select rows by a cutoff index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR6Nz_x2RQix"
      },
      "outputs": [],
      "source": [
        "mtcars_df.filter(mtcars_df.index < 9).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9RxqqXFRQlm"
      },
      "outputs": [],
      "source": [
        "mtcars_df.filter(mtcars_df.index >= 14).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss-w5ub7S3Yw"
      },
      "source": [
        "## Select rows by logical criteria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dT0JE9gS7Rp"
      },
      "source": [
        "Example 1: select rows when **cyl = 4**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-1SdyMZSysK"
      },
      "outputs": [],
      "source": [
        "mtcars_df.filter(mtcars_df.cyl == 4).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6Z01nzOEEbn"
      },
      "outputs": [],
      "source": [
        "mtcars_df.filter(mtcars_df.cyl == 2).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IyYuNONS-mG"
      },
      "source": [
        "Example 2: select rows when **vs = 1 and am = 1**\n",
        "\n",
        "When the filtering is based on multiple **conditions** (e.g., **vs = 1** and **am = 1**), we use the conditions to build a new **boolean type column**. And we filter the DataFrame by the new column.\n",
        "\n",
        "<span style=\"color:red\">Warning: when passing multiple conditions to the **`when()`** function, each condition has to be within a pair of parentheses</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQTuzMBVSzcv"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHAuKvxvSzgg"
      },
      "outputs": [],
      "source": [
        "filtering_column = F.when((mtcars_df.vs == 1) & (mtcars_df.am == 1), 1).name('filter_col')\n",
        "filtering_column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxDiDMJ0TUkj"
      },
      "source": [
        "Now we need to add the new column to the original DataFrame. **This can be done by applying the `select()` function to select all original columns as well as the new filtering columns.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csCTgjmISzlI"
      },
      "outputs": [],
      "source": [
        "all_original_columns = [eval('mtcars_df.' + c) for c in mtcars_df.columns]\n",
        "all_original_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7AA8BiGSznY"
      },
      "outputs": [],
      "source": [
        "all_columns = all_original_columns + [filtering_column]\n",
        "all_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh4kNfXjSzpu"
      },
      "outputs": [],
      "source": [
        "new_mtcars_df = mtcars_df.select(all_columns)\n",
        "new_mtcars_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZkxi9lUTg-m"
      },
      "source": [
        "Now we can filter the DataFrame by the requested conditions. After we filter the DataFrame, we can drop the filtering column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvirQfTCSztj"
      },
      "outputs": [],
      "source": [
        "new_mtcars_df.filter(new_mtcars_df.filter_col == 1).drop('filter_col').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3So9716T8ZY"
      },
      "source": [
        "## Select columns by name\n",
        "\n",
        "We can simply use the **select()** function to select columns by name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a57h925GSzzM"
      },
      "outputs": [],
      "source": [
        "mtcars.select(['hp', 'disp']).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJmmWF51UDLP"
      },
      "source": [
        "## Select columns by index\n",
        "\n",
        "We can convert indices to corresponding column names and then select columns by name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZ3DK2c5Sz2a"
      },
      "outputs": [],
      "source": [
        "indices = [0,3,4,7]\n",
        "selected_columns =  [mtcars.columns[index] for index in indices]\n",
        "selected_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkUGsNK5Sz5g"
      },
      "outputs": [],
      "source": [
        "mtcars.select(selected_columns).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02IMgHWrUNOc"
      },
      "source": [
        "## Select columns by pattern\n",
        "\n",
        "Example: columns start with `d`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRmnfYiVSz8k"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "selected_columns = [x for x in mtcars.columns if re.compile('^d').match(x) is not None]\n",
        "selected_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG0nZJxnUKCM"
      },
      "outputs": [],
      "source": [
        "mtcars.select(selected_columns).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM7ZAChzUikT"
      },
      "source": [
        "# Column expression\n",
        "\n",
        "A Spark **column instance** is **NOT a column of values** from the **DataFrame**: when you crate a column instance, it does not give you the actual values of that column in the DataFrame. I found it makes more sense to me if I consider a **column instance as a column of expressions**. These expressions are evaluated by other methods (e.g., the **select()**, **groupby()**, and **orderby()** from **pyspark.sql.DataFrame**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYLhU6ldUmrC"
      },
      "source": [
        "## Use dot (.) to select column from DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crQLFCk1UKFb"
      },
      "outputs": [],
      "source": [
        "mpg_col = mtcars.mpg\n",
        "mpg_col"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-OiqVwWUsDX"
      },
      "source": [
        "## Modify a column to generate a new column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0klal6WUKIJ"
      },
      "outputs": [],
      "source": [
        "mpg_col + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz92LPASUKKW"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mpg_col * 100).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0OkQc6OU0U_"
      },
      "source": [
        "The `pyspark.sql.Column` has many methods that acts on a column and returns a column instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poecg4a9UKMT"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.gear.isin([2,3])).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJQfsSieSz-T"
      },
      "outputs": [],
      "source": [
        "mtcars.mpg.asc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn-rGb8kVF5k"
      },
      "source": [
        "## Dot (.) column expression\n",
        "\n",
        "Create a column expression that will return the original column values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YvQUX3nU5rz"
      },
      "outputs": [],
      "source": [
        "mpg_col_exp = mtcars.mpg\n",
        "mpg_col_exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HLjsSurU5uV"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mpg_col_exp).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-MlVmvkVWTG"
      },
      "source": [
        "## Boolean column expression\n",
        "\n",
        "Create a column expression that will return **boolean values**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFu3oBTJVZjT"
      },
      "source": [
        "## `between()`: true/false if the column value is between a given range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNjhxIhZU5xZ"
      },
      "outputs": [],
      "source": [
        "mpg_between = mtcars.cyl.between(4,6)\n",
        "mpg_between"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiNkr2K5U50W"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.cyl, mpg_between).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVgsijoGViE6"
      },
      "source": [
        "## `contains()`: true/false if the column value contains a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-5k8bJ7U52U"
      },
      "outputs": [],
      "source": [
        "model_contains = mtcars.model.contains('Ho')\n",
        "model_contains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d9xXQOfU55z"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.model, model_contains).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1t01hv0VnE4"
      },
      "source": [
        "## `endswith()`: true/false if the column value ends with a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBa4odltU576"
      },
      "outputs": [],
      "source": [
        "model_endswith = mtcars.model.endswith('t')\n",
        "model_endswith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqHfHxftU5-y"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.model, model_endswith).show(6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_xRLbPbVyGk"
      },
      "source": [
        "## `isNotNull()`: true/false if the column value is not Null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXqwJbq3U6BD"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Row\n",
        "df = spark.createDataFrame([Row(name='Tom', height=80), Row(name='Alice', height=None)])\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6Mt8G3uVzFJ"
      },
      "outputs": [],
      "source": [
        "height_isNotNull = df.height.isNotNull()\n",
        "height_isNotNull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-qlfsAnVzK9"
      },
      "outputs": [],
      "source": [
        "df.select(df.height, height_isNotNull).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQSr01cXV8oC"
      },
      "source": [
        "## `isNull()`: true/false if the column value is Null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgw2rTFdVzO4"
      },
      "outputs": [],
      "source": [
        "height_isNull = df.height.isNull()\n",
        "height_isNull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOkX2rRuVzRs"
      },
      "outputs": [],
      "source": [
        "df.select(df.height, height_isNull).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh_I6WAgWH3C"
      },
      "source": [
        "## `isin()`: true/false if the column value is contained by the evaluated argument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RhtC9PYVzU4"
      },
      "outputs": [],
      "source": [
        "carb_isin = mtcars.carb.isin([2, 3])\n",
        "carb_isin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivNn1TvEVzWv"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.carb, carb_isin).show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFRlYlskWQ_I"
      },
      "source": [
        "## `like()`: true/false if the column value matches a pattern based on a _SQL LIKE_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l00usXH4VzY2"
      },
      "outputs": [],
      "source": [
        "model_like = mtcars.model.like('Ho%')\n",
        "model_like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXfs_sJDWR3U"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.model, model_like).show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZXFi1WEWZ7K"
      },
      "source": [
        "## `rlike()`: true/false if the column value matches a pattern based on a _SQL RLIKE_ (LIKE with Regex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyqqCN8HWR6E"
      },
      "outputs": [],
      "source": [
        "model_rlike = mtcars.model.rlike('t$')\n",
        "model_rlike"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Teat8OqqWR_F"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.model, model_rlike).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ2fVEXkWjEC"
      },
      "source": [
        "## `startswith()`: true/false if the column value starts with a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFtFM5jXWSBt"
      },
      "outputs": [],
      "source": [
        "model_startswith = mtcars.model.startswith('Merc')\n",
        "model_startswith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mW_vtSLVWSEJ"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.model, model_startswith).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybnKevoGWSGq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odqiAOEdXEOX"
      },
      "source": [
        "# `pyspark.sql.functions` functions\n",
        "\n",
        "`pyspark.sql.functions` is collection of built-in functions for **creating column expressions**. These functions largely increase methods that we can use to manipulate DataFrame and DataFrame columns.\n",
        "\n",
        "There are many sql functions from the `pyspark.sql.functions` module. Here I only choose a few to show how these functions extend the ability to create column expressions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHU-xA9CWSJP"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFNaYPbFXKiM"
      },
      "source": [
        "## `abs()`: create column expression that returns absolute values of a column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUoRVCf0WSMR"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Row\n",
        "df = sc.parallelize([Row(x=1), Row(x=-1), Row(x=-2)]).toDF()\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKXOnqzmWSPb"
      },
      "outputs": [],
      "source": [
        "x_abs = F.abs(df.x)\n",
        "x_abs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WJ23LOMWSST"
      },
      "outputs": [],
      "source": [
        "df.select(df.x, x_abs).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xi6HVfTXV_I"
      },
      "source": [
        "## `concat()`: create column expression that concatenates multiple column values into one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHHSO80lWSUP"
      },
      "outputs": [],
      "source": [
        "df = sc.parallelize([Row(a='apple', b='tree'), Row(a='orange', b='flowers')]).toDF()\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyxlLEfXWSWm"
      },
      "outputs": [],
      "source": [
        "ab_concat = F.concat(df.a, df.b)\n",
        "ab_concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl4tmLFjWSZJ"
      },
      "outputs": [],
      "source": [
        "df.select(df.a, df.b, ab_concat).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1LremMJXfjv"
      },
      "source": [
        "## `corr()`: create column expression that returns pearson correlation coefficient between two columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ONql3HMVzcw"
      },
      "outputs": [],
      "source": [
        "# Reload the mtcars data\n",
        "mtcars = spark.read.csv('./mtcars.csv', inferSchema=True, header=True)\n",
        "mtcars.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk5oOiqcXgqO"
      },
      "outputs": [],
      "source": [
        "drat_wt_corr = F.corr(mtcars.drat, mtcars.wt)\n",
        "drat_wt_corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piXCHGaVXgs0"
      },
      "outputs": [],
      "source": [
        "mtcars.select(drat_wt_corr).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Eaw4xoFXx_f"
      },
      "source": [
        "## `array()`: create column expression that merge multiple column values into an array\n",
        "\n",
        "This function can be used to build **feature column** in machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbTrWjXgXgwJ"
      },
      "outputs": [],
      "source": [
        "cols = [eval('mtcars.' + col) for col in mtcars.columns[1:]]\n",
        "cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHSlAzNTXgzB"
      },
      "outputs": [],
      "source": [
        "cols_array = F.array(cols)\n",
        "cols_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JKKM10dXg1X"
      },
      "outputs": [],
      "source": [
        "mtcars.select(cols_array).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIgC5XONXg4q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYCqADDwYKZl"
      },
      "source": [
        "# `udf()` function and sql types\n",
        "\n",
        "\n",
        "The `pyspark.sql.functions.udf()` function is a very important function. It allows us to transfer a **user defined function** to a **`pyspark.sql.functions`** function which can act on columns of a DataFrame. It makes data framsformation much more flexible.\n",
        "\n",
        "Using `udf()` could be tricky. The key is to understand how to define the `returnType` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc_TrALqXg7K"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import udf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymuFb8YYXg9k"
      },
      "outputs": [],
      "source": [
        "# Reload mtcars data\n",
        "mtcars = spark.read.csv('./mtcars.csv', inferSchema=True, header=True)\n",
        "mtcars = mtcars.withColumnRenamed('_c0', 'model')\n",
        "mtcars.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVW4wANqYfGF"
      },
      "source": [
        "**The structure of the schema passed to `returnType` has to match the data structure of the return value from the user defined function**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDK-5VJsYgd7"
      },
      "source": [
        "**Case 1**: divide **disp** by **hp** and put the result to a new column\n",
        "\n",
        "The user defined function returns a float value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ft1QzN_IXhAC"
      },
      "outputs": [],
      "source": [
        "def disp_by_hp(disp, hp):\n",
        "    return(disp/hp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez-wkS2WXhCY"
      },
      "outputs": [],
      "source": [
        "disp_by_hp_udf = udf(disp_by_hp, returnType=FloatType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-sfypf2Vzfa"
      },
      "outputs": [],
      "source": [
        "all_original_cols = [eval('mtcars.' + x) for x in mtcars.columns]\n",
        "all_original_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ6vetw8YpMJ"
      },
      "outputs": [],
      "source": [
        "disp_by_hp_col = disp_by_hp_udf(mtcars.disp, mtcars.hp)\n",
        "disp_by_hp_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ9I9nz6Yppo"
      },
      "outputs": [],
      "source": [
        "all_new_cols = all_original_cols + [disp_by_hp_col]\n",
        "all_new_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikdhxS8vYps-"
      },
      "outputs": [],
      "source": [
        "mtcars.select(all_new_cols).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fdTKuUYYzWu"
      },
      "source": [
        "**case 2**: create an array column that contain **disp** and **hp** values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUn_jVc_Ypwi"
      },
      "outputs": [],
      "source": [
        "# define function\n",
        "def merge_two_columns(col1, col2):\n",
        "    return([float(col1), float(col2)])\n",
        "\n",
        "# convert user defined function into an udf function (sql function)\n",
        "array_merge_two_columns_udf = udf(merge_two_columns, returnType=ArrayType(FloatType()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GixPBqiUYp2P"
      },
      "outputs": [],
      "source": [
        "array_col = array_merge_two_columns_udf(mtcars.disp, mtcars.hp)\n",
        "array_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhVBzW2QYp6b"
      },
      "outputs": [],
      "source": [
        "all_new_cols = all_original_cols + [array_col]\n",
        "all_new_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BiIWG34YqBV"
      },
      "outputs": [],
      "source": [
        "mtcars.select(all_new_cols).show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzGOJLBhZAHz"
      },
      "source": [
        "## `ArrayType` vs. `StructType`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNbcIXboZAPA"
      },
      "source": [
        "Both `ArrayType` and `StructType` can be used to build `returnType` for a list. The difference is:\n",
        "\n",
        "1. `ArrayType` requires all elements in the list have the same `elementType`, while `StructType` can have different `elementTypes`.\n",
        "2. `StructType` represents a `Row` object.\n",
        "\n",
        "\n",
        "**Define an `ArrayType` with elementType being `FloatType`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDU3JJRcYqEJ"
      },
      "outputs": [],
      "source": [
        "# define function\n",
        "def merge_two_columns(col1, col2):\n",
        "    return([float(col1), float(col2)])\n",
        "array_type = ArrayType(FloatType())\n",
        "array_merge_two_columns_udf = udf(merge_two_columns, returnType=array_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py-l78MNZPW0"
      },
      "source": [
        "**Define a `StructType` with one elementType being `StringType` and the other being `FloatType`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qjs5af3dYqH0"
      },
      "outputs": [],
      "source": [
        "# define function\n",
        "def merge_two_columns(col1, col2):\n",
        "    return([str(col1), float(col2)])\n",
        "struct_type = StructType([\n",
        "    StructField('f1', StringType()),\n",
        "    StructField('f2', FloatType())\n",
        "])\n",
        "struct_merge_two_columns_udf = udf(merge_two_columns, returnType=struct_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eil3Mq4rZVKE"
      },
      "source": [
        "**array column** expression: both values are float type values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmcMZr_rYqKt"
      },
      "outputs": [],
      "source": [
        "array_col = array_merge_two_columns_udf(mtcars.hp, mtcars.disp)\n",
        "array_col"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHKux8hhZbdL"
      },
      "source": [
        "**struct column** expression: first value is a string and the second value is a float type value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTkisZDAZSQ4"
      },
      "outputs": [],
      "source": [
        "struct_col = struct_merge_two_columns_udf(mtcars.model, mtcars.disp)\n",
        "struct_col"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6au8SaKZfIe"
      },
      "source": [
        "**Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBrmB8rEZSTf"
      },
      "outputs": [],
      "source": [
        "mtcars.select(array_col, struct_col).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lq7XSVw6ZSXy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pMotE7XZSa1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59iDgwn0ZSdW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQEGjhbcZShc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Efdc8Z77ZSku"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTK6ikabZSnu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}