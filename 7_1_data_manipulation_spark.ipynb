{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyri0n11/distributed-system/blob/main/7_1_data_manipulation_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G3_5j4Ra-Cgs"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "from pyspark.sql import SparkSession\n",
        "sc = SparkContext()\n",
        "spark = SparkSession(sparkContext=sc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "8lf6GG2TDM2s",
        "outputId": "0e8188b8-c2b2-4a0d-99aa-87e9285d4734"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x784f159b7d10>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://fcc9f69b20be:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.5.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>pyspark-shell</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ijjMPfI-Iuy"
      },
      "source": [
        "## Map functions\n",
        "\n",
        "These functions are probably the most commonly used functions when dealing with an RDD object.\n",
        "\n",
        "* `map()`\n",
        "* `mapValues()`\n",
        "* `flatMap()`\n",
        "* `flatMapValues()`\n",
        "\n",
        "### `map`\n",
        "\n",
        "The `map()` method applies a function to each elements of the RDD. Each element has to be a valid input to the function. The returned RDD has the function outputs as its new elements.\n",
        "\n",
        "Elements in the RDD object `map_exp_rdd` below are rows of the `mtcars` in string format. We are going to apply the `map()` function multiple times to convert each string elements as a list elements. Each list element has two values: the first value will be the auto model in string format; the second value will be a list of numeric values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "AsBPdKp6QU52",
        "outputId": "299836dd-65e0-4210-a8d9-d479159addb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Unnamed: 0   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
              "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
              "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
              "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
              "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
              "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
              "\n",
              "   carb  \n",
              "0     4  \n",
              "1     4  \n",
              "2     1  \n",
              "3     1  \n",
              "4     2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-da327a01-84d3-4445-adeb-2447199626a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>mpg</th>\n",
              "      <th>cyl</th>\n",
              "      <th>disp</th>\n",
              "      <th>hp</th>\n",
              "      <th>drat</th>\n",
              "      <th>wt</th>\n",
              "      <th>qsec</th>\n",
              "      <th>vs</th>\n",
              "      <th>am</th>\n",
              "      <th>gear</th>\n",
              "      <th>carb</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mazda RX4</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6</td>\n",
              "      <td>160.0</td>\n",
              "      <td>110</td>\n",
              "      <td>3.90</td>\n",
              "      <td>2.620</td>\n",
              "      <td>16.46</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mazda RX4 Wag</td>\n",
              "      <td>21.0</td>\n",
              "      <td>6</td>\n",
              "      <td>160.0</td>\n",
              "      <td>110</td>\n",
              "      <td>3.90</td>\n",
              "      <td>2.875</td>\n",
              "      <td>17.02</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Datsun 710</td>\n",
              "      <td>22.8</td>\n",
              "      <td>4</td>\n",
              "      <td>108.0</td>\n",
              "      <td>93</td>\n",
              "      <td>3.85</td>\n",
              "      <td>2.320</td>\n",
              "      <td>18.61</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hornet 4 Drive</td>\n",
              "      <td>21.4</td>\n",
              "      <td>6</td>\n",
              "      <td>258.0</td>\n",
              "      <td>110</td>\n",
              "      <td>3.08</td>\n",
              "      <td>3.215</td>\n",
              "      <td>19.44</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hornet Sportabout</td>\n",
              "      <td>18.7</td>\n",
              "      <td>8</td>\n",
              "      <td>360.0</td>\n",
              "      <td>175</td>\n",
              "      <td>3.15</td>\n",
              "      <td>3.440</td>\n",
              "      <td>17.02</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-da327a01-84d3-4445-adeb-2447199626a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-da327a01-84d3-4445-adeb-2447199626a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-da327a01-84d3-4445-adeb-2447199626a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-4823ef4f-2f1d-4c76-bcfd-7b24c7d57477\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4823ef4f-2f1d-4c76-bcfd-7b24c7d57477')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-4823ef4f-2f1d-4c76-bcfd-7b24c7d57477 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "mtcar_data",
              "summary": "{\n  \"name\": \"mtcar_data\",\n  \"rows\": 32,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 32,\n        \"samples\": [\n          \"Ferrari Dino\",\n          \"Lincoln Continental\",\n          \"Pontiac Firebird\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"mpg\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6.026948052089105,\n        \"min\": 10.4,\n        \"max\": 33.9,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          17.8,\n          33.9,\n          21.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cyl\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 4,\n        \"max\": 8,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6,\n          4,\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"disp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 123.93869383138194,\n        \"min\": 71.1,\n        \"max\": 472.0,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          275.8,\n          75.7,\n          472.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"hp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 68,\n        \"min\": 52,\n        \"max\": 335,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          110,\n          52,\n          180\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"drat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5346787360709716,\n        \"min\": 2.76,\n        \"max\": 4.93,\n        \"num_unique_values\": 22,\n        \"samples\": [\n          3.9,\n          4.93,\n          3.07\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"wt\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9784574429896967,\n        \"min\": 1.513,\n        \"max\": 5.424,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          2.77,\n          1.615,\n          5.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"qsec\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.7869432360968431,\n        \"min\": 14.5,\n        \"max\": 22.9,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          15.5,\n          17.42,\n          17.05\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vs\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"am\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"gear\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 3,\n        \"max\": 5,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"carb\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "mtcar_data = pd.read_csv('./mtcars.csv')\n",
        "mtcar_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "oMcc5mCPDaUZ",
        "outputId": "84cebb4a-050c-442e-cd49-946d8e016185"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pandas.core.frame.DataFrame</b><br/>def __init__(data=None, index: Axes | None=None, columns: Axes | None=None, dtype: Dtype | None=None, copy: bool | None=None) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py</a>Two-dimensional, size-mutable, potentially heterogeneous tabular data.\n",
              "\n",
              "Data structure also contains labeled axes (rows and columns).\n",
              "Arithmetic operations align on both row and column labels. Can be\n",
              "thought of as a dict-like container for Series objects. The primary\n",
              "pandas data structure.\n",
              "\n",
              "Parameters\n",
              "----------\n",
              "data : ndarray (structured or homogeneous), Iterable, dict, or DataFrame\n",
              "    Dict can contain Series, arrays, constants, dataclass or list-like objects. If\n",
              "    data is a dict, column order follows insertion-order. If a dict contains Series\n",
              "    which have an index defined, it is aligned by its index. This alignment also\n",
              "    occurs if data is a Series or a DataFrame itself. Alignment is done on\n",
              "    Series/DataFrame inputs.\n",
              "\n",
              "    If data is a list of dicts, column order follows insertion-order.\n",
              "\n",
              "index : Index or array-like\n",
              "    Index to use for resulting frame. Will default to RangeIndex if\n",
              "    no indexing information part of input data and no index provided.\n",
              "columns : Index or array-like\n",
              "    Column labels to use for resulting frame when data does not have them,\n",
              "    defaulting to RangeIndex(0, 1, 2, ..., n). If data contains column labels,\n",
              "    will perform column selection instead.\n",
              "dtype : dtype, default None\n",
              "    Data type to force. Only a single dtype is allowed. If None, infer.\n",
              "copy : bool or None, default None\n",
              "    Copy data from inputs.\n",
              "    For dict data, the default of None behaves like ``copy=True``.  For DataFrame\n",
              "    or 2d ndarray input, the default of None behaves like ``copy=False``.\n",
              "    If data is a dict containing one or more Series (possibly of different dtypes),\n",
              "    ``copy=False`` will ensure that these inputs are not copied.\n",
              "\n",
              "    .. versionchanged:: 1.3.0\n",
              "\n",
              "See Also\n",
              "--------\n",
              "DataFrame.from_records : Constructor from tuples, also record arrays.\n",
              "DataFrame.from_dict : From dicts of Series, arrays, or dicts.\n",
              "read_csv : Read a comma-separated values (csv) file into DataFrame.\n",
              "read_table : Read general delimited file into DataFrame.\n",
              "read_clipboard : Read text from clipboard into DataFrame.\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Please reference the :ref:`User Guide &lt;basics.dataframe&gt;` for more information.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "Constructing DataFrame from a dictionary.\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [1, 2], &#x27;col2&#x27;: [3, 4]}\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d)\n",
              "&gt;&gt;&gt; df\n",
              "   col1  col2\n",
              "0     1     3\n",
              "1     2     4\n",
              "\n",
              "Notice that the inferred dtype is int64.\n",
              "\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int64\n",
              "col2    int64\n",
              "dtype: object\n",
              "\n",
              "To enforce a single dtype:\n",
              "\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=d, dtype=np.int8)\n",
              "&gt;&gt;&gt; df.dtypes\n",
              "col1    int8\n",
              "col2    int8\n",
              "dtype: object\n",
              "\n",
              "Constructing DataFrame from a dictionary including Series:\n",
              "\n",
              "&gt;&gt;&gt; d = {&#x27;col1&#x27;: [0, 1, 2, 3], &#x27;col2&#x27;: pd.Series([2, 3], index=[2, 3])}\n",
              "&gt;&gt;&gt; pd.DataFrame(data=d, index=[0, 1, 2, 3])\n",
              "   col1  col2\n",
              "0     0   NaN\n",
              "1     1   NaN\n",
              "2     2   2.0\n",
              "3     3   3.0\n",
              "\n",
              "Constructing DataFrame from numpy ndarray:\n",
              "\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]]),\n",
              "...                    columns=[&#x27;a&#x27;, &#x27;b&#x27;, &#x27;c&#x27;])\n",
              "&gt;&gt;&gt; df2\n",
              "   a  b  c\n",
              "0  1  2  3\n",
              "1  4  5  6\n",
              "2  7  8  9\n",
              "\n",
              "Constructing DataFrame from a numpy ndarray that has labeled columns:\n",
              "\n",
              "&gt;&gt;&gt; data = np.array([(1, 2, 3), (4, 5, 6), (7, 8, 9)],\n",
              "...                 dtype=[(&quot;a&quot;, &quot;i4&quot;), (&quot;b&quot;, &quot;i4&quot;), (&quot;c&quot;, &quot;i4&quot;)])\n",
              "&gt;&gt;&gt; df3 = pd.DataFrame(data, columns=[&#x27;c&#x27;, &#x27;a&#x27;])\n",
              "...\n",
              "&gt;&gt;&gt; df3\n",
              "   c  a\n",
              "0  3  1\n",
              "1  6  4\n",
              "2  9  7\n",
              "\n",
              "Constructing DataFrame from dataclass:\n",
              "\n",
              "&gt;&gt;&gt; from dataclasses import make_dataclass\n",
              "&gt;&gt;&gt; Point = make_dataclass(&quot;Point&quot;, [(&quot;x&quot;, int), (&quot;y&quot;, int)])\n",
              "&gt;&gt;&gt; pd.DataFrame([Point(0, 0), Point(0, 3), Point(2, 3)])\n",
              "   x  y\n",
              "0  0  0\n",
              "1  0  3\n",
              "2  2  3\n",
              "\n",
              "Constructing DataFrame from Series/DataFrame:\n",
              "\n",
              "&gt;&gt;&gt; ser = pd.Series([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df = pd.DataFrame(data=ser, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df\n",
              "   0\n",
              "a  1\n",
              "c  3\n",
              "\n",
              "&gt;&gt;&gt; df1 = pd.DataFrame([1, 2, 3], index=[&quot;a&quot;, &quot;b&quot;, &quot;c&quot;], columns=[&quot;x&quot;])\n",
              "&gt;&gt;&gt; df2 = pd.DataFrame(data=df1, index=[&quot;a&quot;, &quot;c&quot;])\n",
              "&gt;&gt;&gt; df2\n",
              "   x\n",
              "a  1\n",
              "c  3</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 509);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "type(mtcar_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oQWrMZg-CoA",
        "outputId": "a2fd8f33-0f52-462a-b792-432e720c6fbe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[',mpg,cyl,disp,hp,drat,wt,qsec,vs,am,gear,carb',\n",
              " 'Mazda RX4,21,6,160,110,3.9,2.62,16.46,0,1,4,4',\n",
              " 'Mazda RX4 Wag,21,6,160,110,3.9,2.875,17.02,0,1,4,4',\n",
              " 'Datsun 710,22.8,4,108,93,3.85,2.32,18.61,1,1,4,1']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# create an example RDD\n",
        "map_exp_rdd = sc.textFile('./mtcars.csv')\n",
        "map_exp_rdd.take(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "KBPQTzWHDgK4",
        "outputId": "cae93dd6-f96d-4dc6-da18-08625b22ed4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.RDD</b><br/>def __init__(jrdd: &#x27;JavaObject&#x27;, ctx: &#x27;SparkContext&#x27;, jrdd_deserializer: Serializer=AutoBatchedSerializer(CPickleSerializer()))</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/rdd.py</a>A Resilient Distributed Dataset (RDD), the basic abstraction in Spark.\n",
              "Represents an immutable, partitioned collection of elements that can be\n",
              "operated on in parallel.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 336);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "type(map_exp_rdd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mvhoaSu-Cqx",
        "outputId": "63dcad10-38bd-4a3d-ac4e-873dc7ff1aaf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('',\n",
              "  ['mpg',\n",
              "   'cyl',\n",
              "   'disp',\n",
              "   'hp',\n",
              "   'drat',\n",
              "   'wt',\n",
              "   'qsec',\n",
              "   'vs',\n",
              "   'am',\n",
              "   'gear',\n",
              "   'carb']),\n",
              " ('Mazda RX4',\n",
              "  ['21', '6', '160', '110', '3.9', '2.62', '16.46', '0', '1', '4', '4']),\n",
              " ('Mazda RX4 Wag',\n",
              "  ['21', '6', '160', '110', '3.9', '2.875', '17.02', '0', '1', '4', '4']),\n",
              " ('Datsun 710',\n",
              "  ['22.8', '4', '108', '93', '3.85', '2.32', '18.61', '1', '1', '4', '1'])]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# split auto model from other feature values\n",
        "map_exp_rdd_1 = map_exp_rdd.map(lambda x: x.split(',')).map(lambda x: (x[0], x[1:]))\n",
        "map_exp_rdd_1.take(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24fAuUw8-Cr_",
        "outputId": "ca5b11bc-1fa1-4f60-95eb-9b390fdf87d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4',\n",
              "  ['21', '6', '160', '110', '3.9', '2.62', '16.46', '0', '1', '4', '4']),\n",
              " ('Mazda RX4 Wag',\n",
              "  ['21', '6', '160', '110', '3.9', '2.875', '17.02', '0', '1', '4', '4']),\n",
              " ('Datsun 710',\n",
              "  ['22.8', '4', '108', '93', '3.85', '2.32', '18.61', '1', '1', '4', '1']),\n",
              " ('Hornet 4 Drive',\n",
              "  ['21.4', '6', '258', '110', '3.08', '3.215', '19.44', '1', '0', '3', '1'])]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# remove the header row\n",
        "header = map_exp_rdd_1.first()\n",
        "# the filter method apply a function to each elemnts. The function output is a boolean value (TRUE or FALSE)\n",
        "# elements that have output TRUE will be kept.\n",
        "map_exp_rdd_2 = map_exp_rdd_1.filter(lambda x: x != header)\n",
        "map_exp_rdd_2.take(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSZDalUC-Cuu",
        "outputId": "27024601-90fb-42fa-d861-6689804a8d44"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4',\n",
              "  [21.0, 6.0, 160.0, 110.0, 3.9, 2.62, 16.46, 0.0, 1.0, 4.0, 4.0]),\n",
              " ('Mazda RX4 Wag',\n",
              "  [21.0, 6.0, 160.0, 110.0, 3.9, 2.875, 17.02, 0.0, 1.0, 4.0, 4.0]),\n",
              " ('Datsun 710',\n",
              "  [22.8, 4.0, 108.0, 93.0, 3.85, 2.32, 18.61, 1.0, 1.0, 4.0, 1.0]),\n",
              " ('Hornet 4 Drive',\n",
              "  [21.4, 6.0, 258.0, 110.0, 3.08, 3.215, 19.44, 1.0, 0.0, 3.0, 1.0])]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# convert string values to numeric values\n",
        "map_exp_rdd_3 = map_exp_rdd_2.map(lambda x: (x[0], list(map(float, x[1]))))\n",
        "map_exp_rdd_3.take(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8w9I4ss5-v82"
      },
      "source": [
        "### `mapValues`\n",
        "\n",
        "The `mapValues` function requires that each element in the RDD has a **key/value** pair structure, for example, a tuple of 2 items, or a list of 2 items. The `mapValues` function applies a function to each of the element values. The element key will remain unchanged.\n",
        "\n",
        "We can apply the `mapValues` function to the RDD object `mapValues_exp_rdd` below.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mKh4etX-Cw4",
        "outputId": "efea15f2-97de-4111-9dbf-7c5e145740bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4',\n",
              "  [21.0, 6.0, 160.0, 110.0, 3.9, 2.62, 16.46, 0.0, 1.0, 4.0, 4.0]),\n",
              " ('Mazda RX4 Wag',\n",
              "  [21.0, 6.0, 160.0, 110.0, 3.9, 2.875, 17.02, 0.0, 1.0, 4.0, 4.0]),\n",
              " ('Datsun 710',\n",
              "  [22.8, 4.0, 108.0, 93.0, 3.85, 2.32, 18.61, 1.0, 1.0, 4.0, 1.0]),\n",
              " ('Hornet 4 Drive',\n",
              "  [21.4, 6.0, 258.0, 110.0, 3.08, 3.215, 19.44, 1.0, 0.0, 3.0, 1.0])]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "mapValues_exp_rdd = map_exp_rdd_3\n",
        "mapValues_exp_rdd.take(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4p9NHPBl-rUr",
        "outputId": "1faced94-1f28-4678-a5d8-0a784e509d5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4', np.float64(29.90727272727273)),\n",
              " ('Mazda RX4 Wag', np.float64(29.98136363636364)),\n",
              " ('Datsun 710', np.float64(23.59818181818182)),\n",
              " ('Hornet 4 Drive', np.float64(38.73954545454546))]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "import numpy as np\n",
        "mapValues_exp_rdd_1 = mapValues_exp_rdd.mapValues(lambda x: np.mean(x))\n",
        "mapValues_exp_rdd_1.take(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz1LndcqESO2",
        "outputId": "008ccd13-7dcc-46fb-f805-46f0e4ddf724"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4', np.float64(0.0)),\n",
              " ('Mazda RX4 Wag', np.float64(0.0)),\n",
              " ('Datsun 710', np.float64(1.0)),\n",
              " ('Hornet 4 Drive', np.float64(0.0))]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "import numpy as np\n",
        "mapValues_exp_rdd_2 = mapValues_exp_rdd.mapValues(lambda x: np.min(x))\n",
        "mapValues_exp_rdd_2.take(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL6sak0QE0tm",
        "outputId": "9bb328e2-640d-4547-a4a4-a5be8d2e6aa6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4', np.float64(80.0)),\n",
              " ('Mazda RX4 Wag', np.float64(80.0)),\n",
              " ('Datsun 710', np.float64(54.5)),\n",
              " ('Hornet 4 Drive', np.float64(129.0))]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import numpy as np\n",
        "mapValues_exp_rdd_3 = mapValues_exp_rdd.mapValues(lambda x: (np.min(x)+np.max(x))/2)\n",
        "mapValues_exp_rdd_3.take(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjbtOMSz-4Sm"
      },
      "source": [
        "When using `mapValues()`, the x in the above lambda function refers to the element value, not including the element key."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Provide more examples of `mapValues()` in Spark\n",
        "\n",
        "# Calculate the sum of all values for each key\n",
        "mapValues_exp_rdd_4 = mapValues_exp_rdd.mapValues(lambda x: sum(x))\n",
        "mapValues_exp_rdd_4.take(4)\n",
        "\n",
        "# Find the maximum value for each key\n",
        "mapValues_exp_rdd_5 = mapValues_exp_rdd.mapValues(lambda x: max(x))\n",
        "mapValues_exp_rdd_5.take(4)\n",
        "\n",
        "# Convert each value (a list of floats) to a numpy array\n",
        "mapValues_exp_rdd_6 = mapValues_exp_rdd.mapValues(lambda x: np.array(x))\n",
        "mapValues_exp_rdd_6.take(4)\n",
        "\n",
        "# Apply a custom function to each value\n",
        "def custom_function(values):\n",
        "  \"\"\"Example custom function that calculates the range of a list of numbers\"\"\"\n",
        "  return max(values) - min(values)\n",
        "\n",
        "mapValues_exp_rdd_7 = mapValues_exp_rdd.mapValues(custom_function)\n",
        "mapValues_exp_rdd_7.take(4)\n",
        "\n",
        "# Example with a conditional operation: square values if the minimum is > 5\n",
        "mapValues_exp_rdd_8 = mapValues_exp_rdd.mapValues(lambda x: [val**2 for val in x] if min(x) > 5 else x)\n",
        "mapValues_exp_rdd_8.take(4)\n"
      ],
      "metadata": {
        "id": "eubdA5ADpHQ9",
        "outputId": "92af09ef-8fcb-407c-9d15-c40481b13f23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Mazda RX4',\n",
              "  [21.0, 6.0, 160.0, 110.0, 3.9, 2.62, 16.46, 0.0, 1.0, 4.0, 4.0]),\n",
              " ('Mazda RX4 Wag',\n",
              "  [21.0, 6.0, 160.0, 110.0, 3.9, 2.875, 17.02, 0.0, 1.0, 4.0, 4.0]),\n",
              " ('Datsun 710',\n",
              "  [22.8, 4.0, 108.0, 93.0, 3.85, 2.32, 18.61, 1.0, 1.0, 4.0, 1.0]),\n",
              " ('Hornet 4 Drive',\n",
              "  [21.4, 6.0, 258.0, 110.0, 3.08, 3.215, 19.44, 1.0, 0.0, 3.0, 1.0])]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffBYhyPy-86E"
      },
      "source": [
        "### `flatMap`\n",
        "\n",
        "This function first applies a function to each elements of an RDD and then flatten the results. We can simply use this function to flatten elements of an RDD without extra operation on each elements.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk30p-v4-rXn",
        "outputId": "114d6a59-6633-4ef6-db1d-6b7ba44a9a89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('a', 'b', 'c'), ('a', 'a'), ('c', 'c', 'c', 'd')]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "x = [('a', 'b', 'c'), ('a', 'a'), ('c', 'c', 'c', 'd')]\n",
        "flatMap_exp_rdd = sc.parallelize(x)\n",
        "flatMap_exp_rdd.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcbjRXZ4-ral",
        "outputId": "efbafa49-d477-4d14-c779-c865d11c1008"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'b', 'c', 'a', 'a', 'c', 'c', 'c', 'd']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "flatMap_exp_rdd_1 = flatMap_exp_rdd.flatMap(lambda x: x)\n",
        "flatMap_exp_rdd_1.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "8y8Q7ioXFTfF",
        "outputId": "a5436b1c-dd55-47e7-ebe4-b9ee6cb9f192"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.rdd.PipelinedRDD"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.rdd.PipelinedRDD</b><br/>def __init__(prev: RDD[T], func: Callable[[int, Iterable[T]], Iterable[U]], preservesPartitioning: bool=False, isFromBarrier: bool=False)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/rdd.py</a>Examples\n",
              "--------\n",
              "Pipelined maps:\n",
              "\n",
              "&gt;&gt;&gt; rdd = sc.parallelize([1, 2, 3, 4])\n",
              "&gt;&gt;&gt; rdd.map(lambda x: 2 * x).cache().map(lambda x: 2 * x).collect()\n",
              "[4, 8, 12, 16]\n",
              "&gt;&gt;&gt; rdd.map(lambda x: 2 * x).map(lambda x: 2 * x).collect()\n",
              "[4, 8, 12, 16]\n",
              "\n",
              "Pipelined reduces:\n",
              "\n",
              "&gt;&gt;&gt; from operator import add\n",
              "&gt;&gt;&gt; rdd.map(lambda x: 2 * x).reduce(add)\n",
              "20\n",
              "&gt;&gt;&gt; rdd.flatMap(lambda x: [x, x]).reduce(add)\n",
              "20</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 5395);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "type(flatMap_exp_rdd_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9L609dD_Fwf"
      },
      "source": [
        "### `flatMapValues`\n",
        "\n",
        "The `flatMapValues` function requires that each element in the RDD has a **key/value** pair structure. It applies a function to each **element value** of the RDD object and then flatten the results.\n",
        "\n",
        "For example, my raw data looks like below. But I would like to transform the data so that it has three columns: the first column is the **sample id**; the second the column is the three **types (A,B or C)**; the third column is the **values**.\n",
        "\n",
        "| sample id |  A |  B |  C |\n",
        "|:---------:|:--:|:--:|:--:|\n",
        "|     1     | 23 | 18 | 32 |\n",
        "|     2     | 18 | 29 | 31 |\n",
        "|     3     | 34 | 21 | 18 |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctnKvigZ-rcp",
        "outputId": "117886f5-f200-49e9-eaf5-ffe8e1ff17c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, (23, 28, 32)], [2, (18, 29, 31)], [3, (34, 21, 18)]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# example data\n",
        "my_data = [\n",
        "    [1, (23, 28, 32)],\n",
        "    [2, (18, 29, 31)],\n",
        "    [3, (34, 21, 18)]\n",
        "]\n",
        "flatMapValues_exp_rdd = sc.parallelize(my_data)\n",
        "flatMapValues_exp_rdd.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOMbRpv__I7F",
        "outputId": "2627d290-5b4a-4ba5-96ed-c026dfe51b53"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(1, ('A', 23)),\n",
              " (1, ('B', 28)),\n",
              " (1, ('C', 32)),\n",
              " (2, ('A', 18)),\n",
              " (2, ('B', 29)),\n",
              " (2, ('C', 31)),\n",
              " (3, ('A', 34)),\n",
              " (3, ('B', 21)),\n",
              " (3, ('C', 18))]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# merge A,B,and C columns into one column and add the type column\n",
        "flatMapValues_exp_rdd_1 = flatMapValues_exp_rdd.flatMapValues(lambda x: list(zip(list('ABC'), x)))\n",
        "flatMapValues_exp_rdd_1.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XLkEqaB_LXa",
        "outputId": "1444106f-06ed-40fa-8ffc-5b2c0b8e3326"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 'A', 23],\n",
              " [1, 'B', 28],\n",
              " [1, 'C', 32],\n",
              " [2, 'A', 18],\n",
              " [2, 'B', 29],\n",
              " [2, 'C', 31],\n",
              " [3, 'A', 34],\n",
              " [3, 'B', 21],\n",
              " [3, 'C', 18]]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# unpack the element values\n",
        "flatMapValues_exp_rdd_2 = flatMapValues_exp_rdd_1.map(lambda x: [x[0]] + list(x[1]) )\n",
        "flatMapValues_exp_rdd_2.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "IkCtkPeG_OGk",
        "outputId": "10f80736-3501-47d5-89f8-bc01ccdd30ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('key1', ('even', 10)), ('key2', ('odd', 25))]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# prompt: Provide more examples of `flatMapValues()` in Pyspark\n",
        "\n",
        "# Example 1: Expanding a list of words associated with each key\n",
        "data = [('doc1', ['apple', 'banana']), ('doc2', ['orange', 'grape', 'kiwi'])]\n",
        "rdd = sc.parallelize(data)\n",
        "\n",
        "# Apply flatMapValues to expand the list of words into individual elements.\n",
        "expanded_rdd = rdd.flatMapValues(lambda words: words)\n",
        "expanded_rdd.collect()  # Output: [('doc1', 'apple'), ('doc1', 'banana'), ('doc2', 'orange'), ('doc2', 'grape'), ('doc2', 'kiwi')]\n",
        "\n",
        "\n",
        "# Example 2: Processing a list of tuples associated with each key.\n",
        "data2 = [('user1', [('productA', 5), ('productB', 2)]), ('user2', [('productC', 1), ('productA', 3)])]\n",
        "rdd2 = sc.parallelize(data2)\n",
        "\n",
        "# Separate product and quantity for each user.\n",
        "product_quantities = rdd2.flatMapValues(lambda purchases: purchases)\n",
        "product_quantities.collect() # Output: [('user1', ('productA', 5)), ('user1', ('productB', 2)), ('user2', ('productC', 1)), ('user2', ('productA', 3))]\n",
        "\n",
        "# Example 3: Splitting strings based on a delimiter\n",
        "data3 = [('sentence1', 'this is a test sentence'), ('sentence2', 'another example')]\n",
        "rdd3 = sc.parallelize(data3)\n",
        "\n",
        "# Split each sentence into words.\n",
        "words_rdd = rdd3.flatMapValues(lambda sentence: sentence.split())\n",
        "words_rdd.collect() # Output: [('sentence1', 'this'), ('sentence1', 'is'), ('sentence1', 'a'), ('sentence1', 'test'), ('sentence1', 'sentence'), ('sentence2', 'another'), ('sentence2', 'example')]\n",
        "\n",
        "\n",
        "# Example 4: Generating multiple key-value pairs from each original value\n",
        "data4 = [('key1', 10), ('key2', 25)]\n",
        "rdd4 = sc.parallelize(data4)\n",
        "\n",
        "\n",
        "# Generate key-value pairs based on whether values are even or odd\n",
        "def process_number(num):\n",
        "    if num % 2 == 0:\n",
        "      return [('even', num)]\n",
        "    else:\n",
        "      return [('odd', num)]\n",
        "\n",
        "processed_rdd = rdd4.flatMapValues(process_number)\n",
        "processed_rdd.collect() # Output: [('key1', ('even', 10)), ('key2', ('odd', 25))]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryl-6ZCB_gbu"
      },
      "source": [
        "## Aggregate functions\n",
        "Two aggregate functions:\n",
        "\n",
        "* `aggregate()`\n",
        "* `aggregateByKey()`\n",
        "\n",
        "### `aggregate(zeroValue, seqOp, combOp)`\n",
        "\n",
        "* **zeroValue** is like a data container. Its structure should match with the data structure of the returned values from the seqOp function.\n",
        "* **seqOp** is a function that takes two arguments: the first argument is the zeroValue and the second argument is an element from the RDD. The zeroValue gets updated with the returned value after every run.\n",
        "* **combOp** is a function that takes two arguments: the first argument is the final zeroValue from one partition and the other is another final zeroValue from another partition.\n",
        "\n",
        "The code below calculates the total sum of squares for **mpg** and **disp** in data set **mtcars**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLrIvL6Y_l0N"
      },
      "source": [
        "Step 1: get some data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DP9Remgv_hII",
        "outputId": "dd9c183c-4577-47c3-f418-0367949b3476"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(mpg=21.0, disp=160.0),\n",
              " Row(mpg=21.0, disp=160.0),\n",
              " Row(mpg=22.8, disp=108.0),\n",
              " Row(mpg=21.4, disp=258.0),\n",
              " Row(mpg=18.7, disp=360.0)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "mtcars_df = spark.read.csv('./mtcars.csv', inferSchema=True, header=True).select(['mpg', 'disp'])\n",
        "mtcars_df.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LEuZHX7_wk9"
      },
      "source": [
        "Step 2: calculate averages of mgp and disp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiAOs1zH_hL1",
        "outputId": "48f547cf-a2ce-4ff4-efed-f96569a4a88d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mpg mean =  20.090625000000003 ; disp mean =  230.721875\n"
          ]
        }
      ],
      "source": [
        "mpg_mean = mtcars_df.select('mpg').rdd.map(lambda x: x[0]).mean()\n",
        "disp_mean = mtcars_df.select('disp').rdd.map(lambda x: x[0]).mean()\n",
        "print('mpg mean = ', mpg_mean, '; '\n",
        "      'disp mean = ', disp_mean)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F99X4I2o_5qJ"
      },
      "source": [
        "Step 3: build **zeroValue, seqOp** and **combOp**\n",
        "\n",
        "We are calculating two TSS. We create a tuple to store two values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LSmHVKxz_hN1"
      },
      "outputs": [],
      "source": [
        "zeroValue = (0, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVH0LflKAAPZ"
      },
      "source": [
        "The **z** below refers to `zeroValue`. Its values get updated after every run. The **x** refers to an element in an RDD partition. In this case, both **z** and **x** have two values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "VScTN0ff_hP8"
      },
      "outputs": [],
      "source": [
        "seqOp = lambda z, x: (z[0] + (x[0] - mpg_mean)**2, z[1] + (x[1] - disp_mean)**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9Kn97AMGRRu",
        "outputId": "3d0ecc90-1562-4e7e-e445-1c3ab4b0f2fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.<lambda>(z, x)>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "seqOp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgC3QsdqAGpv"
      },
      "source": [
        "The `combOp` function simply aggrate all `zeroValues` into one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "glyhdIJD_hSt"
      },
      "outputs": [],
      "source": [
        "combOp = lambda px, py: ( px[0] + py[0], px[1] + py[1] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZlLtjOdAKKb"
      },
      "source": [
        "Implement `aggregate()` function.\n",
        "\n",
        "## `aggregateByKey(zeroValue, seqOp, combOp)`\n",
        "\n",
        "This function does similar things as `aggregate()`. The `aggregate()` aggregate all results to the very end, but aggregateByKey() merge results by key."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VXY7bSm_hWg",
        "outputId": "e5f77687-aff1-4c96-cd2c-f6dc92ddca80"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sepal_length,sepal_width,petal_length,petal_width,species',\n",
              " '5.1,3.5,1.4,0.2,setosa']"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "iris_rdd = sc.textFile('./iris.csv', use_unicode=True)\n",
        "iris_rdd.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zieFneZM_hhO",
        "outputId": "cbf879fd-b9f1-4c64-cd4d-9530a4d4ff6b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('setosa', [5.1, 3.5, 1.4, 0.2]),\n",
              " ('setosa', [4.9, 3.0, 1.4, 0.2]),\n",
              " ('setosa', [4.7, 3.2, 1.3, 0.2]),\n",
              " ('setosa', [4.6, 3.1, 1.5, 0.2]),\n",
              " ('setosa', [5.0, 3.6, 1.4, 0.2])]"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "iris_rdd_2 = iris_rdd.map(lambda x: x.split(',')).\\\n",
        "    filter(lambda x: x[0] != 'sepal_length').\\\n",
        "    map(lambda x: (x[-1], [*map(float, x[:-1])]))\n",
        "iris_rdd_2.take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAA6f6XBA-8U"
      },
      "source": [
        "### Define initial values, seqOp and combOp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Ku4yf29f_hj_"
      },
      "outputs": [],
      "source": [
        "zero_value = (0, 0)\n",
        "seqOp = (lambda x, y: (x[0] + (y[0])**2, x[1] + (y[1])**2))\n",
        "combOp = (lambda x, y: (x[0] + y[0], x[1] + y[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plq1nnx18Dyp",
        "outputId": "5e553bb9-1ffb-4b74-b83d-94d3afb3a8b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.<lambda>(x, y)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "seqOp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmxsXfkI8Fxt",
        "outputId": "335d0b40-4688-4a47-8f88-8968860c31ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.<lambda>(x, y)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "combOp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXtUz-kHBCRu"
      },
      "source": [
        "### Implement `aggregateByKey()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdFloy6U_hnG",
        "outputId": "17f2fd34-b05f-4324-e51d-dd5199894acb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('setosa', (1259.0899999999997, 591.2500000000002)),\n",
              " ('versicolor', (1774.8600000000001, 388.47)),\n",
              " ('virginica', (2189.9000000000005, 447.33))]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "list_aggregated_iris = iris_rdd_2.aggregateByKey(zero_value, seqOp, combOp).collect()\n",
        "list_aggregated_iris"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "NrdO7Z7DBH4a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqFeBwtWOdYT"
      },
      "source": [
        "# Convert continuous variables to categorical variables\n",
        "\n",
        "There are two functions we can use to split a continuous variable into categories:\n",
        "\n",
        "* `pyspark.ml.feature.Binarizer`: split a column of continuous features given a threshold\n",
        "* `pyspark.ml.feature.Bucktizer`: split a column of continuous features into categories given several breaking points.\n",
        "    + with n+1 split points, there are n categories (buckets).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwM3XWqZObw8",
        "outputId": "45c7e45a-f111-43de-ac82-f0e706c73ec4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+\n",
            "|                  x1|                x2|\n",
            "+--------------------+------------------+\n",
            "| 0.47143516373249306| 6.834629351721363|\n",
            "| -1.1909756947064645| 7.127020269829002|\n",
            "|  1.4327069684260973|3.7025075479039495|\n",
            "| -0.3126518960917129| 5.611961860656249|\n",
            "| -0.7205887333650116| 5.030831653078097|\n",
            "|  0.8871629403077386|0.1376844959068224|\n",
            "|  0.8595884137174165| 7.728266216123741|\n",
            "| -0.6365235044173491| 8.826411906361166|\n",
            "|0.015696372114428918| 3.648859839013723|\n",
            "| -2.2426849541854055| 6.153961784334937|\n",
            "+--------------------+------------------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "np.random.seed(seed=1234)\n",
        "pdf = pd.DataFrame({\n",
        "        'x1': np.random.randn(10),\n",
        "        'x2': np.random.rand(10)*10\n",
        "    })\n",
        "np.random.seed(seed=None)\n",
        "df = spark.createDataFrame(pdf)\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP4yy95mOpLr"
      },
      "source": [
        "## Binarize the column x1 and Bucketize the column x2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-nI0bvdNObzn",
        "outputId": "7264efe9-a2e6-4d09-b2cd-5057f045c6f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+------+------+\n",
            "|                  x1|                x2|x1_new|x2_new|\n",
            "+--------------------+------------------+------+------+\n",
            "| 0.47143516373249306| 6.834629351721363|   1.0|   2.0|\n",
            "| -1.1909756947064645| 7.127020269829002|   0.0|   2.0|\n",
            "|  1.4327069684260973|3.7025075479039495|   1.0|   1.0|\n",
            "| -0.3126518960917129| 5.611961860656249|   0.0|   2.0|\n",
            "| -0.7205887333650116| 5.030831653078097|   0.0|   2.0|\n",
            "|  0.8871629403077386|0.1376844959068224|   1.0|   0.0|\n",
            "|  0.8595884137174165| 7.728266216123741|   1.0|   3.0|\n",
            "| -0.6365235044173491| 8.826411906361166|   0.0|   3.0|\n",
            "|0.015696372114428918| 3.648859839013723|   1.0|   1.0|\n",
            "| -2.2426849541854055| 6.153961784334937|   0.0|   2.0|\n",
            "+--------------------+------------------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import Binarizer, Bucketizer\n",
        "# threshold = 0 for binarizer\n",
        "binarizer = Binarizer(threshold=0, inputCol='x1', outputCol='x1_new')\n",
        "# provide 5 split points to generate 4 buckets\n",
        "bucketizer = Bucketizer(splits=[0, 2.5, 5, 7.5, 10], inputCol='x2', outputCol='x2_new')\n",
        "\n",
        "# pipeline stages\n",
        "from pyspark.ml import Pipeline\n",
        "stages = [binarizer, bucketizer]\n",
        "pipeline = Pipeline(stages=stages)\n",
        "\n",
        "# fit the pipeline model and transform the data\n",
        "pipeline.fit(df).transform(df).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise:\n",
        "Do binarizer for `x2` the threshold `3`, and buckertizer `x1` with the split point is `[0.1, 0.3, 0.5, 0.7, 0.9]`."
      ],
      "metadata": {
        "id": "c9WPYhk3uyxI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "FyrGjOPOOb2Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49900d31-e3d4-44e1-9c6f-b7fa7a9798fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+------------------+------+------+\n",
            "|                  x1|                x2|x2_new|x1_new|\n",
            "+--------------------+------------------+------+------+\n",
            "| 0.47143516373249306| 6.834629351721363|   1.0|   2.0|\n",
            "| -1.1909756947064645| 7.127020269829002|   1.0|   0.0|\n",
            "|  1.4327069684260973|3.7025075479039495|   1.0|   5.0|\n",
            "| -0.3126518960917129| 5.611961860656249|   1.0|   0.0|\n",
            "| -0.7205887333650116| 5.030831653078097|   1.0|   0.0|\n",
            "|  0.8871629403077386|0.1376844959068224|   0.0|   4.0|\n",
            "|  0.8595884137174165| 7.728266216123741|   1.0|   4.0|\n",
            "| -0.6365235044173491| 8.826411906361166|   1.0|   0.0|\n",
            "|0.015696372114428918| 3.648859839013723|   1.0|   0.0|\n",
            "| -2.2426849541854055| 6.153961784334937|   1.0|   0.0|\n",
            "+--------------------+------------------+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.ml.feature import Binarizer, Bucketizer\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "binarizer = Binarizer(threshold=3,inputCol='x2', outputCol='x2_new')\n",
        "# Adjust the splits to cover the full range of values in x1\n",
        "bucketizer = Bucketizer(splits=[float('-inf'), 0.1, 0.3, 0.5, 0.7, 0.9, float('inf')], inputCol='x1', outputCol='x1_new')\n",
        "\n",
        "stages = [binarizer, bucketizer]\n",
        "pipeline = Pipeline(stages=stages)\n",
        "\n",
        "# fit the pipeline model and transform the data\n",
        "pipeline.fit(df).transform(df).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DEwjsi3Oxh3"
      },
      "source": [
        "# Data Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWJlnBHsOb6e",
        "outputId": "f1e45c57-ad98-4f57-a1a1-b702b8d955dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iris.csv  mtcars.csv  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "b7ZmC3ENOb-Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "outputId": "51761087-c227-4c61-e6c7-3c8063425768"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AnalysisException",
          "evalue": "[PATH_NOT_FOUND] Path does not exist: file:/content/kaggle-titanic-train.csv.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2615159101.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtitanic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./kaggle-titanic-train.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtitanic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36mcsv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_spark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonUtils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoSeq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRDD\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1323\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pyspark/errors/exceptions/captured.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAnalysisException\u001b[0m: [PATH_NOT_FOUND] Path does not exist: file:/content/kaggle-titanic-train.csv."
          ]
        }
      ],
      "source": [
        "titanic = spark.read.csv('./kaggle-titanic-train.csv', header=True, inferSchema=True)\n",
        "titanic.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A12HJEVKQ9UQ"
      },
      "source": [
        "## Data type\n",
        "\n",
        "First, we want to check if string and numeric variables are imported as we expect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58_zZmOzOcAH"
      },
      "outputs": [],
      "source": [
        "titanic.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83C2f_XARDul"
      },
      "source": [
        "## Data summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICcWm8A5OcCN"
      },
      "outputs": [],
      "source": [
        "len(titanic.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pCx94eZOcDx"
      },
      "outputs": [],
      "source": [
        "titanic.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aaqqogxaRKsJ"
      },
      "source": [
        "### Summarize *columns*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msYO6i1XOcFz"
      },
      "outputs": [],
      "source": [
        "def describe_columns(df):\n",
        "    for i in df.columns:\n",
        "        print('Column: ' + i)\n",
        "        titanic.select(i).describe().show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sUByBgo2OcHQ"
      },
      "outputs": [],
      "source": [
        "describe_columns(titanic)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xu1Ygo2uRZ6c"
      },
      "source": [
        "### Find columns with missing values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHHI7d3oRQSq"
      },
      "outputs": [],
      "source": [
        "def find_missing_values_columns(df):\n",
        "    nrow = df.count()\n",
        "    for v in df.columns:\n",
        "        summary_df = df.select(v).describe()\n",
        "        v_count = int(summary_df.collect()[0][v])\n",
        "        if v_count < nrow:\n",
        "            missing_percentage = (1 - v_count/nrow) * 100\n",
        "            print(\"Total observations: \" + str(nrow) + \"\\n\"\n",
        "                 \"Total observations of \" + v + \": \" + str(v_count) + \"\\n\"\n",
        "                 \"Percentage of missing values: \" + str(missing_percentage) + \"%\" + \"\\n\"\n",
        "                 \"----------------------------\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hN109EJmRQWX"
      },
      "outputs": [],
      "source": [
        "find_missing_values_columns(titanic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hqjbk8MhRQYm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QrA8RH6MR1QN"
      },
      "source": [
        "# Subset selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPD233IUR30V"
      },
      "source": [
        "## Select Rows by index\n",
        "\n",
        "First, we need to add index to each rows. The **zipWithIndex** function zips the RDD elements with their corresponding index and returns the result as a new element."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahvmeUFoSKzr"
      },
      "outputs": [],
      "source": [
        "mtcars = spark.read.csv('./mtcars.csv', inferSchema=True, header=True)\n",
        "# correct first column name\n",
        "mtcars = mtcars.withColumnRenamed('_c0', 'model')\n",
        "mtcars.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dFrR1CnRQaT"
      },
      "outputs": [],
      "source": [
        "mtcars.rdd.zipWithIndex().take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1eNzmsFSP-b"
      },
      "source": [
        "Now we can apply the **map** function to modify the structure of each element. Assume **x** is an element from the above RDD object, **x** has two elements: x[0] and x[1]. x[0] is an **Row** object, and x[1] is the index, which is an integer. We want to merge these two values to create a list. And we also want the first element in the list is the index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5C7IHC91RQd9"
      },
      "outputs": [],
      "source": [
        "mtcars.rdd.zipWithIndex().map(lambda x: [x[1]] + list(x[0])).take(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM5baUq4SU4t"
      },
      "source": [
        "Let's add column names and save the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF0JEZrYRQfs"
      },
      "outputs": [],
      "source": [
        "header = ['index'] + mtcars.columns\n",
        "mtcars_df = mtcars.rdd.zipWithIndex().map(lambda x: [x[1]] + list(x[0])).toDF(header)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Weqr9ng4SVwE"
      },
      "outputs": [],
      "source": [
        "mtcars_df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN_J6Rv6Scg4"
      },
      "source": [
        "After we obtain the **index column**, we can apply the **pyspark.sql.DataFrame.filter** function to select rows of the DataFrame. The **filter** function takes a **column** of **types.BooleanType** as input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvdYCvMmSfzj"
      },
      "source": [
        "### Select specific rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRtbGax9SVzx"
      },
      "outputs": [],
      "source": [
        "mtcars_df.filter(mtcars_df.index.isin([1,2,4,6,9])).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hdfEyXOwSmpc"
      },
      "source": [
        "### Select rows between a range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "096G5_4vSV2E"
      },
      "outputs": [],
      "source": [
        "mtcars_df.filter(mtcars_df.index.between(5, 10)).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_EAObeWPSsyD"
      },
      "source": [
        "### Select rows by a cutoff index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR6Nz_x2RQix"
      },
      "outputs": [],
      "source": [
        "mtcars_df.filter(mtcars_df.index < 9).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9RxqqXFRQlm"
      },
      "outputs": [],
      "source": [
        "mtcars_df.filter(mtcars_df.index >= 14).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss-w5ub7S3Yw"
      },
      "source": [
        "## Select rows by logical criteria"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dT0JE9gS7Rp"
      },
      "source": [
        "Example 1: select rows when **cyl = 4**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-1SdyMZSysK"
      },
      "outputs": [],
      "source": [
        "mtcars_df.filter(mtcars_df.cyl == 4).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6Z01nzOEEbn"
      },
      "outputs": [],
      "source": [
        "mtcars_df.filter(mtcars_df.cyl == 2).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IyYuNONS-mG"
      },
      "source": [
        "Example 2: select rows when **vs = 1 and am = 1**\n",
        "\n",
        "When the filtering is based on multiple **conditions** (e.g., **vs = 1** and **am = 1**), we use the conditions to build a new **boolean type column**. And we filter the DataFrame by the new column.\n",
        "\n",
        "<span style=\"color:red\">Warning: when passing multiple conditions to the **`when()`** function, each condition has to be within a pair of parentheses</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQTuzMBVSzcv"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHAuKvxvSzgg"
      },
      "outputs": [],
      "source": [
        "filtering_column = F.when((mtcars_df.vs == 1) & (mtcars_df.am == 1), 1).name('filter_col')\n",
        "filtering_column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxDiDMJ0TUkj"
      },
      "source": [
        "Now we need to add the new column to the original DataFrame. **This can be done by applying the `select()` function to select all original columns as well as the new filtering columns.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csCTgjmISzlI"
      },
      "outputs": [],
      "source": [
        "all_original_columns = [eval('mtcars_df.' + c) for c in mtcars_df.columns]\n",
        "all_original_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h7AA8BiGSznY"
      },
      "outputs": [],
      "source": [
        "all_columns = all_original_columns + [filtering_column]\n",
        "all_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh4kNfXjSzpu"
      },
      "outputs": [],
      "source": [
        "new_mtcars_df = mtcars_df.select(all_columns)\n",
        "new_mtcars_df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZkxi9lUTg-m"
      },
      "source": [
        "Now we can filter the DataFrame by the requested conditions. After we filter the DataFrame, we can drop the filtering column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fvirQfTCSztj"
      },
      "outputs": [],
      "source": [
        "new_mtcars_df.filter(new_mtcars_df.filter_col == 1).drop('filter_col').show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3So9716T8ZY"
      },
      "source": [
        "## Select columns by name\n",
        "\n",
        "We can simply use the **select()** function to select columns by name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a57h925GSzzM"
      },
      "outputs": [],
      "source": [
        "mtcars.select(['hp', 'disp']).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJmmWF51UDLP"
      },
      "source": [
        "## Select columns by index\n",
        "\n",
        "We can convert indices to corresponding column names and then select columns by name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZ3DK2c5Sz2a"
      },
      "outputs": [],
      "source": [
        "indices = [0,3,4,7]\n",
        "selected_columns =  [mtcars.columns[index] for index in indices]\n",
        "selected_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FkUGsNK5Sz5g"
      },
      "outputs": [],
      "source": [
        "mtcars.select(selected_columns).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02IMgHWrUNOc"
      },
      "source": [
        "## Select columns by pattern\n",
        "\n",
        "Example: columns start with `d`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PRmnfYiVSz8k"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "selected_columns = [x for x in mtcars.columns if re.compile('^d').match(x) is not None]\n",
        "selected_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fG0nZJxnUKCM"
      },
      "outputs": [],
      "source": [
        "mtcars.select(selected_columns).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM7ZAChzUikT"
      },
      "source": [
        "# Column expression\n",
        "\n",
        "A Spark **column instance** is **NOT a column of values** from the **DataFrame**: when you crate a column instance, it does not give you the actual values of that column in the DataFrame. I found it makes more sense to me if I consider a **column instance as a column of expressions**. These expressions are evaluated by other methods (e.g., the **select()**, **groupby()**, and **orderby()** from **pyspark.sql.DataFrame**)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYLhU6ldUmrC"
      },
      "source": [
        "## Use dot (.) to select column from DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "crQLFCk1UKFb"
      },
      "outputs": [],
      "source": [
        "mpg_col = mtcars.mpg\n",
        "mpg_col"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-OiqVwWUsDX"
      },
      "source": [
        "## Modify a column to generate a new column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0klal6WUKIJ"
      },
      "outputs": [],
      "source": [
        "mpg_col + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pz92LPASUKKW"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mpg_col * 100).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0OkQc6OU0U_"
      },
      "source": [
        "The `pyspark.sql.Column` has many methods that acts on a column and returns a column instance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "poecg4a9UKMT"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.gear.isin([2,3])).show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJQfsSieSz-T"
      },
      "outputs": [],
      "source": [
        "mtcars.mpg.asc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn-rGb8kVF5k"
      },
      "source": [
        "## Dot (.) column expression\n",
        "\n",
        "Create a column expression that will return the original column values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YvQUX3nU5rz"
      },
      "outputs": [],
      "source": [
        "mpg_col_exp = mtcars.mpg\n",
        "mpg_col_exp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HLjsSurU5uV"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mpg_col_exp).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-MlVmvkVWTG"
      },
      "source": [
        "## Boolean column expression\n",
        "\n",
        "Create a column expression that will return **boolean values**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFu3oBTJVZjT"
      },
      "source": [
        "## `between()`: true/false if the column value is between a given range"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNjhxIhZU5xZ"
      },
      "outputs": [],
      "source": [
        "mpg_between = mtcars.cyl.between(4,6)\n",
        "mpg_between"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiNkr2K5U50W"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.cyl, mpg_between).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVgsijoGViE6"
      },
      "source": [
        "## `contains()`: true/false if the column value contains a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-5k8bJ7U52U"
      },
      "outputs": [],
      "source": [
        "model_contains = mtcars.model.contains('Ho')\n",
        "model_contains"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_d9xXQOfU55z"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.model, model_contains).show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1t01hv0VnE4"
      },
      "source": [
        "## `endswith()`: true/false if the column value ends with a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBa4odltU576"
      },
      "outputs": [],
      "source": [
        "model_endswith = mtcars.model.endswith('t')\n",
        "model_endswith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqHfHxftU5-y"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.model, model_endswith).show(6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_xRLbPbVyGk"
      },
      "source": [
        "## `isNotNull()`: true/false if the column value is not Null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TXqwJbq3U6BD"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Row\n",
        "df = spark.createDataFrame([Row(name='Tom', height=80), Row(name='Alice', height=None)])\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6Mt8G3uVzFJ"
      },
      "outputs": [],
      "source": [
        "height_isNotNull = df.height.isNotNull()\n",
        "height_isNotNull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-qlfsAnVzK9"
      },
      "outputs": [],
      "source": [
        "df.select(df.height, height_isNotNull).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQSr01cXV8oC"
      },
      "source": [
        "## `isNull()`: true/false if the column value is Null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgw2rTFdVzO4"
      },
      "outputs": [],
      "source": [
        "height_isNull = df.height.isNull()\n",
        "height_isNull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOkX2rRuVzRs"
      },
      "outputs": [],
      "source": [
        "df.select(df.height, height_isNull).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fh_I6WAgWH3C"
      },
      "source": [
        "## `isin()`: true/false if the column value is contained by the evaluated argument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RhtC9PYVzU4"
      },
      "outputs": [],
      "source": [
        "carb_isin = mtcars.carb.isin([2, 3])\n",
        "carb_isin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ivNn1TvEVzWv"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.carb, carb_isin).show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFRlYlskWQ_I"
      },
      "source": [
        "## `like()`: true/false if the column value matches a pattern based on a _SQL LIKE_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l00usXH4VzY2"
      },
      "outputs": [],
      "source": [
        "model_like = mtcars.model.like('Ho%')\n",
        "model_like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXfs_sJDWR3U"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.model, model_like).show(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZXFi1WEWZ7K"
      },
      "source": [
        "## `rlike()`: true/false if the column value matches a pattern based on a _SQL RLIKE_ (LIKE with Regex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZyqqCN8HWR6E"
      },
      "outputs": [],
      "source": [
        "model_rlike = mtcars.model.rlike('t$')\n",
        "model_rlike"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Teat8OqqWR_F"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.model, model_rlike).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZ2fVEXkWjEC"
      },
      "source": [
        "## `startswith()`: true/false if the column value starts with a string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tFtFM5jXWSBt"
      },
      "outputs": [],
      "source": [
        "model_startswith = mtcars.model.startswith('Merc')\n",
        "model_startswith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mW_vtSLVWSEJ"
      },
      "outputs": [],
      "source": [
        "mtcars.select(mtcars.model, model_startswith).show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybnKevoGWSGq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odqiAOEdXEOX"
      },
      "source": [
        "# `pyspark.sql.functions` functions\n",
        "\n",
        "`pyspark.sql.functions` is collection of built-in functions for **creating column expressions**. These functions largely increase methods that we can use to manipulate DataFrame and DataFrame columns.\n",
        "\n",
        "There are many sql functions from the `pyspark.sql.functions` module. Here I only choose a few to show how these functions extend the ability to create column expressions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHU-xA9CWSJP"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import functions as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFNaYPbFXKiM"
      },
      "source": [
        "## `abs()`: create column expression that returns absolute values of a column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NUoRVCf0WSMR"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import Row\n",
        "df = sc.parallelize([Row(x=1), Row(x=-1), Row(x=-2)]).toDF()\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKXOnqzmWSPb"
      },
      "outputs": [],
      "source": [
        "x_abs = F.abs(df.x)\n",
        "x_abs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0WJ23LOMWSST"
      },
      "outputs": [],
      "source": [
        "df.select(df.x, x_abs).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Xi6HVfTXV_I"
      },
      "source": [
        "## `concat()`: create column expression that concatenates multiple column values into one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHHSO80lWSUP"
      },
      "outputs": [],
      "source": [
        "df = sc.parallelize([Row(a='apple', b='tree'), Row(a='orange', b='flowers')]).toDF()\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eyxlLEfXWSWm"
      },
      "outputs": [],
      "source": [
        "ab_concat = F.concat(df.a, df.b)\n",
        "ab_concat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl4tmLFjWSZJ"
      },
      "outputs": [],
      "source": [
        "df.select(df.a, df.b, ab_concat).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1LremMJXfjv"
      },
      "source": [
        "## `corr()`: create column expression that returns pearson correlation coefficient between two columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ONql3HMVzcw"
      },
      "outputs": [],
      "source": [
        "# Reload the mtcars data\n",
        "mtcars = spark.read.csv('./mtcars.csv', inferSchema=True, header=True)\n",
        "mtcars.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vk5oOiqcXgqO"
      },
      "outputs": [],
      "source": [
        "drat_wt_corr = F.corr(mtcars.drat, mtcars.wt)\n",
        "drat_wt_corr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piXCHGaVXgs0"
      },
      "outputs": [],
      "source": [
        "mtcars.select(drat_wt_corr).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Eaw4xoFXx_f"
      },
      "source": [
        "## `array()`: create column expression that merge multiple column values into an array\n",
        "\n",
        "This function can be used to build **feature column** in machine learning models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MbTrWjXgXgwJ"
      },
      "outputs": [],
      "source": [
        "cols = [eval('mtcars.' + col) for col in mtcars.columns[1:]]\n",
        "cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHSlAzNTXgzB"
      },
      "outputs": [],
      "source": [
        "cols_array = F.array(cols)\n",
        "cols_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2JKKM10dXg1X"
      },
      "outputs": [],
      "source": [
        "mtcars.select(cols_array).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIgC5XONXg4q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYCqADDwYKZl"
      },
      "source": [
        "# `udf()` function and sql types\n",
        "\n",
        "\n",
        "The `pyspark.sql.functions.udf()` function is a very important function. It allows us to transfer a **user defined function** to a **`pyspark.sql.functions`** function which can act on columns of a DataFrame. It makes data framsformation much more flexible.\n",
        "\n",
        "Using `udf()` could be tricky. The key is to understand how to define the `returnType` parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc_TrALqXg7K"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.functions import udf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymuFb8YYXg9k"
      },
      "outputs": [],
      "source": [
        "# Reload mtcars data\n",
        "mtcars = spark.read.csv('./mtcars.csv', inferSchema=True, header=True)\n",
        "mtcars = mtcars.withColumnRenamed('_c0', 'model')\n",
        "mtcars.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVW4wANqYfGF"
      },
      "source": [
        "**The structure of the schema passed to `returnType` has to match the data structure of the return value from the user defined function**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDK-5VJsYgd7"
      },
      "source": [
        "**Case 1**: divide **disp** by **hp** and put the result to a new column\n",
        "\n",
        "The user defined function returns a float value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ft1QzN_IXhAC"
      },
      "outputs": [],
      "source": [
        "def disp_by_hp(disp, hp):\n",
        "    return(disp/hp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ez-wkS2WXhCY"
      },
      "outputs": [],
      "source": [
        "disp_by_hp_udf = udf(disp_by_hp, returnType=FloatType())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7-sfypf2Vzfa"
      },
      "outputs": [],
      "source": [
        "all_original_cols = [eval('mtcars.' + x) for x in mtcars.columns]\n",
        "all_original_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ6vetw8YpMJ"
      },
      "outputs": [],
      "source": [
        "disp_by_hp_col = disp_by_hp_udf(mtcars.disp, mtcars.hp)\n",
        "disp_by_hp_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQ9I9nz6Yppo"
      },
      "outputs": [],
      "source": [
        "all_new_cols = all_original_cols + [disp_by_hp_col]\n",
        "all_new_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikdhxS8vYps-"
      },
      "outputs": [],
      "source": [
        "mtcars.select(all_new_cols).show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fdTKuUYYzWu"
      },
      "source": [
        "**case 2**: create an array column that contain **disp** and **hp** values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUn_jVc_Ypwi"
      },
      "outputs": [],
      "source": [
        "# define function\n",
        "def merge_two_columns(col1, col2):\n",
        "    return([float(col1), float(col2)])\n",
        "\n",
        "# convert user defined function into an udf function (sql function)\n",
        "array_merge_two_columns_udf = udf(merge_two_columns, returnType=ArrayType(FloatType()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GixPBqiUYp2P"
      },
      "outputs": [],
      "source": [
        "array_col = array_merge_two_columns_udf(mtcars.disp, mtcars.hp)\n",
        "array_col"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhVBzW2QYp6b"
      },
      "outputs": [],
      "source": [
        "all_new_cols = all_original_cols + [array_col]\n",
        "all_new_cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BiIWG34YqBV"
      },
      "outputs": [],
      "source": [
        "mtcars.select(all_new_cols).show(5, truncate=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzGOJLBhZAHz"
      },
      "source": [
        "## `ArrayType` vs. `StructType`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNbcIXboZAPA"
      },
      "source": [
        "Both `ArrayType` and `StructType` can be used to build `returnType` for a list. The difference is:\n",
        "\n",
        "1. `ArrayType` requires all elements in the list have the same `elementType`, while `StructType` can have different `elementTypes`.\n",
        "2. `StructType` represents a `Row` object.\n",
        "\n",
        "\n",
        "**Define an `ArrayType` with elementType being `FloatType`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDU3JJRcYqEJ"
      },
      "outputs": [],
      "source": [
        "# define function\n",
        "def merge_two_columns(col1, col2):\n",
        "    return([float(col1), float(col2)])\n",
        "array_type = ArrayType(FloatType())\n",
        "array_merge_two_columns_udf = udf(merge_two_columns, returnType=array_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py-l78MNZPW0"
      },
      "source": [
        "**Define a `StructType` with one elementType being `StringType` and the other being `FloatType`.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qjs5af3dYqH0"
      },
      "outputs": [],
      "source": [
        "# define function\n",
        "def merge_two_columns(col1, col2):\n",
        "    return([str(col1), float(col2)])\n",
        "struct_type = StructType([\n",
        "    StructField('f1', StringType()),\n",
        "    StructField('f2', FloatType())\n",
        "])\n",
        "struct_merge_two_columns_udf = udf(merge_two_columns, returnType=struct_type)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eil3Mq4rZVKE"
      },
      "source": [
        "**array column** expression: both values are float type values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UmcMZr_rYqKt"
      },
      "outputs": [],
      "source": [
        "array_col = array_merge_two_columns_udf(mtcars.hp, mtcars.disp)\n",
        "array_col"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHKux8hhZbdL"
      },
      "source": [
        "**struct column** expression: first value is a string and the second value is a float type value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTkisZDAZSQ4"
      },
      "outputs": [],
      "source": [
        "struct_col = struct_merge_two_columns_udf(mtcars.model, mtcars.disp)\n",
        "struct_col"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6au8SaKZfIe"
      },
      "source": [
        "**Results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBrmB8rEZSTf"
      },
      "outputs": [],
      "source": [
        "mtcars.select(array_col, struct_col).show(truncate=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lq7XSVw6ZSXy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pMotE7XZSa1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59iDgwn0ZSdW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQEGjhbcZShc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Efdc8Z77ZSku"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTK6ikabZSnu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}