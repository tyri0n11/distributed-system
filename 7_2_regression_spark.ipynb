{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tyri0n11/distributed-system/blob/main/7_2_regression_spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "32GC-x-Jeohv"
      },
      "source": [
        "from pyspark import SparkContext\n",
        "sc = SparkContext(master = 'local[4]')\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "          .appName(\"Python Spark SQL basic example\") \\\n",
        "          .config(\"spark.some.config.option\", \"some-value\") \\\n",
        "          .getOrCreate()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyJ69dq3e05y"
      },
      "source": [
        "# Linear regression without cross-valiation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f1sdMlCfT6b",
        "outputId": "cdccdd54-8c94-4731-8b24-b62308ba562e"
      },
      "source": [
        "ad = spark.read.csv('./Advertising.csv', header=True, inferSchema=True)\n",
        "ad.show(5)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----+---------+-----+\n",
            "|   TV|Radio|Newspaper|Sales|\n",
            "+-----+-----+---------+-----+\n",
            "|230.1| 37.8|     69.2| 22.1|\n",
            "| 44.5| 39.3|     45.1| 10.4|\n",
            "| 17.2| 45.9|     69.3|  9.3|\n",
            "|151.5| 41.3|     58.5| 18.5|\n",
            "|180.8| 10.8|     58.4| 12.9|\n",
            "+-----+-----+---------+-----+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(ad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "I7ArSC0T4kLy",
        "outputId": "b38925b7-c993-4264-e5ba-f17bc343d01a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.sql.classic.dataframe.DataFrame"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.sql.classic.dataframe.DataFrame</b><br/>def __init__(jdf: &#x27;JavaObject&#x27;, sql_ctx: Union[&#x27;SQLContext&#x27;, &#x27;SparkSession&#x27;])</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/sql/classic/dataframe.py</a>A distributed collection of data grouped into named columns.\n",
              "\n",
              ".. versionadded:: 1.3.0\n",
              "\n",
              ".. versionchanged:: 3.4.0\n",
              "    Supports Spark Connect.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "A :class:`DataFrame` is equivalent to a relational table in Spark SQL,\n",
              "and can be created using various functions in :class:`SparkSession`:\n",
              "\n",
              "&gt;&gt;&gt; people = spark.createDataFrame([\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 40, &quot;name&quot;: &quot;Hyukjin Kwon&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 50},\n",
              "...     {&quot;deptId&quot;: 1, &quot;age&quot;: 50, &quot;name&quot;: &quot;Takuya Ueshin&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 100},\n",
              "...     {&quot;deptId&quot;: 2, &quot;age&quot;: 60, &quot;name&quot;: &quot;Xinrong Meng&quot;, &quot;gender&quot;: &quot;F&quot;, &quot;salary&quot;: 150},\n",
              "...     {&quot;deptId&quot;: 3, &quot;age&quot;: 20, &quot;name&quot;: &quot;Haejoon Lee&quot;, &quot;gender&quot;: &quot;M&quot;, &quot;salary&quot;: 200}\n",
              "... ])\n",
              "\n",
              "Once created, it can be manipulated using the various domain-specific-language\n",
              "(DSL) functions defined in: :class:`DataFrame`, :class:`Column`.\n",
              "\n",
              "To select a column from the :class:`DataFrame`, use the apply method:\n",
              "\n",
              "&gt;&gt;&gt; age_col = people.age\n",
              "\n",
              "A more concrete example:\n",
              "\n",
              "&gt;&gt;&gt; # To create DataFrame using SparkSession\n",
              "... department = spark.createDataFrame([\n",
              "...     {&quot;id&quot;: 1, &quot;name&quot;: &quot;PySpark&quot;},\n",
              "...     {&quot;id&quot;: 2, &quot;name&quot;: &quot;ML&quot;},\n",
              "...     {&quot;id&quot;: 3, &quot;name&quot;: &quot;Spark SQL&quot;}\n",
              "... ])\n",
              "\n",
              "&gt;&gt;&gt; people.filter(people.age &gt; 30).join(\n",
              "...     department, people.deptId == department.id).groupBy(\n",
              "...     department.name, &quot;gender&quot;).agg(\n",
              "...         {&quot;salary&quot;: &quot;avg&quot;, &quot;age&quot;: &quot;max&quot;}).sort(&quot;max(age)&quot;).show()\n",
              "+-------+------+-----------+--------+\n",
              "|   name|gender|avg(salary)|max(age)|\n",
              "+-------+------+-----------+--------+\n",
              "|PySpark|     M|       75.0|      50|\n",
              "|     ML|     F|      150.0|      60|\n",
              "+-------+------+-----------+--------+\n",
              "\n",
              "Notes\n",
              "-----\n",
              "A DataFrame should only be created as described above. It should not be directly\n",
              "created via using the constructor.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 105);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NwU4yPcfeW5"
      },
      "source": [
        "## Transform data structure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7S10xnONfaf6",
        "outputId": "e313a0b8-964c-4009-eb3f-e2f1b7788718"
      },
      "source": [
        "from pyspark.ml.linalg import Vectors\n",
        "ad_df = ad.rdd.map(lambda x: [Vectors.dense(x[0:3]), x[-1]]).toDF(['features', 'label'])\n",
        "ad_df.show(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+\n",
            "|         features|label|\n",
            "+-----------------+-----+\n",
            "|[230.1,37.8,69.2]| 22.1|\n",
            "| [44.5,39.3,45.1]| 10.4|\n",
            "| [17.2,45.9,69.3]|  9.3|\n",
            "|[151.5,41.3,58.5]| 18.5|\n",
            "|[180.8,10.8,58.4]| 12.9|\n",
            "+-----------------+-----+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwhoXn3XfkUU"
      },
      "source": [
        "## Build linear regression model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whCgAEc8fa55"
      },
      "source": [
        "from pyspark.ml.regression import LinearRegression\n",
        "lr = LinearRegression(featuresCol = 'features', labelCol = 'label')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "VP65SUAU5Dcz",
        "outputId": "34239cb4-e280-4a64-c19a-2db6c2964d63"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.ml.regression.LinearRegression"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.ml.regression.LinearRegression</b><br/>def __init__(*, featuresCol: str=&#x27;features&#x27;, labelCol: str=&#x27;label&#x27;, predictionCol: str=&#x27;prediction&#x27;, maxIter: int=100, regParam: float=0.0, elasticNetParam: float=0.0, tol: float=1e-06, fitIntercept: bool=True, standardization: bool=True, solver: str=&#x27;auto&#x27;, weightCol: Optional[str]=None, aggregationDepth: int=2, loss: str=&#x27;squaredError&#x27;, epsilon: float=1.35, maxBlockSizeInMB: float=0.0)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/ml/regression.py</a>Linear regression.\n",
              "\n",
              "The learning objective is to minimize the specified loss function, with regularization.\n",
              "This supports two kinds of loss:\n",
              "\n",
              "* squaredError (a.k.a squared loss)\n",
              "* huber (a hybrid of squared error for relatively small errors and absolute error for     relatively large ones, and we estimate the scale parameter from training data)\n",
              "\n",
              "This supports multiple types of regularization:\n",
              "\n",
              "* none (a.k.a. ordinary least squares)\n",
              "* L2 (ridge regression)\n",
              "* L1 (Lasso)\n",
              "* L2 + L1 (elastic net)\n",
              "\n",
              ".. versionadded:: 1.4.0\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Fitting with huber loss only supports none and L2 regularization.\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; from pyspark.ml.linalg import Vectors\n",
              "&gt;&gt;&gt; df = spark.createDataFrame([\n",
              "...     (1.0, 2.0, Vectors.dense(1.0)),\n",
              "...     (0.0, 2.0, Vectors.sparse(1, [], []))], [&quot;label&quot;, &quot;weight&quot;, &quot;features&quot;])\n",
              "&gt;&gt;&gt; lr = LinearRegression(regParam=0.0, solver=&quot;normal&quot;, weightCol=&quot;weight&quot;)\n",
              "&gt;&gt;&gt; lr.setMaxIter(5)\n",
              "LinearRegression...\n",
              "&gt;&gt;&gt; lr.getMaxIter()\n",
              "5\n",
              "&gt;&gt;&gt; lr.setRegParam(0.1)\n",
              "LinearRegression...\n",
              "&gt;&gt;&gt; lr.getRegParam()\n",
              "0.1\n",
              "&gt;&gt;&gt; lr.setRegParam(0.0)\n",
              "LinearRegression...\n",
              "&gt;&gt;&gt; model = lr.fit(df)\n",
              "&gt;&gt;&gt; model.setFeaturesCol(&quot;features&quot;)\n",
              "LinearRegressionModel...\n",
              "&gt;&gt;&gt; model.setPredictionCol(&quot;newPrediction&quot;)\n",
              "LinearRegressionModel...\n",
              "&gt;&gt;&gt; model.getMaxIter()\n",
              "5\n",
              "&gt;&gt;&gt; model.getMaxBlockSizeInMB()\n",
              "0.0\n",
              "&gt;&gt;&gt; test0 = spark.createDataFrame([(Vectors.dense(-1.0),)], [&quot;features&quot;])\n",
              "&gt;&gt;&gt; abs(model.predict(test0.head().features) - (-1.0)) &lt; 0.001\n",
              "True\n",
              "&gt;&gt;&gt; abs(model.transform(test0).head().newPrediction - (-1.0)) &lt; 0.001\n",
              "True\n",
              "&gt;&gt;&gt; bool(abs(model.coefficients[0] - 1.0) &lt; 0.001)\n",
              "True\n",
              "&gt;&gt;&gt; abs(model.intercept - 0.0) &lt; 0.001\n",
              "True\n",
              "&gt;&gt;&gt; test1 = spark.createDataFrame([(Vectors.sparse(1, [0], [1.0]),)], [&quot;features&quot;])\n",
              "&gt;&gt;&gt; abs(model.transform(test1).head().newPrediction - 1.0) &lt; 0.001\n",
              "True\n",
              "&gt;&gt;&gt; lr.setParams(featuresCol=&quot;vector&quot;)\n",
              "LinearRegression...\n",
              "&gt;&gt;&gt; lr_path = temp_path + &quot;/lr&quot;\n",
              "&gt;&gt;&gt; lr.save(lr_path)\n",
              "&gt;&gt;&gt; lr2 = LinearRegression.load(lr_path)\n",
              "&gt;&gt;&gt; lr2.getMaxIter()\n",
              "5\n",
              "&gt;&gt;&gt; model_path = temp_path + &quot;/lr_model&quot;\n",
              "&gt;&gt;&gt; model.save(model_path)\n",
              "&gt;&gt;&gt; model2 = LinearRegressionModel.load(model_path)\n",
              "&gt;&gt;&gt; bool(model.coefficients[0] == model2.coefficients[0])\n",
              "True\n",
              "&gt;&gt;&gt; bool(model.intercept == model2.intercept)\n",
              "True\n",
              "&gt;&gt;&gt; bool(model.transform(test0).take(1) == model2.transform(test0).take(1))\n",
              "True\n",
              "&gt;&gt;&gt; model.numFeatures\n",
              "1\n",
              "&gt;&gt;&gt; model.write().format(&quot;pmml&quot;).save(model_path + &quot;_2&quot;)</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 211);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YbHlDuC_foGi"
      },
      "source": [
        "## Fit the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6CsYKPEfa8Y"
      },
      "source": [
        "lr_model = lr.fit(ad_df)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(lr_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "_57F3iZC5OwQ",
        "outputId": "293ba5b2-04f4-46ac-9945-c255be20b4c4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.ml.regression.LinearRegressionModel"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.ml.regression.LinearRegressionModel</b><br/>def __init__(java_model: Optional[&#x27;JavaObject&#x27;]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/ml/regression.py</a>Model fitted by :class:`LinearRegression`.\n",
              "\n",
              ".. versionadded:: 1.4.0</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 444);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DS7DrR2Y7PMS",
        "outputId": "0bc7ef9b-78da-46ac-e5c9-cff8da9e4399"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegressionModel: uid=LinearRegression_432ec5b39bf6, numFeatures=3"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OTfxNyntfoyf"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHSnJQ2Qfa_f",
        "outputId": "0dd968bd-0dab-4195-9dd0-5f13318b1956"
      },
      "source": [
        "pred = lr_model.transform(ad_df)\n",
        "pred.show(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+------------------+\n",
            "|         features|label|        prediction|\n",
            "+-----------------+-----+------------------+\n",
            "|[230.1,37.8,69.2]| 22.1| 20.52397440971517|\n",
            "| [44.5,39.3,45.1]| 10.4|12.337854820894362|\n",
            "| [17.2,45.9,69.3]|  9.3|12.307670779994238|\n",
            "|[151.5,41.3,58.5]| 18.5| 17.59782951168913|\n",
            "|[180.8,10.8,58.4]| 12.9|13.188671856831299|\n",
            "+-----------------+-----+------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY3-lv0lfpjW"
      },
      "source": [
        "## Module evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PafLoz9kfbB1",
        "outputId": "76bc1cf2-41e5-4e63-f1ce-a3c457c42798"
      },
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='label')\n",
        "evaluator.setMetricName('r2').evaluate(pred)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.897210638178952"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='label')\n",
        "evaluator.setMetricName('mse').evaluate(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmL61leP7fPm",
        "outputId": "a47cd979-941e-4ab0-af20-28482ffe2089"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.784126314510938"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator.setMetricName('mae').evaluate(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKmbGtxr7mVj",
        "outputId": "6bbddf9d-dd20-434a-d84c-107ed6085b1b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.2520112296870693"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "1. Do research in Spark documentaion to study & practice in other regression models.\n",
        "2. Investigate other metrics for evaluating regression model in Spark.\n",
        "3. Practice on `Advertising` dataset.\n",
        "4. Do the same thing, but now you should split into `train` and `test` datasets, so the fitting modelling in the `train`, then do the evaluation in the `test`"
      ],
      "metadata": {
        "id": "mKoDcxNv5s3m"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rne-jL6Pf4pC"
      },
      "source": [],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZS95SxIf-OL"
      },
      "source": [
        "# Linear regression with cross-validation in Spark"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szIXpqodf-aC"
      },
      "source": [
        "training, test = ad_df.randomSplit([0.8, 0.2], seed=123)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFfseuBaf-cr"
      },
      "source": [
        "##=====build cross valiation model======\n",
        "\n",
        "# estimator\n",
        "lr = LinearRegression(featuresCol = 'features', labelCol = 'label')\n",
        "\n",
        "# parameter grid\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "param_grid = ParamGridBuilder().\\\n",
        "    addGrid(lr.regParam, [0, 0.5, 1]).\\\n",
        "    addGrid(lr.elasticNetParam, [0, 0.5, 1]).\\\n",
        "    build()\n",
        "\n",
        "# evaluator\n",
        "evaluator = RegressionEvaluator(predictionCol='prediction', labelCol='label', metricName='r2')\n",
        "\n",
        "# cross-validation model\n",
        "from pyspark.ml.tuning import CrossValidator\n",
        "cv = CrossValidator(estimator=lr, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=4)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(cv)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "NPHMKqsL_9Zv",
        "outputId": "73ded62f-0c0d-48b4-c7c8-0e2debe24cd3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.ml.tuning.CrossValidator"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.ml.tuning.CrossValidator</b><br/>def __init__(*, estimator: Optional[Estimator]=None, estimatorParamMaps: Optional[List[&#x27;ParamMap&#x27;]]=None, evaluator: Optional[Evaluator]=None, numFolds: int=3, seed: Optional[int]=None, parallelism: int=1, collectSubModels: bool=False, foldCol: str=&#x27;&#x27;) -&gt; None</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/ml/tuning.py</a>K-fold cross validation performs model selection by splitting the dataset into a set of\n",
              "non-overlapping randomly partitioned folds which are used as separate training and test datasets\n",
              "e.g., with k=3 folds, K-fold cross validation will generate 3 (training, test) dataset pairs,\n",
              "each of which uses 2/3 of the data for training and 1/3 for testing. Each fold is used as the\n",
              "test set exactly once.\n",
              "\n",
              ".. versionadded:: 1.4.0\n",
              "\n",
              "Examples\n",
              "--------\n",
              "&gt;&gt;&gt; from pyspark.ml.classification import LogisticRegression\n",
              "&gt;&gt;&gt; from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
              "&gt;&gt;&gt; from pyspark.ml.linalg import Vectors\n",
              "&gt;&gt;&gt; from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, CrossValidatorModel\n",
              "&gt;&gt;&gt; import tempfile\n",
              "&gt;&gt;&gt; dataset = spark.createDataFrame(\n",
              "...     [(Vectors.dense([0.0]), 0.0),\n",
              "...      (Vectors.dense([0.4]), 1.0),\n",
              "...      (Vectors.dense([0.5]), 0.0),\n",
              "...      (Vectors.dense([0.6]), 1.0),\n",
              "...      (Vectors.dense([1.0]), 1.0)] * 10,\n",
              "...     [&quot;features&quot;, &quot;label&quot;])\n",
              "&gt;&gt;&gt; lr = LogisticRegression()\n",
              "&gt;&gt;&gt; grid = ParamGridBuilder().addGrid(lr.maxIter, [0, 1]).build()\n",
              "&gt;&gt;&gt; evaluator = BinaryClassificationEvaluator()\n",
              "&gt;&gt;&gt; cv = CrossValidator(estimator=lr, estimatorParamMaps=grid, evaluator=evaluator,\n",
              "...     parallelism=2)\n",
              "&gt;&gt;&gt; cvModel = cv.fit(dataset)\n",
              "&gt;&gt;&gt; cvModel.getNumFolds()\n",
              "3\n",
              "&gt;&gt;&gt; float(cvModel.avgMetrics[0])\n",
              "0.5\n",
              "&gt;&gt;&gt; path = tempfile.mkdtemp()\n",
              "&gt;&gt;&gt; model_path = path + &quot;/model&quot;\n",
              "&gt;&gt;&gt; cvModel.write().save(model_path)\n",
              "&gt;&gt;&gt; cvModelRead = CrossValidatorModel.read().load(model_path)\n",
              "&gt;&gt;&gt; cvModelRead.avgMetrics\n",
              "[0.5, ...\n",
              "&gt;&gt;&gt; evaluator.evaluate(cvModel.transform(dataset))\n",
              "0.8333...\n",
              "&gt;&gt;&gt; evaluator.evaluate(cvModelRead.transform(dataset))\n",
              "0.8333...</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 676);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY1TWIOSf-f5"
      },
      "source": [
        "cv_model = cv.fit(training)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(cv_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "kvMMJTDWAGx8",
        "outputId": "896a67b3-5057-4bbd-afc0-e16262e34d8e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.ml.tuning.CrossValidatorModel"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.ml.tuning.CrossValidatorModel</b><br/>def __init__(bestModel: Model, avgMetrics: Optional[List[float]]=None, subModels: Optional[List[List[Model]]]=None, stdMetrics: Optional[List[float]]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/ml/tuning.py</a>CrossValidatorModel contains the model with the highest average cross-validation\n",
              "metric across folds and uses this model to transform input data. CrossValidatorModel\n",
              "also tracks the metrics for each param map evaluated.\n",
              "\n",
              ".. versionadded:: 1.4.0\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Since version 3.3.0, CrossValidatorModel contains a new attribute &quot;stdMetrics&quot;,\n",
              "which represent standard deviation of metrics for each paramMap in\n",
              "CrossValidator.estimatorParamMaps.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 1026);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cv_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sFzzyKyW8i2b",
        "outputId": "c14d92a1-5df3-4c21-9423-0fc305df556c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CrossValidatorModel_9515a65de413"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIkZ5GPof-ie"
      },
      "source": [
        "pred_training_cv = cv_model.transform(training)\n",
        "pred_test_cv = cv_model.transform(test)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEopRkEUf-k0",
        "outputId": "887a9e23-0c3b-4be6-e33d-2faf25fc2bf3"
      },
      "source": [
        "# performance on training data\n",
        "evaluator.setMetricName('r2').evaluate(pred_training_cv)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8952845631627804"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Pztn845f-nf",
        "outputId": "fb24f2e5-7477-4c16-effe-77a0bec188d0"
      },
      "source": [
        "# performance on test data\n",
        "evaluator.setMetricName('r2').evaluate(pred_test_cv)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9013819610158472"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OUIp-bsgRT5"
      },
      "source": [
        "## Intercept and coefficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XwVPl4fcgStY",
        "outputId": "504060d4-8d06-4394-84c1-151046d8d84a"
      },
      "source": [
        "print('Intercept: ', cv_model.bestModel.intercept, \"\\n\",\n",
        "     'coefficients: ', cv_model.bestModel.coefficients)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Intercept:  2.9592600706772787 \n",
            " coefficients:  [0.04613729524909818,0.19200356629524312,-0.006269704193266422]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ad_df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGn8QEx4XWck",
        "outputId": "d8ac384f-b986-43e5-b566-e116a3eb1a58"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------+-----+\n",
            "|         features|label|\n",
            "+-----------------+-----+\n",
            "|[230.1,37.8,69.2]| 22.1|\n",
            "| [44.5,39.3,45.1]| 10.4|\n",
            "| [17.2,45.9,69.3]|  9.3|\n",
            "|[151.5,41.3,58.5]| 18.5|\n",
            "|[180.8,10.8,58.4]| 12.9|\n",
            "+-----------------+-----+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "us8cqE8SgYnc"
      },
      "source": [
        "## Get parameter values from the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cV8hCL15gSwb",
        "outputId": "b7da3778-4888-4e23-a1b5-581f5ddafc84"
      },
      "source": [
        "print('best regParam: ' + str(cv_model.bestModel._java_obj.getRegParam()) + \"\\n\" +\n",
        "     'best ElasticNetParam:' + str(cv_model.bestModel._java_obj.getElasticNetParam()))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best regParam: 0.0\n",
            "best ElasticNetParam:0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "Wrap up the code of building cross-validation models in a Python class"
      ],
      "metadata": {
        "id": "qR6Ju0Sw80Ne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "Do the regression to forecast the `inside_sale` of this data: https://github.com/maks-p/restaurant_sales_forecasting/blob/master/csv/CSV_for_EDA_NEW.csv"
      ],
      "metadata": {
        "id": "nYGrazGzD6xT"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAjgMl2QgSz1",
        "outputId": "0c1e2a6e-4ee8-4155-b93a-90609f42dd8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_sales = spark.read.csv('./CSV_for_EDA_NEW.csv', header=True, inferSchema=True)\n",
        "df_sales.show(5)\n",
        "df_sales.printSchema()"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+-------------+-------------+--------------+---------------+-------------+---------------+--------------+---------------+--------------------+--------+--------------------+-------------------+-----------+-----------+--------+-------------------+-----------+\n",
            "|      date|inside_sales|outside_sales|inside_covers|outside_covers|reserved_covers|walkin_covers|waitlist_covers|no_show_covers|no_show_parties|apparent_temperature|humidity|precip_intensity_max|    precip_max_time|precip_prob|precip_type|pressure|            summary|temperature|\n",
            "+----------+------------+-------------+-------------+--------------+---------------+-------------+---------------+--------------+---------------+--------------------+--------+--------------------+-------------------+-----------+-----------+--------+-------------------+-----------+\n",
            "|2017-01-02|    13159.84|          0.0|          174|             0|            106|           26|             42|            17|              6|               35.58|    0.92|              0.0242|2026-01-03 15:00:00|       0.79|       rain| 1027.98|               rain|      39.06|\n",
            "|2017-01-03|    12442.11|          0.0|          181|             0|            119|           31|             31|            14|              4|                41.5|    0.94|              0.0913|2026-01-03 17:00:00|       0.77|       rain| 1000.08|               rain|      43.19|\n",
            "|2017-01-04|    12927.64|          0.0|          174|             0|            131|           17|             26|             5|              2|               36.81|     0.4|              0.0176|2026-01-03 00:00:00|        0.0|       rain| 1002.55|        clear-night|      42.29|\n",
            "|2017-01-05|    14457.79|          0.0|          191|             0|            138|           25|             28|             4|              2|               27.11|    0.48|                 0.0|2026-01-03 05:01:00|        0.0|       none| 1014.61|             cloudy|      31.36|\n",
            "|2017-01-06|    15331.97|          0.0|          200|             0|            130|           16|             54|             6|              3|               24.74|    0.48|              0.0019|2026-01-03 12:00:00|        0.0|       snow|  1022.8|partly-cloudy-night|      29.42|\n",
            "+----------+------------+-------------+-------------+--------------+---------------+-------------+---------------+--------------+---------------+--------------------+--------+--------------------+-------------------+-----------+-----------+--------+-------------------+-----------+\n",
            "only showing top 5 rows\n",
            "root\n",
            " |-- date: date (nullable = true)\n",
            " |-- inside_sales: double (nullable = true)\n",
            " |-- outside_sales: double (nullable = true)\n",
            " |-- inside_covers: integer (nullable = true)\n",
            " |-- outside_covers: integer (nullable = true)\n",
            " |-- reserved_covers: integer (nullable = true)\n",
            " |-- walkin_covers: integer (nullable = true)\n",
            " |-- waitlist_covers: integer (nullable = true)\n",
            " |-- no_show_covers: integer (nullable = true)\n",
            " |-- no_show_parties: integer (nullable = true)\n",
            " |-- apparent_temperature: double (nullable = true)\n",
            " |-- humidity: double (nullable = true)\n",
            " |-- precip_intensity_max: double (nullable = true)\n",
            " |-- precip_max_time: timestamp (nullable = true)\n",
            " |-- precip_prob: double (nullable = true)\n",
            " |-- precip_type: string (nullable = true)\n",
            " |-- pressure: double (nullable = true)\n",
            " |-- summary: string (nullable = true)\n",
            " |-- temperature: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = [\n",
        "    \"reserved_covers\", \"walkin_covers\", \"waitlist_covers\",\n",
        "    \"no_show_covers\", \"no_show_parties\",\n",
        "    \"apparent_temperature\", \"temperature\", \"humidity\",\n",
        "    \"precip_intensity_max\", \"precip_prob\", \"pressure\",\n",
        "    \"day_of_week\", \"month\"\n",
        "]\n",
        "cat_cols = [\"precip_type\", \"summary\", \"is_weekend\"]\n",
        "label_col = \"inside_sales\"\n",
        "target_leakage_cols = [\"outside_sales\", \"outside_covers\", \"inside_covers\"]\n"
      ],
      "metadata": {
        "id": "M9bo_jcx34Ce"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sales = df_sales.drop(*target_leakage_cols)\n"
      ],
      "metadata": {
        "id": "Hx9pUa0y6fWp"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import dayofweek, month, when, col\n",
        "\n",
        "df_sales = (\n",
        "    df_sales\n",
        "    .withColumn(\"day_of_week\", dayofweek(col(\"date\")))\n",
        "    .withColumn(\"month\", month(col(\"date\")))\n",
        "    .withColumn(\n",
        "        \"is_weekend\",\n",
        "        when(dayofweek(col(\"date\")).isin([1, 7]), 1).otherwise(0)\n",
        "    )\n",
        ")\n"
      ],
      "metadata": {
        "id": "4pnPZHQ06-cA"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "df_sales = df_sales.withColumn(\n",
        "    \"date_ts\",\n",
        "    col(\"date\").cast(\"timestamp\").cast(\"long\")\n",
        ")\n",
        "\n",
        "cutoff_ts = df_sales.approxQuantile(\n",
        "    \"date_ts\", [0.8], 0.0\n",
        ")[0]\n",
        "train = df_sales.filter(col(\"date_ts\") <= cutoff_ts)\n",
        "test  = df_sales.filter(col(\"date_ts\") > cutoff_ts)\n",
        "train.select(\"date\").orderBy(\"date\").show(3)\n",
        "test.select(\"date\").orderBy(\"date\").show(3)\n",
        "\n",
        "print(\"Train max date:\", train.selectExpr(\"max(date)\").first()[0])\n",
        "print(\"Test min date:\", test.selectExpr(\"min(date)\").first()[0])\n"
      ],
      "metadata": {
        "id": "Z9_b39Lw5tWc",
        "outputId": "b4e8ff29-755c-4fcf-f34e-cfdf95496404",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|      date|\n",
            "+----------+\n",
            "|2017-01-02|\n",
            "|2017-01-03|\n",
            "|2017-01-04|\n",
            "+----------+\n",
            "only showing top 3 rows\n",
            "+----------+\n",
            "|      date|\n",
            "+----------+\n",
            "|2019-01-02|\n",
            "|2019-01-03|\n",
            "|2019-01-04|\n",
            "+----------+\n",
            "only showing top 3 rows\n",
            "Train max date: 2018-12-31\n",
            "Test min date: 2019-01-02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "indexers = [\n",
        "    StringIndexer(\n",
        "        inputCol=c,\n",
        "        outputCol=f\"{c}_idx\",\n",
        "        handleInvalid=\"keep\"\n",
        "    ) for c in cat_cols\n",
        "]\n"
      ],
      "metadata": {
        "id": "w4uwZAFy6h9p"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import OneHotEncoder\n",
        "\n",
        "encoders = [\n",
        "    OneHotEncoder(\n",
        "        inputCol=f\"{c}_idx\",\n",
        "        outputCol=f\"{c}_ohe\"\n",
        "    ) for c in cat_cols\n",
        "]\n"
      ],
      "metadata": {
        "id": "Ukic4NaA6lqt"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "feature_cols = num_cols + [f\"{c}_ohe\" for c in cat_cols]\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=feature_cols,\n",
        "    outputCol=\"features\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "zqpD_1cv6mux"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.regression import GBTRegressor\n",
        "\n",
        "gbt = GBTRegressor(\n",
        "    labelCol=label_col,\n",
        "    featuresCol=\"features\",\n",
        "    maxIter=100,\n",
        "    maxDepth=5,\n",
        "    stepSize=0.1,\n",
        "    seed=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "23mY57LA6n62"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml import Pipeline\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    stages=indexers + encoders + [assembler, gbt]\n",
        ")\n"
      ],
      "metadata": {
        "id": "wZp9bK0P6pQd"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_sales.printSchema()\n"
      ],
      "metadata": {
        "id": "IsmCa-Z57EUk",
        "outputId": "173879d8-ebe2-4ad9-e21a-4db6fad88a4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- date: date (nullable = true)\n",
            " |-- inside_sales: double (nullable = true)\n",
            " |-- reserved_covers: integer (nullable = true)\n",
            " |-- walkin_covers: integer (nullable = true)\n",
            " |-- waitlist_covers: integer (nullable = true)\n",
            " |-- no_show_covers: integer (nullable = true)\n",
            " |-- no_show_parties: integer (nullable = true)\n",
            " |-- apparent_temperature: double (nullable = true)\n",
            " |-- humidity: double (nullable = true)\n",
            " |-- precip_intensity_max: double (nullable = true)\n",
            " |-- precip_max_time: timestamp (nullable = true)\n",
            " |-- precip_prob: double (nullable = true)\n",
            " |-- precip_type: string (nullable = true)\n",
            " |-- pressure: double (nullable = true)\n",
            " |-- summary: string (nullable = true)\n",
            " |-- temperature: double (nullable = true)\n",
            " |-- day_of_week: integer (nullable = true)\n",
            " |-- month: integer (nullable = true)\n",
            " |-- is_weekend: integer (nullable = false)\n",
            " |-- date_ts: long (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = pipeline.fit(train)\n"
      ],
      "metadata": {
        "id": "-w6zxvcS6qO-"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.transform(test)\n",
        "pred.select(\"inside_sales\", \"prediction\").show(10)\n"
      ],
      "metadata": {
        "id": "e3b9DaDi6rP0",
        "outputId": "eed06b2d-e18a-40f2-986a-4f4342685bce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------------+\n",
            "|inside_sales|        prediction|\n",
            "+------------+------------------+\n",
            "|    12685.24|14380.140563571931|\n",
            "|    13580.96|14638.092184099107|\n",
            "|    16002.75|15642.942736773186|\n",
            "|    16463.62|16974.901304761686|\n",
            "|    12405.14|14784.952597362397|\n",
            "|    14222.67| 13889.11679392458|\n",
            "|    10811.32|12664.754689285679|\n",
            "|    12985.09| 14578.97117472451|\n",
            "|    13196.76|15164.272387610847|\n",
            "|    14699.25|18205.927344249176|\n",
            "+------------+------------------+\n",
            "only showing top 10 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "rmse_eval = RegressionEvaluator(\n",
        "    labelCol=\"inside_sales\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"rmse\"\n",
        ")\n",
        "\n",
        "r2_eval = RegressionEvaluator(\n",
        "    labelCol=\"inside_sales\",\n",
        "    predictionCol=\"prediction\",\n",
        "    metricName=\"r2\"\n",
        ")\n",
        "\n",
        "print(\"RMSE:\", rmse_eval.evaluate(pred))\n",
        "print(\"R2:\", r2_eval.evaluate(pred))\n"
      ],
      "metadata": {
        "id": "bzka4QsI6siZ",
        "outputId": "50023bba-3878-4d64-ed18-0411d7e71f7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RMSE: 2742.785601890637\n",
            "R2: -0.03688928934671609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpbTJU8Mgek2"
      },
      "source": [
        "# Generalized regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RhfkP7Kgezk",
        "outputId": "1cbe0910-2926-4dd5-8647-d686d7516225"
      },
      "source": [
        "cuse = spark.read.csv('./cuse_binary.csv', header=True, inferSchema=True)\n",
        "cuse.show(5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+---------+---+\n",
            "|age|education|wantsMore|  y|\n",
            "+---+---------+---------+---+\n",
            "|<25|      low|      yes|  0|\n",
            "|<25|      low|      yes|  0|\n",
            "|<25|      low|      yes|  0|\n",
            "|<25|      low|      yes|  0|\n",
            "|<25|      low|      yes|  0|\n",
            "+---+---------+---------+---+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYBQARF7ge2Z",
        "outputId": "e117ced8-5953-42d2-d063-62c9dcaed8b3"
      },
      "source": [
        "cuse.columns[0:3]\n",
        "# cuse.select('age').distinct().show()\n",
        "cuse.select('age').rdd.countByValue()\n",
        "# cuse.select('education').rdd.countByValue()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(int,\n",
              "            {Row(age='<25'): 397,\n",
              "             Row(age='25-29'): 404,\n",
              "             Row(age='30-39'): 612,\n",
              "             Row(age='40-49'): 194})"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "relu2PFBge5z",
        "outputId": "f2c44e7f-e3bd-4b82-9cab-d95e631a5af3"
      },
      "source": [
        "# string index each categorical string columns\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml import Pipeline\n",
        "indexers = [StringIndexer(inputCol=column, outputCol=\"indexed_\"+column) for column in ('age', 'education', 'wantsMore')]\n",
        "pipeline = Pipeline(stages=indexers)\n",
        "indexed_cuse = pipeline.fit(cuse).transform(cuse)\n",
        "indexed_cuse.select('age', 'indexed_age').distinct().show(5)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-----------+\n",
            "|  age|indexed_age|\n",
            "+-----+-----------+\n",
            "|30-39|        0.0|\n",
            "|  <25|        2.0|\n",
            "|25-29|        1.0|\n",
            "|40-49|        3.0|\n",
            "+-----+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohO4WZWRg8-N",
        "outputId": "19219a94-ae9e-462e-f3de-c06753130023"
      },
      "source": [
        "# onehotencode each indexed categorical columns\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "columns = indexed_cuse.columns[0:3]\n",
        "onehoteencoders = [OneHotEncoder(inputCol=\"indexed_\"+column, outputCol=\"onehotencode_\"+column) for column in columns]\n",
        "pipeline = Pipeline(stages=onehoteencoders)\n",
        "onehotencode_columns = ['onehotencode_age', 'onehotencode_education', 'onehotencode_wantsMore', 'y']\n",
        "onehotencode_cuse = pipeline.fit(indexed_cuse).transform(indexed_cuse).select(onehotencode_columns)\n",
        "onehotencode_cuse.distinct().show(5)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------------+----------------------+---+\n",
            "|onehotencode_age|onehotencode_education|onehotencode_wantsMore|  y|\n",
            "+----------------+----------------------+----------------------+---+\n",
            "|   (3,[1],[1.0])|             (1,[],[])|         (1,[0],[1.0])|  0|\n",
            "|   (3,[2],[1.0])|         (1,[0],[1.0])|             (1,[],[])|  1|\n",
            "|   (3,[0],[1.0])|         (1,[0],[1.0])|         (1,[0],[1.0])|  0|\n",
            "|       (3,[],[])|         (1,[0],[1.0])|         (1,[0],[1.0])|  1|\n",
            "|   (3,[2],[1.0])|             (1,[],[])|         (1,[0],[1.0])|  0|\n",
            "+----------------+----------------------+----------------------+---+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjqDL8pOg_mU",
        "outputId": "18ec4255-2201-495a-c006-552f7bfc2c2a"
      },
      "source": [
        "# assemble all feature columns into on single vector column\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "assembler = VectorAssembler(inputCols=['onehotencode_age', 'onehotencode_education', 'onehotencode_wantsMore'], outputCol='features')\n",
        "cuse_df_2 = assembler.transform(onehotencode_cuse).withColumnRenamed('y', 'label')\n",
        "cuse_df_2.show(5)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------------+----------------------+-----+-------------------+\n",
            "|onehotencode_age|onehotencode_education|onehotencode_wantsMore|label|           features|\n",
            "+----------------+----------------------+----------------------+-----+-------------------+\n",
            "|   (3,[2],[1.0])|             (1,[],[])|         (1,[0],[1.0])|    0|(5,[2,4],[1.0,1.0])|\n",
            "|   (3,[2],[1.0])|             (1,[],[])|         (1,[0],[1.0])|    0|(5,[2,4],[1.0,1.0])|\n",
            "|   (3,[2],[1.0])|             (1,[],[])|         (1,[0],[1.0])|    0|(5,[2,4],[1.0,1.0])|\n",
            "|   (3,[2],[1.0])|             (1,[],[])|         (1,[0],[1.0])|    0|(5,[2,4],[1.0,1.0])|\n",
            "|   (3,[2],[1.0])|             (1,[],[])|         (1,[0],[1.0])|    0|(5,[2,4],[1.0,1.0])|\n",
            "+----------------+----------------------+----------------------+-----+-------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coFKHYzTP-nL",
        "outputId": "303e5781-ac54-4ea4-cd4e-04d050c53675"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------------+----------------------+-----+---------+\n",
            "|onehotencode_age|onehotencode_education|onehotencode_wantsMore|label| features|\n",
            "+----------------+----------------------+----------------------+-----+---------+\n",
            "|       (3,[],[])|             (1,[],[])|             (1,[],[])|    0|(5,[],[])|\n",
            "|       (3,[],[])|             (1,[],[])|             (1,[],[])|    0|(5,[],[])|\n",
            "|       (3,[],[])|             (1,[],[])|             (1,[],[])|    0|(5,[],[])|\n",
            "|       (3,[],[])|             (1,[],[])|             (1,[],[])|    0|(5,[],[])|\n",
            "|       (3,[],[])|             (1,[],[])|             (1,[],[])|    0|(5,[],[])|\n",
            "+----------------+----------------------+----------------------+-----+---------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMuEWNjZhCus",
        "outputId": "f942260d-d640-447c-8517-677ddb9e3091"
      },
      "source": [
        "# split data into training and test datasets\n",
        "training, test = cuse_df_2.randomSplit([0.8, 0.2], seed=1234)\n",
        "training.show(5)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------------+----------------------+-----+---------+\n",
            "|onehotencode_age|onehotencode_education|onehotencode_wantsMore|label| features|\n",
            "+----------------+----------------------+----------------------+-----+---------+\n",
            "|       (3,[],[])|             (1,[],[])|             (1,[],[])|    0|(5,[],[])|\n",
            "|       (3,[],[])|             (1,[],[])|             (1,[],[])|    0|(5,[],[])|\n",
            "|       (3,[],[])|             (1,[],[])|             (1,[],[])|    0|(5,[],[])|\n",
            "|       (3,[],[])|             (1,[],[])|             (1,[],[])|    0|(5,[],[])|\n",
            "|       (3,[],[])|             (1,[],[])|             (1,[],[])|    0|(5,[],[])|\n",
            "+----------------+----------------------+----------------------+-----+---------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q_IWGzXhE27"
      },
      "source": [
        "## ======= build cross validation model ===========\n",
        "\n",
        "# estimator\n",
        "from pyspark.ml.regression import GeneralizedLinearRegression\n",
        "glm = GeneralizedLinearRegression(featuresCol='features', labelCol='label', family='binomial')\n",
        "\n",
        "# parameter grid\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "param_grid = ParamGridBuilder().\\\n",
        "    addGrid(glm.regParam, [0, 0.5, 1, 2, 4]).\\\n",
        "    build()\n",
        "\n",
        "# evaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction')\n",
        "\n",
        "# build cross-validation model\n",
        "from pyspark.ml.tuning import CrossValidator\n",
        "cv = CrossValidator(estimator=glm, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=4)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ix5ugEvhJdF"
      },
      "source": [
        "# fit model\n",
        "# cv_model = cv.fit(training)\n",
        "cv_model = cv.fit(cuse_df_2)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(cv_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "H_8klxPMQoiv",
        "outputId": "424c37e5-8745-471a-acc5-abb81beaa25f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pyspark.ml.tuning.CrossValidatorModel"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>pyspark.ml.tuning.CrossValidatorModel</b><br/>def __init__(bestModel: Model, avgMetrics: Optional[List[float]]=None, subModels: Optional[List[List[Model]]]=None, stdMetrics: Optional[List[float]]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.12/dist-packages/pyspark/ml/tuning.py</a>CrossValidatorModel contains the model with the highest average cross-validation\n",
              "metric across folds and uses this model to transform input data. CrossValidatorModel\n",
              "also tracks the metrics for each param map evaluated.\n",
              "\n",
              ".. versionadded:: 1.4.0\n",
              "\n",
              "Notes\n",
              "-----\n",
              "Since version 3.3.0, CrossValidatorModel contains a new attribute &quot;stdMetrics&quot;,\n",
              "which represent standard deviation of metrics for each paramMap in\n",
              "CrossValidator.estimatorParamMaps.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 1026);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4wyjSK7hMll",
        "outputId": "72b46898-155e-42af-c9a8-78dc817d8b1b"
      },
      "source": [
        "# prediction\n",
        "pred_training_cv = cv_model.transform(training)\n",
        "pred_test_cv = cv_model.transform(test)\n",
        "\n",
        "pred_training_cv.show(5)\n",
        "pred_test_cv.show(5, truncate=False)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------------------+----------------------+-----+---------+------------------+\n",
            "|onehotencode_age|onehotencode_education|onehotencode_wantsMore|label| features|        prediction|\n",
            "+----------------+----------------------+----------------------+-----+---------+------------------+\n",
            "|       (3,[],[])|             (1,[],[])|             (1,[],[])|    0|(5,[],[])|0.5140024065151407|\n",
            "|       (3,[],[])|             (1,[],[])|             (1,[],[])|    0|(5,[],[])|0.5140024065151407|\n",
            "|       (3,[],[])|             (1,[],[])|             (1,[],[])|    0|(5,[],[])|0.5140024065151407|\n",
            "|       (3,[],[])|             (1,[],[])|             (1,[],[])|    0|(5,[],[])|0.5140024065151407|\n",
            "|       (3,[],[])|             (1,[],[])|             (1,[],[])|    0|(5,[],[])|0.5140024065151407|\n",
            "+----------------+----------------------+----------------------+-----+---------+------------------+\n",
            "only showing top 5 rows\n",
            "+----------------+----------------------+----------------------+-----+---------+------------------+\n",
            "|onehotencode_age|onehotencode_education|onehotencode_wantsMore|label|features |prediction        |\n",
            "+----------------+----------------------+----------------------+-----+---------+------------------+\n",
            "|(3,[],[])       |(1,[],[])             |(1,[],[])             |0    |(5,[],[])|0.5140024065151407|\n",
            "|(3,[],[])       |(1,[],[])             |(1,[],[])             |0    |(5,[],[])|0.5140024065151407|\n",
            "|(3,[],[])       |(1,[],[])             |(1,[],[])             |0    |(5,[],[])|0.5140024065151407|\n",
            "|(3,[],[])       |(1,[],[])             |(1,[],[])             |0    |(5,[],[])|0.5140024065151407|\n",
            "|(3,[],[])       |(1,[],[])             |(1,[],[])             |0    |(5,[],[])|0.5140024065151407|\n",
            "+----------------+----------------------+----------------------+-----+---------+------------------+\n",
            "only showing top 5 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6v6dHHXhP6i",
        "outputId": "a8acd203-7a47-43bb-eb5d-c54c6e0e1ed2"
      },
      "source": [
        "cv_model.bestModel.coefficients"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DenseVector([-0.2806, -0.7999, -1.1892, 0.325, -0.833])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6v9AZUSRhP-7",
        "outputId": "53483d78-53e8-440a-f124-9ed7f386e1b9"
      },
      "source": [
        "cv_model.bestModel.intercept"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.05602427516928616"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdJGL9ZrhXm1",
        "outputId": "c82ec71d-3656-4f85-c5c4-c8877f49a582"
      },
      "source": [
        "evaluator.evaluate(pred_training_cv)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6716478245974649"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPJ2YTkuhhEE",
        "outputId": "20090909-3970-4660-c63a-8822ff82d152"
      },
      "source": [
        "evaluator.evaluate(pred_test_cv)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6830864197530864"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7s2dyqB1hqkM"
      },
      "source": [],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise\n",
        "\n",
        "1. Do the generalized regression to forecast the `inside_sale` of this data: https://github.com/maks-p/restaurant_sales_forecasting/blob/master/csv/CSV_for_EDA_NEW.csv\n",
        "\n",
        "2. Wrap your code in a pipeline as a Python class"
      ],
      "metadata": {
        "id": "MHh2ALPnBLNn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ig44VM2fBSM0"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}